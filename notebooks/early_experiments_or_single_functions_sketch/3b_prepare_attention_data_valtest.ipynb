{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Prepare Attention Data for Validation and Test Sets\n",
    "\n",
    "This notebook prepares the final aligned data for validation and test sets.\n",
    "\n",
    "Since validation/test subjects don't have ground-truth concept labels, we create zero concept matrices.\n",
    "\n",
    "Input:\n",
    "- `subject_features_raw_validation.npz` - Validation embeddings\n",
    "- `subject_features_raw_test.npz` - Test embeddings\n",
    "\n",
    "Output:\n",
    "- `cem_input_raw_validation.npz` - Validation aligned data (X_raw, C=zeros, y, subject_ids, concept_names)\n",
    "- `cem_input_raw_test.npz` - Test aligned data (X_raw, C=zeros, y, subject_ids, concept_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "data_dir = os.path.join(project_root, \"data/processed\")\n",
    "\n",
    "val_features = os.path.join(data_dir, \"subject_features_raw_validation.npz\")\n",
    "test_features = os.path.join(data_dir, \"subject_features_raw_test.npz\")\n",
    "\n",
    "val_output = os.path.join(data_dir, \"cem_input_raw_validation.npz\")\n",
    "test_output = os.path.join(data_dir, \"cem_input_raw_test.npz\")\n",
    "\n",
    "print(f\"Validation features: {val_features}\")\n",
    "print(f\"Test features: {test_features}\")\n",
    "print(f\"Output directory: {data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concept_names",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define concept names (same 21 BDI-II concepts as training)\n",
    "concept_names = np.array([\n",
    "    \"Sadness\", \"Pessimism\", \"Past failure\", \"Loss of pleasure\",\n",
    "    \"Guilty feelings\", \"Punishment feelings\", \"Self-dislike\", \"Self-criticalness\",\n",
    "    \"Suicidal thoughts or wishes\", \"Crying\", \"Agitation\", \"Loss of interest\",\n",
    "    \"Indecisiveness\", \"Worthlessness\", \"Loss of energy\", \"Changes in sleeping pattern\",\n",
    "    \"Irritability\", \"Changes in appetite\", \"Concentration difficulty\",\n",
    "    \"Tiredness or fatigue\", \"Loss of interest in sex\"\n",
    "])\n",
    "\n",
    "n_concepts = len(concept_names)\n",
    "print(f\"Number of concepts: {n_concepts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare_function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_cem_data(features_path, output_path, dataset_name):\n",
    "    \"\"\"\n",
    "    Prepare CEM input data with zero concept matrix.\n",
    "    \n",
    "    Since val/test subjects don't have ground-truth concept labels,\n",
    "    we create an all-zero concept matrix.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing {dataset_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Load features\n",
    "    if not os.path.exists(features_path):\n",
    "        print(f\"Error: Input file not found at {features_path}\")\n",
    "        return\n",
    "    \n",
    "    features = np.load(features_path, allow_pickle=True)\n",
    "    X_raw = features[\"X_raw\"]\n",
    "    y = features[\"y\"]\n",
    "    subject_ids = features[\"subject_ids\"]\n",
    "    \n",
    "    n_subjects = len(y)\n",
    "    \n",
    "    print(f\"Loaded {n_subjects} subjects\")\n",
    "    print(f\"X_raw shape: {X_raw.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    print(f\"Label distribution: {np.bincount(y)}\")\n",
    "    \n",
    "    # Create zero concept matrix\n",
    "    # Shape: (n_subjects, n_concepts)\n",
    "    C = np.zeros((n_subjects, n_concepts), dtype=np.float32)\n",
    "    \n",
    "    print(f\"\\nCreated zero concept matrix: {C.shape}\")\n",
    "    print(f\"  Rationale: Val/test subjects don't have ground-truth concept labels\")\n",
    "    print(f\"  The model will learn to predict from embeddings primarily\")\n",
    "    \n",
    "    # Convert X_raw to float32 to avoid object dtype issues\n",
    "    X_raw_float = X_raw.astype(np.float32)\n",
    "    print(f\"\\nConverted X_raw to dtype: {X_raw_float.dtype}\")\n",
    "    \n",
    "    # Save\n",
    "    np.savez(\n",
    "        output_path,\n",
    "        X_raw=X_raw_float,\n",
    "        C=C,\n",
    "        y=y.astype(np.int64),\n",
    "        subject_ids=subject_ids,\n",
    "        concept_names=concept_names\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nSaved dataset to {output_path}\")\n",
    "    print(f\"Done with {dataset_name}!\\n\")\n",
    "\n",
    "print(\"Prepare function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process_validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process validation set\n",
    "prepare_cem_data(val_features, val_output, \"VALIDATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process test set\n",
    "prepare_cem_data(test_features, test_output, \"TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load and verify\n",
    "if os.path.exists(val_output):\n",
    "    val_data = np.load(val_output, allow_pickle=True)\n",
    "    print(f\"\\nValidation set:\")\n",
    "    print(f\"  - Subjects: {len(val_data['y'])}\")\n",
    "    print(f\"  - X_raw shape: {val_data['X_raw'].shape}\")\n",
    "    print(f\"  - C (concepts) shape: {val_data['C'].shape}\")\n",
    "    print(f\"  - C sum (should be 0): {val_data['C'].sum()}\")\n",
    "    print(f\"  - y shape: {val_data['y'].shape}\")\n",
    "    print(f\"  - Concept names: {len(val_data['concept_names'])}\")\n",
    "\n",
    "if os.path.exists(test_output):\n",
    "    test_data = np.load(test_output, allow_pickle=True)\n",
    "    print(f\"\\nTest set:\")\n",
    "    print(f\"  - Subjects: {len(test_data['y'])}\")\n",
    "    print(f\"  - X_raw shape: {test_data['X_raw'].shape}\")\n",
    "    print(f\"  - C (concepts) shape: {test_data['C'].shape}\")\n",
    "    print(f\"  - C sum (should be 0): {test_data['C'].sum()}\")\n",
    "    print(f\"  - y shape: {test_data['y'].shape}\")\n",
    "    print(f\"  - Concept names: {len(test_data['concept_names'])}\")\n",
    "\n",
    "print(\"\\nAll aligned data created successfully!\")\n",
    "print(\"\\nReady for training with proper train/val/test splits!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
