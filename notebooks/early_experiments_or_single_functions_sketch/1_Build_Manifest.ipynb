{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2470cd1",
   "metadata": {},
   "source": [
    "# Build Manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c53b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/38concept_embedding/lib/python3.8/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import json\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2313de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Paths ---\n",
    "POS_BASE = \"positive_examples_anonymous_chunks\"\n",
    "NEG_BASE = \"negative_examples_anonymous_chunks\"\n",
    "\n",
    "# Using regex to extract subject and chunk number\n",
    "SUBJECT_RE = re.compile(r\"subject(\\d+)\", re.IGNORECASE)\n",
    "CHUNK_RE   = re.compile(r\"_(\\d+)$\")   # trailing _<chunkid>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7777986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_name(filename):\n",
    "    \"\"\"\n",
    "    Parse filenames like 'train_subject7488_1.xml'\n",
    "    Returns:\n",
    "        tuple: (subject_id, chunk_id)\n",
    "    \"\"\"\n",
    "    basename_no_ext = os.path.splitext(filename)[0]  # e.g. 'train_subject7488_1'\n",
    "    parts = basename_no_ext.split(\"_\")               # ['train', 'subject7488', '1']\n",
    "\n",
    "    subject_id = parts[1]   # 'subject7488'\n",
    "    chunk_id = int(parts[2])  # '1' -> 1\n",
    "\n",
    "    return subject_id, chunk_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0513056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_manifest(base_folder, label):\n",
    "    \"\"\"\n",
    "    Build a manifest DataFrame:\n",
    "    - Each row = one subject\n",
    "    - Columns: subject_id, chunks (list of file paths), label\n",
    "    \"\"\"\n",
    "    manifest = {}\n",
    "\n",
    "    # find ALL xml files recursively\n",
    "    pattern = os.path.join(base_folder, \"**\", \"*.xml\")\n",
    "    all_files = glob.glob(pattern, recursive=True)\n",
    "\n",
    "    for filepath in all_files:\n",
    "        filename = os.path.basename(filepath)\n",
    "        subject_id, chunk_id = parse_name(filename)\n",
    "\n",
    "        if subject_id not in manifest:\n",
    "            manifest[subject_id] = []\n",
    "        manifest[subject_id].append(filepath)\n",
    "\n",
    "    # build DataFrame\n",
    "    df = pd.DataFrame([\n",
    "        {\"subject_id\": subject, \"chunks\": sorted(files), \"label\": label}\n",
    "        for subject, files in manifest.items()\n",
    "    ])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c459502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    subject_id                                             chunks     label\n",
      "0  subject6760  [positive_examples_anonymous_chunks/chunk 1/tr...  positive\n",
      "1   subject127  [positive_examples_anonymous_chunks/chunk 1/tr...  positive\n",
      "2  subject7326  [positive_examples_anonymous_chunks/chunk 1/tr...  positive\n",
      "3  subject2712  [positive_examples_anonymous_chunks/chunk 1/tr...  positive\n",
      "4  subject2252  [positive_examples_anonymous_chunks/chunk 1/tr...  positive\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 486 entries, 0 to 485\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   subject_id  486 non-null    object\n",
      " 1   chunks      486 non-null    object\n",
      " 2   label       486 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 11.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_pos = build_manifest(POS_BASE, \"positive\")\n",
    "df_neg = build_manifest(NEG_BASE, \"negative\")\n",
    "\n",
    "df_all = pd.concat([df_pos, df_neg], ignore_index=True)\n",
    "\n",
    "print(df_all.head())\n",
    "print(df_all.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e17e699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: subject6760\n",
      "Label: positive\n",
      "Chunks: ['positive_examples_anonymous_chunks/chunk 1/train_subject6760_1.xml', 'positive_examples_anonymous_chunks/chunk 10/train_subject6760_10.xml', 'positive_examples_anonymous_chunks/chunk 2/train_subject6760_2.xml', 'positive_examples_anonymous_chunks/chunk 3/train_subject6760_3.xml', 'positive_examples_anonymous_chunks/chunk 4/train_subject6760_4.xml', 'positive_examples_anonymous_chunks/chunk 5/train_subject6760_5.xml', 'positive_examples_anonymous_chunks/chunk 6/train_subject6760_6.xml', 'positive_examples_anonymous_chunks/chunk 7/train_subject6760_7.xml', 'positive_examples_anonymous_chunks/chunk 8/train_subject6760_8.xml', 'positive_examples_anonymous_chunks/chunk 9/train_subject6760_9.xml']\n",
      "<INDIVIDUAL>\n",
      "<ID>train_subject6760</ID>\n",
      "<WRITING>\n",
      "\t<TITLE>   </TITLE>\n",
      "\t<DATE> 2014-07-03 20:10:46 </DATE>\n",
      "\t<INFO> reddit post </INFO>\n",
      "\t<TEXT> I have to admit that Facebook seemed to have increased the quality of my life in the past. At this point, everything looks rather gloomy. In fact, I don't play any games other than the scrabble-esque Words With Friends. In the last few weeks, I have played my move with the first word that I can think of, without considering whether it is a high-point word, just to get rid of the notification. </TEXT>\n",
      "</WRITING>\n",
      "<WRITING>\n",
      "\t<TITLE>   </TITLE>\n",
      "\t<DATE> 2014-07-03 20:08:03 </DATE>\n",
      "\t<INFO> reddit post </INFO>\n",
      "\t<TEXT> The deterrent for deleting the account is that I have some friends who I keep in touch with. Of course, I can get their e-mails and communicate with them there. But seeing updates/photos/events has been important once in my life. I'm thinking that maybe I'll come out of it. Plus, I'm a musician. We NEED social networking to remain relevant\n"
     ]
    }
   ],
   "source": [
    "#Visualize Sample for debug\n",
    "\n",
    "# Pick first row\n",
    "row = df_all.iloc[0]\n",
    "print(\"Subject:\", row[\"subject_id\"])\n",
    "print(\"Label:\", row[\"label\"])\n",
    "print(\"Chunks:\", row[\"chunks\"])\n",
    "\n",
    "# Load first XML file for this subject\n",
    "first_chunk_path = row[\"chunks\"][0]\n",
    "tree = ET.parse(first_chunk_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "# For quick inspection, print raw XML text\n",
    "with open(first_chunk_path, \"r\") as f:\n",
    "    print(f.read()[:1000])  # print first 1000 chars only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bbd5173",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Functions for getting the cleaned text from the chunks\n",
    "WHITESPACE_RE = re.compile(r\"\\s+\")\n",
    "\n",
    "def _normalize_text(t: str) -> str:\n",
    "    t = t or \"\"\n",
    "    t = t.replace(\"\\u0000\", \"\")\n",
    "    t = WHITESPACE_RE.sub(\" \", t).strip()\n",
    "    return t\n",
    "\n",
    "def extract_texts_from_xml(path, min_chars=10):\n",
    "    \"\"\"\n",
    "    Given one subject chunk XMLs, extract posts.\n",
    "    Each <WRITING> becomes a post: TITLE + TEXT (concatenated).\n",
    "    Returns a list of strings.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(path)\n",
    "        root = tree.getroot()\n",
    "    except Exception as e:\n",
    "        print(f\"[XML-Parse-Error] {path}: {e}\")\n",
    "        return []\n",
    "\n",
    "    posts = []\n",
    "    for writing in root.findall(\"WRITING\"):\n",
    "        title = writing.findtext(\"TITLE\") or \"\"\n",
    "        text  = writing.findtext(\"TEXT\") or \"\"\n",
    "\n",
    "        combined = _normalize_text(f\"{title} {text}\".strip())\n",
    "        if len(combined) >= min_chars:\n",
    "            posts.append(combined)\n",
    "\n",
    "    return posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1097af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_manifest_to_posts(df_manifest):\n",
    "    \"\"\"\n",
    "    Expand manifest DataFrame into a DataFrame of posts.\n",
    "    Each row = one post with subject_id, label, text.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for _, row in df_manifest.iterrows():\n",
    "        subject_id = row[\"subject_id\"]\n",
    "        label = row[\"label\"]\n",
    "        chunk_paths = row[\"chunks\"]\n",
    "\n",
    "        for file_path in chunk_paths:\n",
    "            try:\n",
    "                tree = ET.parse(file_path)\n",
    "                root = tree.getroot()\n",
    "            except Exception as e:\n",
    "                print(f\"[XML-Parse-Error] {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "            for writing in root.findall(\"WRITING\"):\n",
    "                title = (writing.findtext(\"TITLE\") or \"\").strip()\n",
    "                text = (writing.findtext(\"TEXT\") or \"\").strip()\n",
    "\n",
    "                full_text = f\"{title}\\n{text}\" if title else text\n",
    "                full_text = full_text.strip()\n",
    "\n",
    "                if full_text:\n",
    "                    rows.append({\n",
    "                        \"subject_id\": subject_id,\n",
    "                        \"label\": label,\n",
    "                        \"text\": full_text\n",
    "                    })\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "143f3e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    subject_id     label                                               text\n",
      "0  subject6760  positive  I have to admit that Facebook seemed to have i...\n",
      "1  subject6760  positive  The deterrent for deleting the account is that...\n",
      "2  subject6760  positive                        That being gay is a choice.\n",
      "3  subject6760  positive  I'm from India where there is not too much awa...\n",
      "4  subject6760  positive  I completely agree. I have not accessed Facebo...\n",
      "294977 posts extracted\n"
     ]
    }
   ],
   "source": [
    "\n",
    "posts_df = explode_manifest_to_posts(df_all)\n",
    "#Visual inspection for debug\n",
    "print(posts_df.head())\n",
    "print(len(posts_df), \"posts extracted\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "250d10a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Subject  Sadness  Pessimism  Past failure  Loss of pleasure  \\\n",
      "0  train_subject4550        0          0             0                 0   \n",
      "1  train_subject4181        0          0             0                 0   \n",
      "2  train_subject8202        0          0             0                 0   \n",
      "3  train_subject6783        0          0             0                 0   \n",
      "4  train_subject1642        0          0             0                 0   \n",
      "\n",
      "   Guilty feelings  Punishment feelings  Self-dislike  Self-criticalness  \\\n",
      "0                0                    0             0                  0   \n",
      "1                0                    0             0                  0   \n",
      "2                0                    0             0                  0   \n",
      "3                0                    0             0                  0   \n",
      "4                0                    0             0                  0   \n",
      "\n",
      "   Suicidal thoughts or wishes  ...  Indecisiveness  Worthlessness  \\\n",
      "0                            0  ...               0              0   \n",
      "1                            0  ...               0              0   \n",
      "2                            0  ...               0              0   \n",
      "3                            0  ...               0              0   \n",
      "4                            0  ...               0              0   \n",
      "\n",
      "   Loss of energy  Changes in sleeping pattern  Irritability  \\\n",
      "0               0                            0             0   \n",
      "1               0                            0             0   \n",
      "2               0                            0             0   \n",
      "3               0                            0             0   \n",
      "4               0                            0             0   \n",
      "\n",
      "   Changes in appetite  Concentration difficulty  Tiredness or fatigue  \\\n",
      "0                    0                         0                     0   \n",
      "1                    0                         0                     0   \n",
      "2                    0                         0                     0   \n",
      "3                    0                         0                     0   \n",
      "4                    0                         0                     0   \n",
      "\n",
      "   Loss of interest in sex  Diagnosis  \n",
      "0                        0          0  \n",
      "1                        0          0  \n",
      "2                        0          0  \n",
      "3                        0          0  \n",
      "4                        0          0  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 486 entries, 0 to 485\n",
      "Data columns (total 23 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   Subject                      486 non-null    object\n",
      " 1   Sadness                      486 non-null    int64 \n",
      " 2   Pessimism                    486 non-null    int64 \n",
      " 3   Past failure                 486 non-null    int64 \n",
      " 4   Loss of pleasure             486 non-null    int64 \n",
      " 5   Guilty feelings              486 non-null    int64 \n",
      " 6   Punishment feelings          486 non-null    int64 \n",
      " 7   Self-dislike                 486 non-null    int64 \n",
      " 8   Self-criticalness            486 non-null    int64 \n",
      " 9   Suicidal thoughts or wishes  486 non-null    int64 \n",
      " 10  Crying                       486 non-null    int64 \n",
      " 11  Agitation                    486 non-null    int64 \n",
      " 12  Loss of interest             486 non-null    int64 \n",
      " 13  Indecisiveness               486 non-null    int64 \n",
      " 14  Worthlessness                486 non-null    int64 \n",
      " 15  Loss of energy               486 non-null    int64 \n",
      " 16  Changes in sleeping pattern  486 non-null    int64 \n",
      " 17  Irritability                 486 non-null    int64 \n",
      " 18  Changes in appetite          486 non-null    int64 \n",
      " 19  Concentration difficulty     486 non-null    int64 \n",
      " 20  Tiredness or fatigue         486 non-null    int64 \n",
      " 21  Loss of interest in sex      486 non-null    int64 \n",
      " 22  Diagnosis                    486 non-null    int64 \n",
      "dtypes: int64(22), object(1)\n",
      "memory usage: 87.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Getting the excel\n",
    "# Path relative to notebook\n",
    "symptom_file = \"../data/processed/merged_questionnaires.csv\"\n",
    "\n",
    "symptoms_df = pd.read_csv(symptom_file)\n",
    "\n",
    "#visual inspection\n",
    "print(symptoms_df.head())\n",
    "print(symptoms_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7498a653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Subject queries\n",
      "0  train_subject4550      []\n",
      "1  train_subject4181      []\n",
      "2  train_subject8202      []\n",
      "3  train_subject6783      []\n",
      "4  train_subject1642      []\n",
      "               Subject                                            queries\n",
      "122  train_subject7329  [Changes in sleeping pattern, Changes in appet...\n"
     ]
    }
   ],
   "source": [
    "# Function to create symptom queries for each subject (only symptoms = 1)\n",
    "def subject_symptom_queries(row):\n",
    "    return [\n",
    "        col.replace(\"_\", \" \")  # nicer text\n",
    "        for col in symptoms_df.columns\n",
    "        if col != \"subject_id\" and row[col] == 1\n",
    "    ]\n",
    "\n",
    "symptoms_df[\"queries\"] = symptoms_df.apply(subject_symptom_queries, axis=1)\n",
    "\n",
    "# Visual inspection\n",
    "print(symptoms_df[[\"Subject\", \"queries\"]].head())\n",
    "print(symptoms_df.loc[[122], [\"Subject\", \"queries\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea2a445e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    subject_id     label                                               text  \\\n",
      "0  subject6760  positive  I have to admit that Facebook seemed to have i...   \n",
      "1  subject6760  positive  The deterrent for deleting the account is that...   \n",
      "2  subject6760  positive                        That being gay is a choice.   \n",
      "3  subject6760  positive  I'm from India where there is not too much awa...   \n",
      "4  subject6760  positive  I completely agree. I have not accessed Facebo...   \n",
      "\n",
      "   Sadness  Pessimism  Past failure  Loss of pleasure  Guilty feelings  \\\n",
      "0        0          1             1                 0                1   \n",
      "1        0          1             1                 0                1   \n",
      "2        0          1             1                 0                1   \n",
      "3        0          1             1                 0                1   \n",
      "4        0          1             1                 0                1   \n",
      "\n",
      "   Punishment feelings  Self-dislike  ...  Worthlessness  Loss of energy  \\\n",
      "0                    1             1  ...              1               0   \n",
      "1                    1             1  ...              1               0   \n",
      "2                    1             1  ...              1               0   \n",
      "3                    1             1  ...              1               0   \n",
      "4                    1             1  ...              1               0   \n",
      "\n",
      "   Changes in sleeping pattern  Irritability  Changes in appetite  \\\n",
      "0                            0             0                    0   \n",
      "1                            0             0                    0   \n",
      "2                            0             0                    0   \n",
      "3                            0             0                    0   \n",
      "4                            0             0                    0   \n",
      "\n",
      "   Concentration difficulty  Tiredness or fatigue  Loss of interest in sex  \\\n",
      "0                         0                     0                        0   \n",
      "1                         0                     0                        0   \n",
      "2                         0                     0                        0   \n",
      "3                         0                     0                        0   \n",
      "4                         0                     0                        0   \n",
      "\n",
      "   Diagnosis                                            queries  \n",
      "0          1  [Pessimism, Past failure, Guilty feelings, Pun...  \n",
      "1          1  [Pessimism, Past failure, Guilty feelings, Pun...  \n",
      "2          1  [Pessimism, Past failure, Guilty feelings, Pun...  \n",
      "3          1  [Pessimism, Past failure, Guilty feelings, Pun...  \n",
      "4          1  [Pessimism, Past failure, Guilty feelings, Pun...  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "486\n",
      "486\n"
     ]
    }
   ],
   "source": [
    "#MERGE\n",
    "# Fix column name\n",
    "symptoms_df = symptoms_df.rename(columns={\"Subject\": \"subject_id\"})\n",
    "\n",
    "# Strip the \"train_\" prefix\n",
    "symptoms_df[\"subject_id\"] = symptoms_df[\"subject_id\"].str.replace(r\"^train_\", \"\", regex=True)\n",
    "\n",
    "#merge on user id\n",
    "merged_df = posts_df.merge(\n",
    "    symptoms_df[[\"subject_id\"] + [c for c in symptoms_df.columns if c not in [\"subject_id\"]]],\n",
    "    on=\"subject_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "print(merged_df.head())\n",
    "print(symptoms_df[\"subject_id\"].nunique())\n",
    "print(merged_df[\"subject_id\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "328b65bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Using MacBook GPU (MPS)\n",
      "SBERT model device: mps:0\n"
     ]
    }
   ],
   "source": [
    "# Load SBERT model (can change later to another one)\n",
    "sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Check if GPU is available and move model to GPU\n",
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "    print(\"✓ Using MacBook GPU (MPS)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(\"✓ Using CUDA GPU\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"⚠ Using CPU (this will be slow)\")\n",
    "\n",
    "# Move model to device\n",
    "sbert_model = sbert_model.to(device)\n",
    "print(f\"SBERT model device: {sbert_model.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6oh5fue966e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings for 21 concepts...\n",
      "Concept embeddings shape: torch.Size([21, 384])\n"
     ]
    }
   ],
   "source": [
    "# Create concept embeddings for retrieval\n",
    "# Use the 21 BDI-II concept names from the questionnaire\n",
    "concept_names = [\n",
    "    \"Sadness\", \"Pessimism\", \"Past failure\", \"Loss of pleasure\",\n",
    "    \"Guilty feelings\", \"Punishment feelings\", \"Self-dislike\", \"Self-criticalness\",\n",
    "    \"Suicidal thoughts or wishes\", \"Crying\", \"Agitation\", \"Loss of interest\",\n",
    "    \"Indecisiveness\", \"Worthlessness\", \"Loss of energy\", \"Changes in sleeping pattern\",\n",
    "    \"Irritability\", \"Changes in appetite\", \"Concentration difficulty\",\n",
    "    \"Tiredness or fatigue\", \"Loss of interest in sex\"\n",
    "]\n",
    "\n",
    "print(f\"Creating embeddings for {len(concept_names)} concepts...\")\n",
    "concept_embeddings = sbert_model.encode(concept_names, convert_to_tensor=True)\n",
    "print(f\"Concept embeddings shape: {concept_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4457dd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_posts_for_subject(subject_id, symptoms_df, posts_df, k=5, n_fallback=5):\n",
    "    \"\"\"\n",
    "    Retrieve posts for one subject based on SBERT similarity with symptoms or fallback to random sampling if no symptoms are present.\n",
    "    \"\"\"\n",
    "    # --- 1. get subject's queries\n",
    "    subj_row = symptoms_df[symptoms_df[\"subject_id\"] == subject_id].iloc[0]\n",
    "    queries = subj_row[\"queries\"]\n",
    "\n",
    "    # --- 2. get subject's posts\n",
    "    subj_posts = posts_df[posts_df[\"subject_id\"] == subject_id][\"text\"].tolist()\n",
    "    if len(subj_posts) == 0:\n",
    "        return []  # no posts at all for this subject\n",
    "\n",
    "    # --- 3. if no queries → fallback\n",
    "    if len(queries) == 0:\n",
    "        return list(np.random.choice(subj_posts, size=min(n_fallback, len(subj_posts)), replace=False))\n",
    "\n",
    "    # --- 4. embed queries + posts\n",
    "    query_embs = sbert_model.encode(queries, convert_to_tensor=True)\n",
    "    post_embs = sbert_model.encode(subj_posts, convert_to_tensor=True)\n",
    "\n",
    "    # --- 5. cosine similarity\n",
    "    cos_scores = util.cos_sim(query_embs, post_embs)  # shape [n_queries, n_posts]\n",
    "\n",
    "    # --- 6. select top-k posts per query\n",
    "    retrieved_posts = set()\n",
    "    for i, q in enumerate(queries):\n",
    "        top_results = np.argpartition(-cos_scores[i].cpu().numpy(), range(k))[:k]\n",
    "        for idx in top_results:\n",
    "            retrieved_posts.add(subj_posts[idx])\n",
    "\n",
    "    return list(retrieved_posts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee0eabfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    subject_id  label                                               text\n",
      "0  subject4550      0                                    Wonderful work!\n",
      "1  subject4550      0                              Travelling in Titanic\n",
      "2  subject4550      0  Israeli premier criticizes world's 'silence' o...\n",
      "3  subject4550      0                  Fantastic Leadership and Ideology\n",
      "4  subject4550      0                          Leon Keer - 3D Street Art\n"
     ]
    }
   ],
   "source": [
    "retrieved_data = []\n",
    "\n",
    "for subject_id in symptoms_df[\"subject_id\"]:\n",
    "    posts = retrieve_posts_for_subject(subject_id, symptoms_df, posts_df, k=5, n_fallback=5)\n",
    "    for p in posts:\n",
    "        retrieved_data.append({\n",
    "            \"subject_id\": subject_id,\n",
    "            \"label\": symptoms_df.loc[symptoms_df[\"subject_id\"] == subject_id, \"Diagnosis\"].values[0],\n",
    "            \"text\": p\n",
    "        })\n",
    "\n",
    "retrieved_df = pd.DataFrame(retrieved_data)\n",
    "print(retrieved_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57a2731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "retrieved_df.to_csv(\"../data/processed/retrieved_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85e4898b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "486"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of unique subject IDs\n",
    "retrieved_df[\"subject_id\"].nunique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709f0465",
   "metadata": {},
   "source": [
    "Now I'll do the same but introducing some random post (possibly not relevant) as well, which should be better for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5330d326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_posts_for_subject_concept_sim(subject_id, posts_df, concept_embeddings, k=20):\n",
    "    \"\"\"\n",
    "    Retrieve top-k posts for a subject using concept-embedding similarity.\n",
    "    \n",
    "    Instead of using concept values to create queries, this function:\n",
    "    1. Embeds all posts for the subject\n",
    "    2. Computes cosine similarity between each post and ALL 21 concept embeddings\n",
    "    3. For each post, takes the max similarity across all concepts as the relevance score\n",
    "    4. Returns top-k posts with highest concept-relevance scores\n",
    "    \n",
    "    Args:\n",
    "        subject_id: Subject identifier\n",
    "        posts_df: DataFrame with all posts (must have 'subject_id' and 'text' columns)\n",
    "        concept_embeddings: Tensor of shape (21, embedding_dim) with concept embeddings\n",
    "        k: Number of posts to retrieve (default: 20)\n",
    "    \n",
    "    Returns:\n",
    "        List of k selected post texts\n",
    "    \"\"\"\n",
    "    # Get subject's posts\n",
    "    subj_posts = posts_df[posts_df[\"subject_id\"] == subject_id][\"text\"].tolist()\n",
    "    \n",
    "    if len(subj_posts) == 0:\n",
    "        return []\n",
    "    \n",
    "    # If subject has fewer posts than k, return all posts with padding\n",
    "    if len(subj_posts) <= k:\n",
    "        # Pad with random duplicates if necessary\n",
    "        if len(subj_posts) < k:\n",
    "            extra_needed = k - len(subj_posts)\n",
    "            padding = list(np.random.choice(subj_posts, size=extra_needed, replace=True))\n",
    "            return subj_posts + padding\n",
    "        else:\n",
    "            return subj_posts\n",
    "    \n",
    "    # Embed all subject's posts (this is the slow part - encoding hundreds of posts)\n",
    "    # Use a smaller batch size to see progress and avoid memory issues\n",
    "    post_embeddings = sbert_model.encode(\n",
    "        subj_posts, \n",
    "        convert_to_tensor=True, \n",
    "        batch_size=32,  # Smaller batch size for better progress\n",
    "        show_progress_bar=False  # Disable individual progress bars (too cluttered)\n",
    "    )\n",
    "    \n",
    "    # Compute cosine similarity: [num_posts, num_concepts]\n",
    "    cos_scores = util.cos_sim(post_embeddings, concept_embeddings)\n",
    "    \n",
    "    # For each post, take the maximum similarity across all concepts\n",
    "    # This gives us a relevance score for each post\n",
    "    max_sim_scores = cos_scores.max(dim=1).values.cpu().numpy()\n",
    "    \n",
    "    # Select top-k posts by relevance score\n",
    "    top_k_indices = np.argpartition(-max_sim_scores, range(min(k, len(subj_posts))))[:k]\n",
    "    \n",
    "    selected_posts = [subj_posts[i] for i in top_k_indices]\n",
    "    \n",
    "    return selected_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73a57cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving posts using concept-embedding similarity...\n",
      "Processing 486 subjects...\n",
      "  Processed 50/486 subjects (2.0min elapsed, ~17.6min remaining)\n",
      "  Processed 100/486 subjects (3.5min elapsed, ~13.6min remaining)\n",
      "  Processed 150/486 subjects (5.7min elapsed, ~12.7min remaining)\n",
      "  Processed 200/486 subjects (7.7min elapsed, ~11.0min remaining)\n",
      "  Processed 250/486 subjects (9.9min elapsed, ~9.4min remaining)\n",
      "  Processed 300/486 subjects (12.4min elapsed, ~7.7min remaining)\n",
      "  Processed 350/486 subjects (15.0min elapsed, ~5.8min remaining)\n",
      "  Processed 400/486 subjects (17.6min elapsed, ~3.8min remaining)\n",
      "  Processed 450/486 subjects (19.2min elapsed, ~1.5min remaining)\n",
      "\n",
      "Completed in 20.2 minutes\n",
      "\n",
      "Results:\n",
      "  Total retrieved posts: 14580\n",
      "  Unique subjects: 486\n",
      "  Posts per subject: 30.0\n",
      "\n",
      "First few rows:\n",
      "    subject_id  label                                               text\n",
      "0  subject4550      0                                            Sleepio\n",
      "1  subject4550      0              Really heart breaking... very weak...\n",
      "2  subject4550      0  The death of a loved one. I'm not prepared to ...\n",
      "3  subject4550      0  That people need constructive work to do, and ...\n",
      "4  subject4550      0         Allowing myself to become addicted to food\n"
     ]
    }
   ],
   "source": [
    "retrieved_data_concept_sim = []\n",
    "\n",
    "print(\"Retrieving posts using concept-embedding similarity...\")\n",
    "print(f\"Processing {len(symptoms_df['subject_id'])} subjects...\")\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for idx, subject_id in enumerate(symptoms_df[\"subject_id\"]):\n",
    "    # Progress indicator every 50 subjects\n",
    "    if (idx + 1) % 50 == 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        avg_time = elapsed / (idx + 1)\n",
    "        remaining = avg_time * (len(symptoms_df['subject_id']) - idx - 1)\n",
    "        print(f\"  Processed {idx + 1}/{len(symptoms_df['subject_id'])} subjects \"\n",
    "              f\"({elapsed/60:.1f}min elapsed, ~{remaining/60:.1f}min remaining)\")\n",
    "    \n",
    "    posts = retrieve_posts_for_subject_concept_sim(\n",
    "        subject_id, \n",
    "        posts_df, \n",
    "        concept_embeddings, \n",
    "        k=30  # Retrieve top-30 concept-relevant posts\n",
    "    )\n",
    "    for p in posts:\n",
    "        retrieved_data_concept_sim.append({\n",
    "            \"subject_id\": subject_id,\n",
    "            \"label\": symptoms_df.loc[symptoms_df[\"subject_id\"] == subject_id, \"Diagnosis\"].values[0],\n",
    "            \"text\": p\n",
    "        })\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nCompleted in {total_time/60:.1f} minutes\")\n",
    "\n",
    "retrieved_concept_sim_df = pd.DataFrame(retrieved_data_concept_sim)\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Total retrieved posts: {len(retrieved_concept_sim_df)}\")\n",
    "print(f\"  Unique subjects: {retrieved_concept_sim_df['subject_id'].nunique()}\")\n",
    "print(f\"  Posts per subject: {len(retrieved_concept_sim_df) / retrieved_concept_sim_df['subject_id'].nunique():.1f}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(retrieved_concept_sim_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d07a4851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ../data/processed/retrieved_noise_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "#save with new concept-embedding retrieval approach\n",
    "retrieved_concept_sim_df.to_csv(\"../data/processed/retrieved_noise_dataset.csv\", index=False)\n",
    "print(\"Saved to ../data/processed/retrieved_noise_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f5f2a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Class distribution (concept-embedding retrieval) ===\n",
      "label\n",
      "0    403\n",
      "1     83\n",
      "Name: subject_id, dtype: int64\n",
      "\n",
      "Total subjects: 486\n",
      "Posts per subject: 30.0\n"
     ]
    }
   ],
   "source": [
    "# Check balance and final stats\n",
    "print(\"=== Class distribution (concept-embedding retrieval) ===\")\n",
    "print(retrieved_concept_sim_df.groupby(\"label\")[\"subject_id\"].nunique())\n",
    "print(f\"\\nTotal subjects: {retrieved_concept_sim_df['subject_id'].nunique()}\")\n",
    "print(f\"Posts per subject: {len(retrieved_concept_sim_df) / retrieved_concept_sim_df['subject_id'].nunique():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43dbb1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "486"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_concept_sim_df[\"subject_id\"].nunique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "38concept_embedding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
