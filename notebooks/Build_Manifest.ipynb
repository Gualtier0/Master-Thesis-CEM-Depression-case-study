{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2470cd1",
   "metadata": {},
   "source": [
    "# Build Manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9c53b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import json\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2313de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Paths ---\n",
    "POS_BASE = \"positive_examples_anonymous_chunks\"\n",
    "NEG_BASE = \"negative_examples_anonymous_chunks\"\n",
    "\n",
    "# Using regex to extract subject and chunk number\n",
    "SUBJECT_RE = re.compile(r\"subject(\\d+)\", re.IGNORECASE)\n",
    "CHUNK_RE   = re.compile(r\"_(\\d+)$\")   # trailing _<chunkid>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7777986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_name(filename):\n",
    "    \"\"\"\n",
    "    Parse filenames like 'train_subject7488_1.xml'\n",
    "    Returns:\n",
    "        tuple: (subject_id, chunk_id)\n",
    "    \"\"\"\n",
    "    basename_no_ext = os.path.splitext(filename)[0]  # e.g. 'train_subject7488_1'\n",
    "    parts = basename_no_ext.split(\"_\")               # ['train', 'subject7488', '1']\n",
    "\n",
    "    subject_id = parts[1]   # 'subject7488'\n",
    "    chunk_id = int(parts[2])  # '1' -> 1\n",
    "\n",
    "    return subject_id, chunk_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0513056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_manifest(base_folder, label):\n",
    "    \"\"\"\n",
    "    Build a manifest DataFrame:\n",
    "    - Each row = one subject\n",
    "    - Columns: subject_id, chunks (list of file paths), label\n",
    "    \"\"\"\n",
    "    manifest = {}\n",
    "\n",
    "    # find ALL xml files recursively\n",
    "    pattern = os.path.join(base_folder, \"**\", \"*.xml\")\n",
    "    all_files = glob.glob(pattern, recursive=True)\n",
    "\n",
    "    for filepath in all_files:\n",
    "        filename = os.path.basename(filepath)\n",
    "        subject_id, chunk_id = parse_name(filename)\n",
    "\n",
    "        if subject_id not in manifest:\n",
    "            manifest[subject_id] = []\n",
    "        manifest[subject_id].append(filepath)\n",
    "\n",
    "    # build DataFrame\n",
    "    df = pd.DataFrame([\n",
    "        {\"subject_id\": subject, \"chunks\": sorted(files), \"label\": label}\n",
    "        for subject, files in manifest.items()\n",
    "    ])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c459502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    subject_id                                             chunks     label\n",
      "0  subject6760  [positive_examples_anonymous_chunks/chunk 1/tr...  positive\n",
      "1   subject127  [positive_examples_anonymous_chunks/chunk 1/tr...  positive\n",
      "2  subject7326  [positive_examples_anonymous_chunks/chunk 1/tr...  positive\n",
      "3  subject2712  [positive_examples_anonymous_chunks/chunk 1/tr...  positive\n",
      "4  subject2252  [positive_examples_anonymous_chunks/chunk 1/tr...  positive\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 486 entries, 0 to 485\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   subject_id  486 non-null    object\n",
      " 1   chunks      486 non-null    object\n",
      " 2   label       486 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 11.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_pos = build_manifest(POS_BASE, \"positive\")\n",
    "df_neg = build_manifest(NEG_BASE, \"negative\")\n",
    "\n",
    "df_all = pd.concat([df_pos, df_neg], ignore_index=True)\n",
    "\n",
    "print(df_all.head())\n",
    "print(df_all.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e17e699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: subject6760\n",
      "Label: positive\n",
      "Chunks: ['positive_examples_anonymous_chunks/chunk 1/train_subject6760_1.xml', 'positive_examples_anonymous_chunks/chunk 10/train_subject6760_10.xml', 'positive_examples_anonymous_chunks/chunk 2/train_subject6760_2.xml', 'positive_examples_anonymous_chunks/chunk 3/train_subject6760_3.xml', 'positive_examples_anonymous_chunks/chunk 4/train_subject6760_4.xml', 'positive_examples_anonymous_chunks/chunk 5/train_subject6760_5.xml', 'positive_examples_anonymous_chunks/chunk 6/train_subject6760_6.xml', 'positive_examples_anonymous_chunks/chunk 7/train_subject6760_7.xml', 'positive_examples_anonymous_chunks/chunk 8/train_subject6760_8.xml', 'positive_examples_anonymous_chunks/chunk 9/train_subject6760_9.xml']\n",
      "<INDIVIDUAL>\n",
      "<ID>train_subject6760</ID>\n",
      "<WRITING>\n",
      "\t<TITLE>   </TITLE>\n",
      "\t<DATE> 2014-07-03 20:10:46 </DATE>\n",
      "\t<INFO> reddit post </INFO>\n",
      "\t<TEXT> I have to admit that Facebook seemed to have increased the quality of my life in the past. At this point, everything looks rather gloomy. In fact, I don't play any games other than the scrabble-esque Words With Friends. In the last few weeks, I have played my move with the first word that I can think of, without considering whether it is a high-point word, just to get rid of the notification. </TEXT>\n",
      "</WRITING>\n",
      "<WRITING>\n",
      "\t<TITLE>   </TITLE>\n",
      "\t<DATE> 2014-07-03 20:08:03 </DATE>\n",
      "\t<INFO> reddit post </INFO>\n",
      "\t<TEXT> The deterrent for deleting the account is that I have some friends who I keep in touch with. Of course, I can get their e-mails and communicate with them there. But seeing updates/photos/events has been important once in my life. I'm thinking that maybe I'll come out of it. Plus, I'm a musician. We NEED social networking to remain relevant\n"
     ]
    }
   ],
   "source": [
    "#Visualize Sample for debug\n",
    "\n",
    "# Pick first row\n",
    "row = df_all.iloc[0]\n",
    "print(\"Subject:\", row[\"subject_id\"])\n",
    "print(\"Label:\", row[\"label\"])\n",
    "print(\"Chunks:\", row[\"chunks\"])\n",
    "\n",
    "# Load first XML file for this subject\n",
    "first_chunk_path = row[\"chunks\"][0]\n",
    "tree = ET.parse(first_chunk_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "# For quick inspection, print raw XML text\n",
    "with open(first_chunk_path, \"r\") as f:\n",
    "    print(f.read()[:1000])  # print first 1000 chars only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbd5173",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Functions for getting the cleaned text from the chunks\n",
    "WHITESPACE_RE = re.compile(r\"\\s+\")\n",
    "\n",
    "def _normalize_text(t: str) -> str:\n",
    "    t = t or \"\"\n",
    "    t = t.replace(\"\\u0000\", \"\")\n",
    "    t = WHITESPACE_RE.sub(\" \", t).strip()\n",
    "    return t\n",
    "\n",
    "def extract_texts_from_xml(path, min_chars=10):\n",
    "    \"\"\"\n",
    "    Given one subject chunk XMLs, extract posts.\n",
    "    Each <WRITING> becomes a post: TITLE + TEXT (concatenated).\n",
    "    Returns a list of strings.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(path)\n",
    "        root = tree.getroot()\n",
    "    except Exception as e:\n",
    "        print(f\"[XML-Parse-Error] {path}: {e}\")\n",
    "        return []\n",
    "\n",
    "    posts = []\n",
    "    for writing in root.findall(\"WRITING\"):\n",
    "        title = writing.findtext(\"TITLE\") or \"\"\n",
    "        text  = writing.findtext(\"TEXT\") or \"\"\n",
    "\n",
    "        combined = _normalize_text(f\"{title} {text}\".strip())\n",
    "        if len(combined) >= min_chars:\n",
    "            posts.append(combined)\n",
    "\n",
    "    return posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1097af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_manifest_to_posts(df_manifest):\n",
    "    \"\"\"\n",
    "    Expand manifest DataFrame into a DataFrame of posts.\n",
    "    Each row = one post with subject_id, label, text.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for _, row in df_manifest.iterrows():\n",
    "        subject_id = row[\"subject_id\"]\n",
    "        label = row[\"label\"]\n",
    "        chunk_paths = row[\"chunks\"]\n",
    "\n",
    "        for file_path in chunk_paths:\n",
    "            try:\n",
    "                tree = ET.parse(file_path)\n",
    "                root = tree.getroot()\n",
    "            except Exception as e:\n",
    "                print(f\"[XML-Parse-Error] {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "            for writing in root.findall(\"WRITING\"):\n",
    "                title = (writing.findtext(\"TITLE\") or \"\").strip()\n",
    "                text = (writing.findtext(\"TEXT\") or \"\").strip()\n",
    "\n",
    "                full_text = f\"{title}\\n{text}\" if title else text\n",
    "                full_text = full_text.strip()\n",
    "\n",
    "                if full_text:\n",
    "                    rows.append({\n",
    "                        \"subject_id\": subject_id,\n",
    "                        \"label\": label,\n",
    "                        \"text\": full_text\n",
    "                    })\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143f3e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    subject_id     label                                               text\n",
      "0  subject6760  positive  I have to admit that Facebook seemed to have i...\n",
      "1  subject6760  positive  The deterrent for deleting the account is that...\n",
      "2  subject6760  positive                        That being gay is a choice.\n",
      "3  subject6760  positive  I'm from India where there is not too much awa...\n",
      "4  subject6760  positive  I completely agree. I have not accessed Facebo...\n",
      "294977 posts extracted\n"
     ]
    }
   ],
   "source": [
    "\n",
    "posts_df = explode_manifest_to_posts(df_all)\n",
    "#Visual inspection for debug\n",
    "print(posts_df.head())\n",
    "print(len(posts_df), \"posts extracted\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250d10a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Subject  Sadness  Pessimism  Past failure  Loss of pleasure  \\\n",
      "0  train_subject4550        0          0             0                 0   \n",
      "1  train_subject4181        0          0             0                 0   \n",
      "2  train_subject8202        0          0             0                 0   \n",
      "3  train_subject6783        0          0             0                 0   \n",
      "4  train_subject1642        0          0             0                 0   \n",
      "\n",
      "   Guilty feelings  Punishment feelings  Self-dislike  Self-criticalness  \\\n",
      "0                0                    0             0                  0   \n",
      "1                0                    0             0                  0   \n",
      "2                0                    0             0                  0   \n",
      "3                0                    0             0                  0   \n",
      "4                0                    0             0                  0   \n",
      "\n",
      "   Suicidal thoughts or wishes  ...  Indecisiveness  Worthlessness  \\\n",
      "0                            0  ...               0              0   \n",
      "1                            0  ...               0              0   \n",
      "2                            0  ...               0              0   \n",
      "3                            0  ...               0              0   \n",
      "4                            0  ...               0              0   \n",
      "\n",
      "   Loss of energy  Changes in sleeping pattern  Irritability  \\\n",
      "0               0                            0             0   \n",
      "1               0                            0             0   \n",
      "2               0                            0             0   \n",
      "3               0                            0             0   \n",
      "4               0                            0             0   \n",
      "\n",
      "   Changes in appetite  Concentration difficulty  Tiredness or fatigue  \\\n",
      "0                    0                         0                     0   \n",
      "1                    0                         0                     0   \n",
      "2                    0                         0                     0   \n",
      "3                    0                         0                     0   \n",
      "4                    0                         0                     0   \n",
      "\n",
      "   Loss of interest in sex  Diagnosis  \n",
      "0                        0          0  \n",
      "1                        0          0  \n",
      "2                        0          0  \n",
      "3                        0          0  \n",
      "4                        0          0  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 486 entries, 0 to 485\n",
      "Data columns (total 23 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   Subject                      486 non-null    object\n",
      " 1   Sadness                      486 non-null    int64 \n",
      " 2   Pessimism                    486 non-null    int64 \n",
      " 3   Past failure                 486 non-null    int64 \n",
      " 4   Loss of pleasure             486 non-null    int64 \n",
      " 5   Guilty feelings              486 non-null    int64 \n",
      " 6   Punishment feelings          486 non-null    int64 \n",
      " 7   Self-dislike                 486 non-null    int64 \n",
      " 8   Self-criticalness            486 non-null    int64 \n",
      " 9   Suicidal thoughts or wishes  486 non-null    int64 \n",
      " 10  Crying                       486 non-null    int64 \n",
      " 11  Agitation                    486 non-null    int64 \n",
      " 12  Loss of interest             486 non-null    int64 \n",
      " 13  Indecisiveness               486 non-null    int64 \n",
      " 14  Worthlessness                486 non-null    int64 \n",
      " 15  Loss of energy               486 non-null    int64 \n",
      " 16  Changes in sleeping pattern  486 non-null    int64 \n",
      " 17  Irritability                 486 non-null    int64 \n",
      " 18  Changes in appetite          486 non-null    int64 \n",
      " 19  Concentration difficulty     486 non-null    int64 \n",
      " 20  Tiredness or fatigue         486 non-null    int64 \n",
      " 21  Loss of interest in sex      486 non-null    int64 \n",
      " 22  Diagnosis                    486 non-null    int64 \n",
      "dtypes: int64(22), object(1)\n",
      "memory usage: 87.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Getting the excel\n",
    "# Path relative to notebook\n",
    "symptom_file = \"../data/processed/merged_questionnaires.csv\"\n",
    "\n",
    "symptoms_df = pd.read_csv(symptom_file)\n",
    "\n",
    "#visual inspection\n",
    "print(symptoms_df.head())\n",
    "print(symptoms_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7498a653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Subject queries\n",
      "0  train_subject4550      []\n",
      "1  train_subject4181      []\n",
      "2  train_subject8202      []\n",
      "3  train_subject6783      []\n",
      "4  train_subject1642      []\n",
      "               Subject                                            queries\n",
      "122  train_subject7329  [Changes in sleeping pattern, Changes in appet...\n"
     ]
    }
   ],
   "source": [
    "# Function to create symptom queries for each subject (only symptoms = 1)\n",
    "def subject_symptom_queries(row):\n",
    "    return [\n",
    "        col.replace(\"_\", \" \")  # nicer text\n",
    "        for col in symptoms_df.columns\n",
    "        if col != \"subject_id\" and row[col] == 1\n",
    "    ]\n",
    "\n",
    "symptoms_df[\"queries\"] = symptoms_df.apply(subject_symptom_queries, axis=1)\n",
    "\n",
    "# Visual inspection\n",
    "print(symptoms_df[[\"Subject\", \"queries\"]].head())\n",
    "print(symptoms_df.loc[[122], [\"Subject\", \"queries\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2a445e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    subject_id     label                                               text  \\\n",
      "0  subject6760  positive  I have to admit that Facebook seemed to have i...   \n",
      "1  subject6760  positive  The deterrent for deleting the account is that...   \n",
      "2  subject6760  positive                        That being gay is a choice.   \n",
      "3  subject6760  positive  I'm from India where there is not too much awa...   \n",
      "4  subject6760  positive  I completely agree. I have not accessed Facebo...   \n",
      "\n",
      "   Sadness  Pessimism  Past failure  Loss of pleasure  Guilty feelings  \\\n",
      "0        0          1             1                 0                1   \n",
      "1        0          1             1                 0                1   \n",
      "2        0          1             1                 0                1   \n",
      "3        0          1             1                 0                1   \n",
      "4        0          1             1                 0                1   \n",
      "\n",
      "   Punishment feelings  Self-dislike  ...  Worthlessness  Loss of energy  \\\n",
      "0                    1             1  ...              1               0   \n",
      "1                    1             1  ...              1               0   \n",
      "2                    1             1  ...              1               0   \n",
      "3                    1             1  ...              1               0   \n",
      "4                    1             1  ...              1               0   \n",
      "\n",
      "   Changes in sleeping pattern  Irritability  Changes in appetite  \\\n",
      "0                            0             0                    0   \n",
      "1                            0             0                    0   \n",
      "2                            0             0                    0   \n",
      "3                            0             0                    0   \n",
      "4                            0             0                    0   \n",
      "\n",
      "   Concentration difficulty  Tiredness or fatigue  Loss of interest in sex  \\\n",
      "0                         0                     0                        0   \n",
      "1                         0                     0                        0   \n",
      "2                         0                     0                        0   \n",
      "3                         0                     0                        0   \n",
      "4                         0                     0                        0   \n",
      "\n",
      "   Diagnosis                                            queries  \n",
      "0          1  [Pessimism, Past failure, Guilty feelings, Pun...  \n",
      "1          1  [Pessimism, Past failure, Guilty feelings, Pun...  \n",
      "2          1  [Pessimism, Past failure, Guilty feelings, Pun...  \n",
      "3          1  [Pessimism, Past failure, Guilty feelings, Pun...  \n",
      "4          1  [Pessimism, Past failure, Guilty feelings, Pun...  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "486\n",
      "486\n"
     ]
    }
   ],
   "source": [
    "#MERGE\n",
    "# Fix column name\n",
    "symptoms_df = symptoms_df.rename(columns={\"Subject\": \"subject_id\"})\n",
    "\n",
    "# Strip the \"train_\" prefix\n",
    "symptoms_df[\"subject_id\"] = symptoms_df[\"subject_id\"].str.replace(r\"^train_\", \"\", regex=True)\n",
    "\n",
    "#merge on user id\n",
    "merged_df = posts_df.merge(\n",
    "    symptoms_df[[\"subject_id\"] + [c for c in symptoms_df.columns if c not in [\"subject_id\"]]],\n",
    "    on=\"subject_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "print(merged_df.head())\n",
    "print(symptoms_df[\"subject_id\"].nunique())\n",
    "print(merged_df[\"subject_id\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "328b65bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SBERT model (can change later to another one)\n",
    "sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4457dd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_posts_for_subject(subject_id, symptoms_df, posts_df, k=5, n_fallback=5):\n",
    "    \"\"\"\n",
    "    Retrieve posts for one subject based on SBERT similarity with symptoms or fallback to random sampling if no symptoms are present.\n",
    "    \"\"\"\n",
    "    # --- 1. get subject's queries\n",
    "    subj_row = symptoms_df[symptoms_df[\"subject_id\"] == subject_id].iloc[0]\n",
    "    queries = subj_row[\"queries\"]\n",
    "\n",
    "    # --- 2. get subject's posts\n",
    "    subj_posts = posts_df[posts_df[\"subject_id\"] == subject_id][\"text\"].tolist()\n",
    "    if len(subj_posts) == 0:\n",
    "        return []  # no posts at all for this subject\n",
    "\n",
    "    # --- 3. if no queries → fallback\n",
    "    if len(queries) == 0:\n",
    "        return list(np.random.choice(subj_posts, size=min(n_fallback, len(subj_posts)), replace=False))\n",
    "\n",
    "    # --- 4. embed queries + posts\n",
    "    query_embs = sbert_model.encode(queries, convert_to_tensor=True)\n",
    "    post_embs = sbert_model.encode(subj_posts, convert_to_tensor=True)\n",
    "\n",
    "    # --- 5. cosine similarity\n",
    "    cos_scores = util.cos_sim(query_embs, post_embs)  # shape [n_queries, n_posts]\n",
    "\n",
    "    # --- 6. select top-k posts per query\n",
    "    retrieved_posts = set()\n",
    "    for i, q in enumerate(queries):\n",
    "        top_results = np.argpartition(-cos_scores[i].cpu().numpy(), range(k))[:k]\n",
    "        for idx in top_results:\n",
    "            retrieved_posts.add(subj_posts[idx])\n",
    "\n",
    "    return list(retrieved_posts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee0eabfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    subject_id  label                                               text\n",
      "0  subject4550      0                                 Amazing Street Art\n",
      "1  subject4550      0  I want to say just one thing after this that \"...\n",
      "2  subject4550      0               Autorickshaw Strike Hits Mumbai Hard\n",
      "3  subject4550      0  Oscar Pistorius will be released from prison f...\n",
      "4  subject4550      0  My Greatest fear in my life is - being jobless...\n"
     ]
    }
   ],
   "source": [
    "retrieved_data = []\n",
    "\n",
    "for subject_id in symptoms_df[\"subject_id\"]:\n",
    "    posts = retrieve_posts_for_subject(subject_id, symptoms_df, posts_df, k=5, n_fallback=5)\n",
    "    for p in posts:\n",
    "        retrieved_data.append({\n",
    "            \"subject_id\": subject_id,\n",
    "            \"label\": symptoms_df.loc[symptoms_df[\"subject_id\"] == subject_id, \"Diagnosis\"].values[0],\n",
    "            \"text\": p\n",
    "        })\n",
    "\n",
    "retrieved_df = pd.DataFrame(retrieved_data)\n",
    "print(retrieved_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57a2731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "retrieved_df.to_csv(\"../data/processed/retrieved_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85e4898b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "486"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of unique subject IDs\n",
    "retrieved_df[\"subject_id\"].nunique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709f0465",
   "metadata": {},
   "source": [
    "Now I'll do the same but introducing some random post (possibly not relevant) as well, which should be better for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5330d326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_posts_for_subject_noise(subject_id, symptoms_df, posts_df, k_relevant=15, n_random=5):\n",
    "    \"\"\"\n",
    "    Retrieve posts for one subject:\n",
    "    - Top-k SBERT-relevant posts\n",
    "    - Plus n_random random posts from the remaining pool\n",
    "    Always pads so total = k_relevant + n_random (if enough posts exist).\n",
    "    \"\"\"\n",
    "    target_total = k_relevant + n_random\n",
    "\n",
    "    # --- 1. get subject's queries\n",
    "    subj_row = symptoms_df[symptoms_df[\"subject_id\"] == subject_id].iloc[0]\n",
    "    queries = subj_row[\"queries\"]\n",
    "\n",
    "    # --- 2. get subject's posts\n",
    "    subj_posts = posts_df[posts_df[\"subject_id\"] == subject_id][\"text\"].tolist()\n",
    "    if len(subj_posts) == 0:\n",
    "        return []  # no posts at all\n",
    "\n",
    "    retrieved_posts = set()\n",
    "\n",
    "    # --- 3. if no queries → only random\n",
    "    if len(queries) > 0:\n",
    "        # --- embed queries + posts\n",
    "        query_embs = sbert_model.encode(queries, convert_to_tensor=True)\n",
    "        post_embs = sbert_model.encode(subj_posts, convert_to_tensor=True)\n",
    "\n",
    "        # --- cosine similarity\n",
    "        cos_scores = util.cos_sim(query_embs, post_embs).cpu().numpy()\n",
    "\n",
    "        # --- select top-k posts per query\n",
    "        for i in range(len(queries)):\n",
    "            top_results = np.argpartition(-cos_scores[i], range(min(k_relevant, len(subj_posts))))[:k_relevant]\n",
    "            for idx in top_results:\n",
    "                retrieved_posts.add(subj_posts[idx])\n",
    "\n",
    "    # --- 4. sample random from remaining posts\n",
    "    remaining_posts = list(set(subj_posts) - retrieved_posts)\n",
    "    if remaining_posts and n_random > 0:\n",
    "        n_to_sample = min(n_random, len(remaining_posts))\n",
    "        random_posts = np.random.choice(remaining_posts, size=n_to_sample, replace=False)\n",
    "        retrieved_posts.update(random_posts)\n",
    "\n",
    "    # --- 5. pad if fewer than target_total\n",
    "    retrieved_posts = list(retrieved_posts)\n",
    "    if len(retrieved_posts) < target_total:\n",
    "        # sample with replacement if necessary\n",
    "        extra_needed = target_total - len(retrieved_posts)\n",
    "        padding = np.random.choice(subj_posts, size=extra_needed, replace=True)\n",
    "        retrieved_posts.extend(padding.tolist())\n",
    "\n",
    "    # --- 6. if more than target_total (possible if many relevant overlap across queries), truncate\n",
    "    if len(retrieved_posts) > target_total:\n",
    "        retrieved_posts = retrieved_posts[:target_total]\n",
    "\n",
    "    return retrieved_posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a57cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    subject_id  label                                               text\n",
      "0  subject4550      0                                             Pocket\n",
      "1  subject4550      0                                      So beautiful!\n",
      "2  subject4550      0  Australia's Chris Rogers to miss another Test ...\n",
      "3  subject4550      0  He need to go through gastic bypass surgery an...\n",
      "4  subject4550      0  Good gravy, I love this woman! She's as gifted...\n",
      "Total retrieved posts: 9720\n",
      "Unique subjects: 486\n"
     ]
    }
   ],
   "source": [
    "retrieved_data_noise = []\n",
    "\n",
    "for subject_id in symptoms_df[\"subject_id\"]:\n",
    "    posts = retrieve_posts_for_subject_noise(subject_id, symptoms_df, posts_df,\n",
    "                                       k_relevant=15,  # top-15 relevant (padded with random if <15)\n",
    "                                       n_random=5)    # plus 5 random \n",
    "    for p in posts:\n",
    "        retrieved_data_noise.append({\n",
    "            \"subject_id\": subject_id,\n",
    "            \"label\": symptoms_df.loc[symptoms_df[\"subject_id\"] == subject_id, \"Diagnosis\"].values[0],\n",
    "            \"text\": p\n",
    "        })\n",
    "\n",
    "retrieved_noise_df = pd.DataFrame(retrieved_data_noise)\n",
    "print(retrieved_noise_df.head())\n",
    "print(f\"Total retrieved posts: {len(retrieved_noise_df)}\")\n",
    "print(f\"Unique subjects: {retrieved_noise_df['subject_id'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d07a4851",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "retrieved_noise_df.to_csv(\"../data/processed/retrieved_noise_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8f5f2a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Class distribution in retrieved_df ===\n",
      "label\n",
      "0    403\n",
      "1     83\n",
      "Name: subject_id, dtype: int64\n",
      "=== Class distribution in retrieved_noise_df ===\n",
      "label\n",
      "0    403\n",
      "1     83\n",
      "Name: subject_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check balance of patients\n",
    "print(\"=== Class distribution in retrieved_df ===\")\n",
    "print(retrieved_df.groupby(\"label\")[\"subject_id\"].nunique())\n",
    "\n",
    "print(\"=== Class distribution in retrieved_noise_df ===\")\n",
    "print(retrieved_noise_df.groupby(\"label\")[\"subject_id\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "43dbb1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "486"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_noise_df[\"subject_id\"].nunique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "concept_embedding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
