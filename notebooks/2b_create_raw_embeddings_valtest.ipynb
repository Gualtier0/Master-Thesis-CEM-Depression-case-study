{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Create Raw Embeddings for Validation and Test Sets\n",
    "\n",
    "This notebook creates SBERT embeddings for validation and test subjects.\n",
    "\n",
    "Input:\n",
    "- `retrieved_test_validation.csv` - Validation posts (from 1b_Build_Test_Manifest)\n",
    "- `retrieved_test_test.csv` - Test posts (from 1b_Build_Test_Manifest)\n",
    "\n",
    "Output:\n",
    "- `subject_features_raw_validation.npz` - Validation embeddings\n",
    "- `subject_features_raw_test.npz` - Test embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SBERT model (same as training)\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "embed_dim = model.get_sentence_embedding_dimension()\n",
    "print(f\"Loaded SBERT '{MODEL_NAME}' â€” embedding dim = {embed_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "data_dir = os.path.join(project_root, \"data/processed\")\n",
    "\n",
    "val_csv = os.path.join(data_dir, \"retrieved_test_validation.csv\")\n",
    "test_csv = os.path.join(data_dir, \"retrieved_test_test.csv\")\n",
    "\n",
    "val_output = os.path.join(data_dir, \"subject_features_raw_validation.npz\")\n",
    "test_output = os.path.join(data_dir, \"subject_features_raw_test.npz\")\n",
    "\n",
    "print(f\"Validation CSV: {val_csv}\")\n",
    "print(f\"Test CSV: {test_csv}\")\n",
    "print(f\"Output directory: {data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embed_function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_from_csv(csv_path, output_path, dataset_name):\n",
    "    \"\"\"\n",
    "    Create embeddings from a CSV file with columns: subject_id, label, text\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing {dataset_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Load CSV\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"Error: Input file not found at {csv_path}\")\n",
    "        return\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"Loaded {len(df)} posts for {df['subject_id'].nunique()} subjects\")\n",
    "    \n",
    "    # Encode all posts\n",
    "    texts = df[\"text\"].astype(str).tolist()\n",
    "    batch_size = 64\n",
    "    \n",
    "    print(\"Encoding posts...\")\n",
    "    embeddings = model.encode(\n",
    "        texts,\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True\n",
    "    )\n",
    "    print(f\"Encoded shape: {embeddings.shape}\")\n",
    "    \n",
    "    # Attach embeddings to dataframe\n",
    "    df = df.reset_index(drop=True)\n",
    "    df[\"emb\"] = list(embeddings)\n",
    "    \n",
    "    # Group by subject\n",
    "    subject_ids = df[\"subject_id\"].unique()\n",
    "    n_subjects = len(subject_ids)\n",
    "    \n",
    "    X_raw = []\n",
    "    subject_list = []\n",
    "    y = []\n",
    "    \n",
    "    print(f\"Grouping embeddings for {n_subjects} subjects...\")\n",
    "    for sid in subject_ids:\n",
    "        group_embs = np.vstack(df.loc[df[\"subject_id\"] == sid, \"emb\"].values)\n",
    "        X_raw.append(group_embs)\n",
    "        subject_list.append(sid)\n",
    "        \n",
    "        # Get label\n",
    "        y_val = int(df.loc[df[\"subject_id\"] == sid, \"label\"].iloc[0])\n",
    "        y.append(y_val)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X_raw = np.array(X_raw, dtype=object)\n",
    "    y = np.array(y, dtype=np.int64)\n",
    "    subject_ids_array = np.array(subject_list)\n",
    "    \n",
    "    print(f\"X_raw shape: {X_raw.shape}\")\n",
    "    if X_raw.shape[0] > 0:\n",
    "        print(f\"First subject embedding matrix shape: {X_raw[0].shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    print(f\"Label distribution: {np.bincount(y)}\")\n",
    "    \n",
    "    # Save\n",
    "    np.savez_compressed(\n",
    "        output_path,\n",
    "        X_raw=X_raw,\n",
    "        y=y,\n",
    "        subject_ids=subject_ids_array\n",
    "    )\n",
    "    \n",
    "    print(f\"Saved to {output_path}\")\n",
    "    print(f\"Done with {dataset_name}!\\n\")\n",
    "\n",
    "print(\"Embedding function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process_validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process validation set\n",
    "create_embeddings_from_csv(val_csv, val_output, \"VALIDATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process test set\n",
    "create_embeddings_from_csv(test_csv, test_output, \"TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load and verify saved files\n",
    "if os.path.exists(val_output):\n",
    "    val_data = np.load(val_output, allow_pickle=True)\n",
    "    print(f\"\\nValidation set:\")\n",
    "    print(f\"  - Subjects: {len(val_data['y'])}\")\n",
    "    print(f\"  - X_raw shape: {val_data['X_raw'].shape}\")\n",
    "    print(f\"  - First subject posts: {val_data['X_raw'][0].shape[0]}\")\n",
    "    print(f\"  - Embedding dim: {val_data['X_raw'][0].shape[1]}\")\n",
    "\n",
    "if os.path.exists(test_output):\n",
    "    test_data = np.load(test_output, allow_pickle=True)\n",
    "    print(f\"\\nTest set:\")\n",
    "    print(f\"  - Subjects: {len(test_data['y'])}\")\n",
    "    print(f\"  - X_raw shape: {test_data['X_raw'].shape}\")\n",
    "    print(f\"  - First subject posts: {test_data['X_raw'][0].shape[0]}\")\n",
    "    print(f\"  - Embedding dim: {test_data['X_raw'][0].shape[1]}\")\n",
    "\n",
    "print(\"\\nAll embeddings created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
