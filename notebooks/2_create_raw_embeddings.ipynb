{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec0d1f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: Create raw embeddings\n",
      "Loaded SBERT 'all-MiniLM-L6-v2' — embedding dim = 384\n",
      "Loaded dataset with 9720 posts.\n",
      "Encoding posts (this may take a moment)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc66a8c8fd34b56a642fcc815189fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: (9720, 384)\n",
      "Grouping embeddings for 486 subjects...\n",
      "Built X_raw object array with shape: (486, 20, 384)\n",
      "Shape of first subject's embedding matrix: (20, 384)\n",
      "Built y: (486,)\n",
      "Saved raw features to /Users/gualtieromarencoturi/Desktop/thesis/Master-Thesis-CEM-Depression-etc-case-study/data/processed/subject_features_raw.npz\n",
      "Finished: Create raw embeddings\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def create_raw_embeddings():\n",
    "    \"\"\"\n",
    "    This script encodes posts using a sentence transformer and saves the raw, \n",
    "    unaggregated embeddings for each subject.\n",
    "    The output is a .npz file containing:\n",
    "    - X_raw: A NumPy object array where each element is a (num_posts, embedding_dim) array for a subject.\n",
    "    - y: The corresponding labels.\n",
    "    - subject_ids: The subject IDs.\n",
    "    \"\"\"\n",
    "    print(\"Starting: Create raw embeddings\")\n",
    "\n",
    "    # Paths\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "    retrieved_path = os.path.join(project_root, \"data/processed/retrieved_noise_dataset.csv\")\n",
    "    out_dir = os.path.join(project_root, \"data/processed\")\n",
    "    feat_path = os.path.join(out_dir, \"subject_features_raw.npz\")\n",
    "\n",
    "    # Load model\n",
    "    MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "    model = SentenceTransformer(MODEL_NAME)\n",
    "    embed_dim = model.get_sentence_embedding_dimension()\n",
    "    print(f\"Loaded SBERT '{MODEL_NAME}' — embedding dim = {embed_dim}\")\n",
    "\n",
    "    # Load dataset\n",
    "    if not os.path.exists(retrieved_path):\n",
    "        print(f\"Error: Input file not found at {retrieved_path}\")\n",
    "        return\n",
    "    retrieved_df = pd.read_csv(retrieved_path)\n",
    "    print(f\"Loaded dataset with {len(retrieved_df)} posts.\")\n",
    "\n",
    "    # Encode all posts (batched)\n",
    "    texts = retrieved_df[\"text\"].astype(str).tolist()\n",
    "    batch_size = 64\n",
    "    print(\"Encoding posts (this may take a moment)...\")\n",
    "    embeddings = model.encode(\n",
    "        texts,\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True\n",
    "    )\n",
    "    print(\"Encoded:\", embeddings.shape)\n",
    "\n",
    "    # Attach embeddings back to retrieved_df\n",
    "    retrieved_df = retrieved_df.reset_index(drop=True)\n",
    "    retrieved_df[\"emb\"] = list(embeddings)\n",
    "\n",
    "    # Group embeddings by subject, but do not aggregate\n",
    "    subject_ids = retrieved_df[\"subject_id\"].unique()\n",
    "    n_subjects = len(subject_ids)\n",
    "\n",
    "    X_raw = []\n",
    "    subject_list = []\n",
    "    print(f\"Grouping embeddings for {n_subjects} subjects...\")\n",
    "\n",
    "    for sid in subject_ids:\n",
    "        group_embs = np.vstack(retrieved_df.loc[retrieved_df[\"subject_id\"] == sid, \"emb\"].values)\n",
    "        X_raw.append(group_embs)\n",
    "        subject_list.append(sid)\n",
    "\n",
    "    # Convert to a numpy object array\n",
    "    X_raw = np.array(X_raw, dtype=object)\n",
    "\n",
    "    print(\"Built X_raw object array with shape:\", X_raw.shape)\n",
    "    if X_raw.shape[0] > 0:\n",
    "        print(\"Shape of first subject's embedding matrix:\", X_raw[0].shape)\n",
    "\n",
    "    # Build y (label vector)\n",
    "    y = []\n",
    "    for sid in subject_list:\n",
    "        y_val = int(retrieved_df.loc[retrieved_df[\"subject_id\"] == sid, \"label\"].iloc[0])\n",
    "        y.append(y_val)\n",
    "    y = np.array(y, dtype=np.int64)\n",
    "    print(\"Built y:\", y.shape)\n",
    "\n",
    "    # Save the raw features to disk\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    np.savez_compressed(feat_path, X_raw=X_raw, y=y, subject_ids=np.array(subject_list))\n",
    "    print(f\"Saved raw features to {feat_path}\")\n",
    "    print(\"Finished: Create raw embeddings\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    create_raw_embeddings()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "38concept_embedding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
