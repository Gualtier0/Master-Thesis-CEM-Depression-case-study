{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc3cd65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d14c1bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix: (486, 1152)\n",
      "Labels: (486,) Positive rate: 0.17078189300411523\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load embeddings and labels\n",
    "data = np.load(\"../data/processed/subject_features.npz\")\n",
    "X = data[\"X\"]   # features\n",
    "y = data[\"y\"]   # labels (0 = control, 1 = depressed)\n",
    "\n",
    "print(\"Feature matrix:\", X.shape)\n",
    "print(\"Labels:\", y.shape, \"Positive rate:\", np.mean(y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "290f90a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 388 Val size: 98\n"
     ]
    }
   ],
   "source": [
    "# Train/validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape[0], \"Val size:\", X_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "685008c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val_tensor   = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor   = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "train_ds = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_ds   = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True) #shuffle then load 32 patients batches, \n",
    "val_loader   = DataLoader(val_ds, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40070db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1152, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define simple MLP classifier \n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128): #might try 64 or 256 hidden dim\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, 2)   # binary classification\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = MLPClassifier(input_dim=X.shape[1])\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e740035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss=0.4542, val acc=0.9184\n",
      "Epoch 2: train loss=0.1536, val acc=0.8980\n",
      "Epoch 3: train loss=0.0784, val acc=0.9082\n",
      "Epoch 4: train loss=0.0401, val acc=0.9082\n",
      "Epoch 5: train loss=0.0255, val acc=0.9082\n",
      "Epoch 6: train loss=0.0131, val acc=0.9184\n",
      "Epoch 7: train loss=0.0104, val acc=0.9184\n",
      "Epoch 8: train loss=0.0074, val acc=0.9184\n",
      "Epoch 9: train loss=0.0068, val acc=0.9184\n",
      "Epoch 10: train loss=0.0052, val acc=0.9184\n"
     ]
    }
   ],
   "source": [
    "# Training setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 10\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader.dataset)\n",
    "\n",
    "    # Validation \n",
    "    model.eval()\n",
    "    all_preds, all_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_true.extend(yb.cpu().numpy())\n",
    "\n",
    "    val_acc = accuracy_score(all_true, all_preds)\n",
    "    print(f\"Epoch {epoch}: train loss={avg_loss:.4f}, val acc={val_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f221cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        81\n",
      "           1       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.92        98\n",
      "   macro avg       0.86      0.86      0.86        98\n",
      "weighted avg       0.92      0.92      0.92        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation \n",
    "print(\"\\nValidation classification report:\")\n",
    "print(classification_report(all_true, all_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "38concept_embedding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
