{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Long Alternative Attention Dataset Preparation - Sum+Max Embeddings\n",
    "\n",
    "**Purpose:** Prepare dataset using BOTH sum and max of concept similarities.\n",
    "\n",
    "**Key Features:**\n",
    "- **Sum-based**: Captures posts relevant to MULTIPLE concepts\n",
    "- **Max-based**: Captures posts expert in SINGLE concepts\n",
    "- **Concatenation**: 384 + 384 = **768-dimensional embeddings**\n",
    "- Posts retrieved **separately** for each method\n",
    "\n",
    "**Runtime:** ~80-100 minutes (2x the original due to dual retrieval)\n",
    "\n",
    "This notebook:\n",
    "1. Loads training and test data from XML files\n",
    "2. Uses SBERT to retrieve top-50 posts per subject with **SUM-based** scoring\n",
    "3. Uses SBERT to retrieve top-50 posts per subject with **MAX-based** scoring\n",
    "4. Pools both sets using their respective attention mechanisms\n",
    "5. **Concatenates** sum and max embeddings: **768 dims total**\n",
    "6. Saves everything to `data/processed/long_alternative_attention_pipeline/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Section 0: Configuration & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/38concept_embedding/lib/python3.8/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import zipfile\n",
    "import tempfile\n",
    "import shutil\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Random seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "print(f\"✓ Random seed set to {SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Using MacBook GPU (MPS)\n"
     ]
    }
   ],
   "source": [
    "# Detect device (MPS/CUDA/CPU)\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "    print(\"✓ Using MacBook GPU (MPS)\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "    print(\"✓ Using CUDA GPU\")\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "    print(\"⚠ Using CPU (will be slow)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Paths configured\n",
      "  Project root: /Users/gualtieromarencoturi/Desktop/thesis/Master-Thesis-CEM-Depression-etc-case-study\n",
      "  Data save dir: /Users/gualtieromarencoturi/Desktop/thesis/Master-Thesis-CEM-Depression-etc-case-study/data/processed/long_alternative_attention_pipeline\n",
      "\n",
      "  NOTE: This creates 768-dim embeddings (sum+max concatenation)\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "DATA_RAW = os.path.join(PROJECT_ROOT, \"data/raw\")\n",
    "DATA_PROCESSED = os.path.join(PROJECT_ROOT, \"data/processed\")\n",
    "\n",
    "# Training data paths\n",
    "POS_DIR = os.path.join(DATA_RAW, \"train/positive_examples_anonymous_chunks\")\n",
    "NEG_DIR = os.path.join(DATA_RAW, \"train/negative_examples_anonymous_chunks\")\n",
    "\n",
    "# Test data paths\n",
    "TEST_DIR = os.path.join(DATA_RAW, \"test\")\n",
    "TEST_LABELS = os.path.join(TEST_DIR, \"test_golden_truth.txt\")\n",
    "\n",
    "# Concept labels\n",
    "CONCEPTS_FILE = os.path.join(DATA_PROCESSED, \"merged_questionnaires.csv\")\n",
    "\n",
    "# Output directory - LONG ALTERNATIVE PIPELINE (768-dim embeddings)\n",
    "SAVE_DIR = os.path.join(DATA_PROCESSED, \"long_alternative_attention_pipeline\")\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "print(\"✓ Paths configured\")\n",
    "print(f\"  Project root: {PROJECT_ROOT}\")\n",
    "print(f\"  Data save dir: {SAVE_DIR}\")\n",
    "print(f\"\\n  NOTE: This creates 768-dim embeddings (sum+max concatenation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Defined 21 BDI-II concepts\n"
     ]
    }
   ],
   "source": [
    "# Define 21 BDI-II concept names\n",
    "CONCEPT_NAMES = [\n",
    "    \"Sadness\", \"Pessimism\", \"Past failure\", \"Loss of pleasure\",\n",
    "    \"Guilty feelings\", \"Punishment feelings\", \"Self-dislike\", \"Self-criticalness\",\n",
    "    \"Suicidal thoughts or wishes\", \"Crying\", \"Agitation\", \"Loss of interest\",\n",
    "    \"Indecisiveness\", \"Worthlessness\", \"Loss of energy\", \"Changes in sleeping pattern\",\n",
    "    \"Irritability\", \"Changes in appetite\", \"Concentration difficulty\",\n",
    "    \"Tiredness or fatigue\", \"Loss of interest in sex\"\n",
    "]\n",
    "N_CONCEPTS = len(CONCEPT_NAMES)\n",
    "\n",
    "print(f\"✓ Defined {N_CONCEPTS} BDI-II concepts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Hyperparameters configured:\n",
      "  k_posts: 50\n",
      "  sbert_model: all-MiniLM-L6-v2\n",
      "  embedding_dim: 384\n",
      "  final_embedding_dim: 768\n",
      "\n",
      "  Final embedding: 768 dims = 384 (sum) + 384 (max)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "HYPERPARAMS = {\n",
    "    \"k_posts\": 50,              # Top-k posts per subject per method\n",
    "    \"sbert_model\": \"all-MiniLM-L6-v2\",\n",
    "    \"embedding_dim\": 384,       # Dimension per method (sum or max)\n",
    "    \"final_embedding_dim\": 768, # 384 (sum) + 384 (max) = 768\n",
    "}\n",
    "# =========================\n",
    "# DEBUG / SANITY CHECK CONFIG\n",
    "# =========================\n",
    "DEBUG = True\n",
    "DEBUG_N_SUBJECTS = 3          # how many subjects to inspect\n",
    "DEBUG_TOP_N_POSTS = 5         # how many top posts to print\n",
    "DEBUG_PRINT_CONCEPTS = True   # print per-concept similarity stats\n",
    "\n",
    "print(\"✓ Hyperparameters configured:\")\n",
    "for k, v in HYPERPARAMS.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(f\"\\n  Final embedding: {HYPERPARAMS['final_embedding_dim']} dims = {HYPERPARAMS['embedding_dim']} (sum) + {HYPERPARAMS['embedding_dim']} (max)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Memory configuration:\n",
      "  post_batch_size: 32\n",
      "  subject_cache_interval: 10\n",
      "  use_no_grad: True\n",
      "  move_to_cpu_immediately: True\n"
     ]
    }
   ],
   "source": [
    "# Memory Management Configuration\n",
    "MEMORY_CONFIG = {\n",
    "    \"post_batch_size\": 32,        # Encode N posts at a time\n",
    "    \"subject_cache_interval\": 10,  # Clear GPU cache every N subjects\n",
    "    \"use_no_grad\": True,           # Disable gradient tracking\n",
    "    \"move_to_cpu_immediately\": True # Move results to CPU after computation\n",
    "}\n",
    "\n",
    "print(\"✓ Memory configuration:\")\n",
    "for k, v in MEMORY_CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ GPU cache clearing utility defined\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def clear_gpu_cache():\n",
    "    \"\"\"Clear GPU cache and run garbage collection.\"\"\"\n",
    "    if DEVICE == \"mps\":\n",
    "        torch.mps.empty_cache()\n",
    "    elif DEVICE == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "print(\"✓ GPU cache clearing utility defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Section 1: Load Training Data\n",
    "\n",
    "Extract 486 training subjects with posts and concept labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "# Helper functions for XML parsing\n",
    "WHITESPACE_RE = re.compile(r\"\\s+\")\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Normalize text by removing null chars and extra whitespace.\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = text.replace(\"\\u0000\", \"\")\n",
    "    text = WHITESPACE_RE.sub(\" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def extract_posts_from_xml(xml_path, min_chars=10):\n",
    "    \"\"\"Extract posts from a single XML file.\"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "    except Exception as e:\n",
    "        print(f\"WARNING: Failed to parse {xml_path}: {e}\")\n",
    "        return []\n",
    "    \n",
    "    posts = []\n",
    "    for writing in root.findall(\"WRITING\"):\n",
    "        title = writing.findtext(\"TITLE\") or \"\"\n",
    "        text = writing.findtext(\"TEXT\") or \"\"\n",
    "        \n",
    "        combined = normalize_text(f\"{title} {text}\".strip())\n",
    "        if len(combined) >= min_chars:\n",
    "            posts.append(combined)\n",
    "    \n",
    "    return posts\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "  Processing positive examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing positive examples: 100%|██████████| 830/830 [00:00<00:00, 2406.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 29868 posts from positive subjects\n",
      "  Processing negative examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing negative examples: 100%|██████████| 4031/4031 [00:02<00:00, 1702.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Loaded training data in 2.9s\n",
      "  Total posts: 286,740\n",
      "  Unique subjects: 486\n",
      "  Label distribution:\n",
      "label\n",
      "0    403\n",
      "1     83\n",
      "Name: subject_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Parse training XML files\n",
    "print(\"Loading training data...\")\n",
    "start_time = time.time()\n",
    "\n",
    "train_data = []\n",
    "\n",
    "# Process positive examples\n",
    "print(\"  Processing positive examples...\")\n",
    "pos_files = glob.glob(os.path.join(POS_DIR, \"**\", \"*.xml\"), recursive=True)\n",
    "for xml_file in tqdm(pos_files, desc=\"Processing positive examples\"):\n",
    "    filename = os.path.basename(xml_file)\n",
    "    match = re.match(r\"train_(subject\\d+)_\\d+\\.xml\", filename)\n",
    "    if match:\n",
    "        subject_id = match.group(1)\n",
    "        posts = extract_posts_from_xml(xml_file)\n",
    "        for post in posts:\n",
    "            train_data.append({\n",
    "                \"subject_id\": subject_id,\n",
    "                \"label\": 1,  # Positive (depression)\n",
    "                \"text\": post\n",
    "            })\n",
    "\n",
    "print(f\"  Loaded {sum(d['label'] == 1 for d in train_data)} posts from positive subjects\")\n",
    "\n",
    "# Process negative examples\n",
    "print(\"  Processing negative examples...\")\n",
    "neg_files = glob.glob(os.path.join(NEG_DIR, \"**\", \"*.xml\"), recursive=True)\n",
    "for xml_file in tqdm(neg_files, desc=\"Processing negative examples\"):\n",
    "    filename = os.path.basename(xml_file)\n",
    "    match = re.match(r\"train_(subject\\d+)_\\d+\\.xml\", filename)\n",
    "    if match:\n",
    "        subject_id = match.group(1)\n",
    "        posts = extract_posts_from_xml(xml_file)\n",
    "        for post in posts:\n",
    "            train_data.append({\n",
    "                \"subject_id\": subject_id,\n",
    "                \"label\": 0,  # Negative (control)\n",
    "                \"text\": post\n",
    "            })\n",
    "\n",
    "train_posts_df = pd.DataFrame(train_data)\n",
    "\n",
    "print(f\"\\n✓ Loaded training data in {time.time()-start_time:.1f}s\")\n",
    "print(f\"  Total posts: {len(train_posts_df):,}\")\n",
    "print(f\"  Unique subjects: {train_posts_df['subject_id'].nunique()}\")\n",
    "print(f\"  Label distribution:\")\n",
    "print(train_posts_df.groupby('label')['subject_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading concept labels...\n",
      "✓ Loaded concept labels for 486 subjects\n"
     ]
    }
   ],
   "source": [
    "# Load concept labels from questionnaires\n",
    "print(\"Loading concept labels...\")\n",
    "\n",
    "concepts_df = pd.read_csv(CONCEPTS_FILE)\n",
    "concepts_df[\"subject_id\"] = concepts_df[\"Subject\"].str.replace(\"train_\", \"\", regex=True)\n",
    "\n",
    "# Binarize concept values\n",
    "concept_cols = [col for col in concepts_df.columns if col in CONCEPT_NAMES]\n",
    "for col in concept_cols:\n",
    "    concepts_df[col] = (concepts_df[col] > 0).astype(int)\n",
    "\n",
    "print(f\"✓ Loaded concept labels for {len(concepts_df)} subjects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Section 2: Load Test Data\n",
    "\n",
    "Load all 401 test subjects from test folder (will be used entirely as test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting test data...\n",
      "  Temp directory: /var/folders/gb/m6c_r5xx6_14p7mlfjwk29900000gn/T/test_chunks_5djc6uf6\n",
      "  Extracted chunk 3/10\n",
      "  Extracted chunk 6/10\n",
      "  Extracted chunk 9/10\n",
      "✓ Test data extracted\n"
     ]
    }
   ],
   "source": [
    "# Extract test ZIP files to temporary directory\n",
    "print(\"Extracting test data...\")\n",
    "temp_dir = tempfile.mkdtemp(prefix=\"test_chunks_\")\n",
    "print(f\"  Temp directory: {temp_dir}\")\n",
    "\n",
    "for i in range(1, 11):\n",
    "    zip_path = os.path.join(TEST_DIR, f\"chunk {i}.zip\")\n",
    "    if os.path.exists(zip_path):\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(os.path.join(temp_dir, f\"chunk_{i}\"))\n",
    "        if i % 3 == 0:\n",
    "            print(f\"  Extracted chunk {i}/10\")\n",
    "\n",
    "print(\"✓ Test data extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded test labels for 401 subjects\n",
      "  Label distribution:\n",
      "label\n",
      "0    349\n",
      "1     52\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load test labels\n",
    "test_labels_df = pd.read_csv(TEST_LABELS, sep='\\t', header=None, names=['subject_id', 'label'])\n",
    "test_labels_df['subject_id'] = test_labels_df['subject_id'].str.strip()\n",
    "\n",
    "print(f\"✓ Loaded test labels for {len(test_labels_df)} subjects\")\n",
    "print(f\"  Label distribution:\")\n",
    "print(test_labels_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test posts...\n",
      "  Found 4010 XML files\n",
      "✓ Loaded test posts\n",
      "  Total posts: 229,746\n",
      "  Unique subjects: 401\n"
     ]
    }
   ],
   "source": [
    "# Parse test XML files\n",
    "print(\"Loading test posts...\")\n",
    "test_data = []\n",
    "\n",
    "test_xml_files = glob.glob(os.path.join(temp_dir, \"**\", \"*.xml\"), recursive=True)\n",
    "print(f\"  Found {len(test_xml_files)} XML files\")\n",
    "\n",
    "for xml_file in test_xml_files:\n",
    "    filename = os.path.basename(xml_file)\n",
    "    match = re.match(r\"(test_subject\\d+)_\\d+\\.xml\", filename)\n",
    "    if match:\n",
    "        subject_id = match.group(1)\n",
    "        label_row = test_labels_df[test_labels_df['subject_id'] == subject_id]\n",
    "        if len(label_row) > 0:\n",
    "            label = label_row.iloc[0]['label']\n",
    "            posts = extract_posts_from_xml(xml_file)\n",
    "            for post in posts:\n",
    "                test_data.append({\n",
    "                    \"subject_id\": subject_id,\n",
    "                    \"label\": label,\n",
    "                    \"text\": post\n",
    "                })\n",
    "\n",
    "test_posts_df = pd.DataFrame(test_data)\n",
    "\n",
    "print(f\"✓ Loaded test posts\")\n",
    "print(f\"  Total posts: {len(test_posts_df):,}\")\n",
    "print(f\"  Unique subjects: {test_posts_df['subject_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting training data into train (80%) and validation (20%)...\n",
      "✓ Split complete\n",
      "  Training: 388 subjects (80% of original train)\n",
      "  Validation: 98 subjects (20% of original train)\n",
      "  Test: 401 subjects (100% of test folder)\n",
      "\n",
      "  Training label distribution:\n",
      "label\n",
      "0    322\n",
      "1     66\n",
      "Name: subject_id, dtype: int64\n",
      "\n",
      "  Validation label distribution:\n",
      "label\n",
      "0    81\n",
      "1    17\n",
      "Name: subject_id, dtype: int64\n",
      "\n",
      "  Test label distribution:\n",
      "label\n",
      "0    349\n",
      "1     52\n",
      "Name: subject_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split TRAINING data into train and validation (80/20)\n",
    "print(\"Splitting training data into train (80%) and validation (20%)...\")\n",
    "\n",
    "train_subjects = train_posts_df.groupby('subject_id')['label'].first().reset_index()\n",
    "\n",
    "train_subjects_final, val_subjects = train_test_split(\n",
    "    train_subjects['subject_id'],\n",
    "    test_size=0.2,\n",
    "    stratify=train_subjects['label'],\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "# Create new train dataframe with only 80% of subjects\n",
    "train_posts_df_final = train_posts_df[train_posts_df['subject_id'].isin(train_subjects_final)].copy()\n",
    "\n",
    "# Create validation dataframe from remaining 20% of training subjects\n",
    "val_posts_df = train_posts_df[train_posts_df['subject_id'].isin(val_subjects)].copy()\n",
    "\n",
    "# Keep ALL test data as test set (no split)\n",
    "test_posts_df_final = test_posts_df.copy()\n",
    "\n",
    "print(f\"✓ Split complete\")\n",
    "print(f\"  Training: {train_posts_df_final['subject_id'].nunique()} subjects (80% of original train)\")\n",
    "print(f\"  Validation: {val_posts_df['subject_id'].nunique()} subjects (20% of original train)\")\n",
    "print(f\"  Test: {test_posts_df_final['subject_id'].nunique()} subjects (100% of test folder)\")\n",
    "\n",
    "# Show label distributions\n",
    "print(f\"\\n  Training label distribution:\")\n",
    "print(train_posts_df_final.groupby('label')['subject_id'].nunique())\n",
    "print(f\"\\n  Validation label distribution:\")\n",
    "print(val_posts_df.groupby('label')['subject_id'].nunique())\n",
    "print(f\"\\n  Test label distribution:\")\n",
    "print(test_posts_df_final.groupby('label')['subject_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## Section 3: SBERT Setup & Concept Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SBERT model: all-MiniLM-L6-v2\n",
      "✓ SBERT model loaded on mps\n",
      "  Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Load SBERT model\n",
    "print(f\"Loading SBERT model: {HYPERPARAMS['sbert_model']}\")\n",
    "sbert_model = SentenceTransformer(HYPERPARAMS['sbert_model'])\n",
    "sbert_model = sbert_model.to(DEVICE)\n",
    "\n",
    "print(f\"✓ SBERT model loaded on {DEVICE}\")\n",
    "print(f\"  Embedding dimension: {sbert_model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings for 21 concepts...\n",
      "✓ Concept embeddings created\n",
      "  Shape: torch.Size([21, 384])\n"
     ]
    }
   ],
   "source": [
    "# Create concept embeddings\n",
    "print(f\"Creating embeddings for {N_CONCEPTS} concepts...\")\n",
    "concept_embeddings = sbert_model.encode(\n",
    "    CONCEPT_NAMES,\n",
    "    convert_to_tensor=True,\n",
    "    show_progress_bar=False\n",
    ")\n",
    "\n",
    "print(f\"✓ Concept embeddings created\")\n",
    "print(f\"  Shape: {concept_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ SUM-based post retrieval function defined\n"
     ]
    }
   ],
   "source": [
    "def retrieve_top_k_posts_sum(subject_id, posts_df, concept_embs, sbert, k=50, batch_size=32, debug=False):\n",
    "    \"\"\"\n",
    "    Retrieve top-k posts for a subject based on SUM of concept similarities.\n",
    "    OPTIMIZED: Uses batching to prevent memory exhaustion.\n",
    "    \"\"\"\n",
    "    subj_posts = posts_df[posts_df['subject_id'] == subject_id]['text'].tolist()\n",
    "\n",
    "    if len(subj_posts) == 0:\n",
    "        return []\n",
    "\n",
    "    if len(subj_posts) <= k:\n",
    "        if len(subj_posts) < k:\n",
    "            extra_needed = k - len(subj_posts)\n",
    "            padding = list(np.random.choice(subj_posts, size=extra_needed, replace=True))\n",
    "            return subj_posts + padding\n",
    "        else:\n",
    "            return subj_posts\n",
    "\n",
    "    # Batch encoding to prevent memory issues\n",
    "    sum_sim_scores = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient tracking\n",
    "        for i in range(0, len(subj_posts), batch_size):\n",
    "            batch_posts = subj_posts[i:i + batch_size]\n",
    "\n",
    "            # Encode batch\n",
    "            batch_embeddings = sbert.encode(\n",
    "                batch_posts,\n",
    "                convert_to_tensor=True,\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "\n",
    "            # Compute similarities for this batch\n",
    "            cos_scores = util.cos_sim(batch_embeddings, concept_embs)  # [batch, 21]\n",
    "            batch_sum_scores = cos_scores.sum(dim=1).cpu().numpy()  # Move to CPU immediately\n",
    "\n",
    "            sum_sim_scores.extend(batch_sum_scores)\n",
    "\n",
    "            # Clear references\n",
    "            del batch_embeddings, cos_scores, batch_sum_scores\n",
    "\n",
    "    sum_sim_scores = np.array(sum_sim_scores)\n",
    "\n",
    "    if debug:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"[DEBUG][SUM] Subject: {subject_id}\")\n",
    "        print(f\"[DEBUG][SUM] Total posts: {len(subj_posts)}\")\n",
    "        print(\"[DEBUG][SUM] Sum similarity stats:\")\n",
    "        print(f\"  min={sum_sim_scores.min():.4f} \"\n",
    "              f\"max={sum_sim_scores.max():.4f} \"\n",
    "              f\"mean={sum_sim_scores.mean():.4f} \"\n",
    "              f\"std={sum_sim_scores.std():.4f}\")\n",
    "\n",
    "        top_idx_sorted = np.argsort(-sum_sim_scores)\n",
    "        print(f\"\\n[DEBUG][SUM] Top-{DEBUG_TOP_N_POSTS} retrieved posts:\")\n",
    "        for rank, i in enumerate(top_idx_sorted[:DEBUG_TOP_N_POSTS]):\n",
    "            print(f\"\\n  Rank {rank+1}\")\n",
    "            print(f\"  Score: {sum_sim_scores[i]:.4f}\")\n",
    "            print(f\"  Text: {subj_posts[i][:200]}\")\n",
    "\n",
    "    # Select top-k posts\n",
    "    top_k_indices = np.argpartition(-sum_sim_scores, range(min(k, len(subj_posts))))[:k]\n",
    "\n",
    "    return [subj_posts[i] for i in top_k_indices]\n",
    "\n",
    "print(\"✓ SUM-based post retrieval function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cell-23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ MAX-based post retrieval function defined\n"
     ]
    }
   ],
   "source": [
    "def retrieve_top_k_posts_max(subject_id, posts_df, concept_embs, sbert, k=50, batch_size=32, debug=False):\n",
    "    \"\"\"\n",
    "    Retrieve top-k posts for a subject based on MAX of concept similarities.\n",
    "    \n",
    "    Key difference from sum-based:\n",
    "    - For each post, takes MAX similarity across all 21 concepts\n",
    "    - Selects posts that are highly relevant to at least ONE concept\n",
    "    \"\"\"\n",
    "    subj_posts = posts_df[posts_df['subject_id'] == subject_id]['text'].tolist()\n",
    "\n",
    "    if len(subj_posts) == 0:\n",
    "        return []\n",
    "\n",
    "    if len(subj_posts) <= k:\n",
    "        if len(subj_posts) < k:\n",
    "            extra_needed = k - len(subj_posts)\n",
    "            padding = list(np.random.choice(subj_posts, size=extra_needed, replace=True))\n",
    "            return subj_posts + padding\n",
    "        else:\n",
    "            return subj_posts\n",
    "\n",
    "    # Batch encoding to prevent memory issues\n",
    "    max_sim_scores = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient tracking\n",
    "        for i in range(0, len(subj_posts), batch_size):\n",
    "            batch_posts = subj_posts[i:i + batch_size]\n",
    "\n",
    "            # Encode batch\n",
    "            batch_embeddings = sbert.encode(\n",
    "                batch_posts,\n",
    "                convert_to_tensor=True,\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "\n",
    "            # Compute similarities for this batch\n",
    "            cos_scores = util.cos_sim(batch_embeddings, concept_embs)  # [batch, 21]\n",
    "            # KEY DIFFERENCE: Take MAX instead of SUM\n",
    "            batch_max_scores = cos_scores.max(dim=1)[0].cpu().numpy()  # [0] gets values, not indices\n",
    "\n",
    "            max_sim_scores.extend(batch_max_scores)\n",
    "\n",
    "            # Clear references\n",
    "            del batch_embeddings, cos_scores, batch_max_scores\n",
    "\n",
    "    max_sim_scores = np.array(max_sim_scores)\n",
    "\n",
    "    if debug:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"[DEBUG][MAX] Subject: {subject_id}\")\n",
    "        print(f\"[DEBUG][MAX] Total posts: {len(subj_posts)}\")\n",
    "        print(\"[DEBUG][MAX] Max similarity stats:\")\n",
    "        print(f\"  min={max_sim_scores.min():.4f} \"\n",
    "              f\"max={max_sim_scores.max():.4f} \"\n",
    "              f\"mean={max_sim_scores.mean():.4f} \"\n",
    "              f\"std={max_sim_scores.std():.4f}\")\n",
    "\n",
    "        top_idx_sorted = np.argsort(-max_sim_scores)\n",
    "        print(f\"\\n[DEBUG][MAX] Top-{DEBUG_TOP_N_POSTS} retrieved posts:\")\n",
    "        for rank, i in enumerate(top_idx_sorted[:DEBUG_TOP_N_POSTS]):\n",
    "            print(f\"\\n  Rank {rank+1}\")\n",
    "            print(f\"  Score: {max_sim_scores[i]:.4f}\")\n",
    "            print(f\"  Text: {subj_posts[i][:200]}\")\n",
    "\n",
    "    # Select top-k posts\n",
    "    top_k_indices = np.argpartition(-max_sim_scores, range(min(k, len(subj_posts))))[:k]\n",
    "\n",
    "    return [subj_posts[i] for i in top_k_indices]\n",
    "\n",
    "print(\"✓ MAX-based post retrieval function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cell-24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ SUM-based attention pooling function defined\n"
     ]
    }
   ],
   "source": [
    "def encode_and_attention_pool_sum(selected_posts_dict, sbert, concept_embs,\n",
    "                                   normalize=True, debug=False):\n",
    "    \"\"\"\n",
    "    Encode posts and pool using SUM of concept similarities for attention.\n",
    "    OPTIMIZED: Includes memory management for stability.\n",
    "    \"\"\"\n",
    "    subject_ids = list(selected_posts_dict.keys())\n",
    "    pooled_embeddings = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient tracking\n",
    "        for idx, subject_id in enumerate(subject_ids):\n",
    "            posts = selected_posts_dict[subject_id]\n",
    "\n",
    "            # Handle empty posts\n",
    "            if len(posts) == 0:\n",
    "                print(f\"WARNING: No posts for subject {subject_id}, using zero embedding\")\n",
    "                pooled_embeddings.append(np.zeros(384))\n",
    "                continue\n",
    "\n",
    "            # Filter out empty posts\n",
    "            posts = [p for p in posts if p.strip()]\n",
    "            if len(posts) == 0:\n",
    "                print(f\"WARNING: All posts empty for subject {subject_id}, using zero embedding\")\n",
    "                pooled_embeddings.append(np.zeros(384))\n",
    "                continue\n",
    "\n",
    "            # Encode posts\n",
    "            post_embs = sbert.encode(\n",
    "                posts,\n",
    "                convert_to_tensor=True,\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "\n",
    "            if post_embs.shape[0] == 0 or post_embs.shape[1] == 0:\n",
    "                print(f\"WARNING: Empty embeddings for subject {subject_id}, using zero embedding\")\n",
    "                pooled_embeddings.append(np.zeros(384))\n",
    "                continue\n",
    "\n",
    "            # Compute similarity to concepts\n",
    "            cos_scores = util.cos_sim(post_embs, concept_embs)\n",
    "\n",
    "            # Sum over concepts\n",
    "            post_scores = cos_scores.sum(dim=1)\n",
    "\n",
    "            # Remove negative similarities\n",
    "            post_scores = torch.clamp(post_scores, min=0.0)\n",
    "\n",
    "            # Attention weights\n",
    "            TEMPERATURE = 0.2  \n",
    "            attn_weights = torch.softmax(post_scores / TEMPERATURE, dim=0)\n",
    "\n",
    "            if debug and idx < DEBUG_N_SUBJECTS:\n",
    "                print(\"\\n\" + \"=\"*60)\n",
    "                print(f\"[DEBUG][SUM-ATTN] Subject: {subject_id}\")\n",
    "                attn_np = attn_weights.cpu().numpy()\n",
    "                print(\"[DEBUG][SUM-ATTN] Weight stats:\")\n",
    "                print(f\"  min={attn_np.min():.6f} \"\n",
    "                      f\"max={attn_np.max():.6f} \"\n",
    "                      f\"mean={attn_np.mean():.6f}\")\n",
    "\n",
    "            # Weighted sum pooling\n",
    "            pooled = torch.sum(attn_weights.unsqueeze(1) * post_embs, dim=0)\n",
    "            pooled_embeddings.append(pooled.cpu().numpy())\n",
    "\n",
    "            # Clean up GPU memory\n",
    "            del post_embs, cos_scores, attn_weights, pooled\n",
    "\n",
    "    return np.vstack(pooled_embeddings), subject_ids\n",
    "\n",
    "print(\"✓ SUM-based attention pooling function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cell-25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ MAX-based attention pooling function defined\n"
     ]
    }
   ],
   "source": [
    "def encode_and_attention_pool_max(selected_posts_dict, sbert, concept_embs,\n",
    "                                   normalize=True, debug=False):\n",
    "    \"\"\"\n",
    "    Encode posts and pool using MAX of concept similarities for attention.\n",
    "    \n",
    "    For each post:\n",
    "    1. Compute similarities to all 21 concepts\n",
    "    2. Take MAX similarity as the post's relevance score\n",
    "    3. Use softmax(max_scores / temperature) for attention weights\n",
    "    4. Weighted sum pooling to create final embedding\n",
    "    \"\"\"\n",
    "    subject_ids = list(selected_posts_dict.keys())\n",
    "    pooled_embeddings = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient tracking\n",
    "        for idx, subject_id in enumerate(subject_ids):\n",
    "            posts = selected_posts_dict[subject_id]\n",
    "\n",
    "            # Handle empty posts\n",
    "            if len(posts) == 0:\n",
    "                print(f\"WARNING: No posts for subject {subject_id}, using zero embedding\")\n",
    "                pooled_embeddings.append(np.zeros(384))\n",
    "                continue\n",
    "\n",
    "            # Filter out empty posts\n",
    "            posts = [p for p in posts if p.strip()]\n",
    "            if len(posts) == 0:\n",
    "                print(f\"WARNING: All posts empty for subject {subject_id}, using zero embedding\")\n",
    "                pooled_embeddings.append(np.zeros(384))\n",
    "                continue\n",
    "\n",
    "            # Encode posts\n",
    "            post_embs = sbert.encode(\n",
    "                posts,\n",
    "                convert_to_tensor=True,\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "\n",
    "            if post_embs.shape[0] == 0 or post_embs.shape[1] == 0:\n",
    "                print(f\"WARNING: Empty embeddings for subject {subject_id}, using zero embedding\")\n",
    "                pooled_embeddings.append(np.zeros(384))\n",
    "                continue\n",
    "\n",
    "            # Compute similarity to concepts\n",
    "            cos_scores = util.cos_sim(post_embs, concept_embs)\n",
    "\n",
    "            # KEY DIFFERENCE: Take MAX instead of SUM\n",
    "            post_scores = cos_scores.max(dim=1)[0]  # [0] gets values, not indices\n",
    "\n",
    "            # Remove negative similarities\n",
    "            post_scores = torch.clamp(post_scores, min=0.0)\n",
    "\n",
    "            # Attention weights\n",
    "            TEMPERATURE = 0.2  \n",
    "            attn_weights = torch.softmax(post_scores / TEMPERATURE, dim=0)\n",
    "\n",
    "            if debug and idx < DEBUG_N_SUBJECTS:\n",
    "                print(\"\\n\" + \"=\"*60)\n",
    "                print(f\"[DEBUG][MAX-ATTN] Subject: {subject_id}\")\n",
    "                attn_np = attn_weights.cpu().numpy()\n",
    "                print(\"[DEBUG][MAX-ATTN] Weight stats:\")\n",
    "                print(f\"  min={attn_np.min():.6f} \"\n",
    "                      f\"max={attn_np.max():.6f} \"\n",
    "                      f\"mean={attn_np.mean():.6f}\")\n",
    "\n",
    "            # Weighted sum pooling\n",
    "            pooled = torch.sum(attn_weights.unsqueeze(1) * post_embs, dim=0)\n",
    "            pooled_embeddings.append(pooled.cpu().numpy())\n",
    "\n",
    "            # Clean up GPU memory\n",
    "            del post_embs, cos_scores, attn_weights, pooled\n",
    "\n",
    "    return np.vstack(pooled_embeddings), subject_ids\n",
    "\n",
    "print(\"✓ MAX-based attention pooling function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## Section 4: Dual Post Retrieval (Sum + Max)\n",
    "\n",
    "Retrieve top-50 posts using BOTH methods for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cell-27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving top-50 posts using SUM and MAX methods...\n",
      "⏰ This will take ~2x longer due to dual retrieval\n",
      "\n",
      "  Processing training subjects (80% of train data)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train subjects (sum+max):   0%|          | 0/388 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "[DEBUG][SUM] Subject: subject6760\n",
      "[DEBUG][SUM] Total posts: 124\n",
      "[DEBUG][SUM] Sum similarity stats:\n",
      "  min=-0.9500 max=5.2591 mean=1.5585 std=1.3026\n",
      "\n",
      "[DEBUG][SUM] Top-5 retrieved posts:\n",
      "\n",
      "  Rank 1\n",
      "  Score: 5.2591\n",
      "  Text: Not feeling negative could be considered as better.\n",
      "\n",
      "  Rank 2\n",
      "  Score: 4.8450\n",
      "  Text: The 12 Worst Habits for Your Mental Health\n",
      "\n",
      "  Rank 3\n",
      "  Score: 4.2735\n",
      "  Text: Can you explain?\n",
      "\n",
      "  Rank 4\n",
      "  Score: 4.2102\n",
      "  Text: A roller-coaster in which I always seem to be lost in the past or in the future, never living the moment.\n",
      "\n",
      "  Rank 5\n",
      "  Score: 3.8703\n",
      "  Text: Selfish motives seem to make you succeed. I'm shocked!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train subjects (sum+max):   0%|          | 1/388 [00:01<11:50,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "[DEBUG][MAX] Subject: subject6760\n",
      "[DEBUG][MAX] Total posts: 124\n",
      "[DEBUG][MAX] Max similarity stats:\n",
      "  min=0.0221 max=0.6737 mean=0.2090 std=0.0993\n",
      "\n",
      "[DEBUG][MAX] Top-5 retrieved posts:\n",
      "\n",
      "  Rank 1\n",
      "  Score: 0.6737\n",
      "  Text: My therapist asked me to try and be an imaginary observer about how critical I'm about myself. She thinks that even if you can't stop being hyper-self-critical, being aware of it helps. (PS: Is your n\n",
      "\n",
      "  Rank 2\n",
      "  Score: 0.4208\n",
      "  Text: The 12 Worst Habits for Your Mental Health\n",
      "\n",
      "  Rank 3\n",
      "  Score: 0.4175\n",
      "  Text: It's sometimes hard for me to do imaginary tasks - e.g., the containment task in mindfulness is not easy for me. :)\n",
      "\n",
      "  Rank 4\n",
      "  Score: 0.4051\n",
      "  Text: Must confess. I do both.\n",
      "\n",
      "  Rank 5\n",
      "  Score: 0.4041\n",
      "  Text: Not feeling negative could be considered as better.\n",
      "\n",
      "============================================================\n",
      "[DEBUG][SUM] Subject: subject7326\n",
      "[DEBUG][SUM] Total posts: 118\n",
      "[DEBUG][SUM] Sum similarity stats:\n",
      "  min=-1.0593 max=3.1569 mean=1.0799 std=0.8906\n",
      "\n",
      "[DEBUG][SUM] Top-5 retrieved posts:\n",
      "\n",
      "  Rank 1\n",
      "  Score: 3.1569\n",
      "  Text: I have had a good friend in school, who changed A LOT in personality when he picked up these kind of games at the age of ~ 14. He isolated himself from others, started hating around, joined a \"shootin\n",
      "\n",
      "  Rank 2\n",
      "  Score: 3.0400\n",
      "  Text: I actually DO think that playing ego-shooters increases your willingness to use violence and causes emotional blunting. edit: gettin' downvoted on an unpopular opinion thread, i did it reddit! ppl pla\n",
      "\n",
      "  Rank 3\n",
      "  Score: 2.9997\n",
      "  Text: \"actively sabotage\" lol. He offered her food. That's about it. He didn't fill her food with hidden chocolate and neither did he shove down pizza down her throat when she was asleep. There's NO point o\n",
      "\n",
      "  Rank 4\n",
      "  Score: 2.9662\n",
      "  Text: on r/relationships there was a guy who had his gf's father staying in his house and heard strange noises at night, leading him to believe his gf was sleeping with her father. he said he would check th\n",
      "\n",
      "  Rank 5\n",
      "  Score: 2.8420\n",
      "  Text: I have similar experiences. I have often HUGE problems falling asleep and lying around waiting until my body decides it's ok now to fall asleep is just super annoying and exhausting for me. I'll mostl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train subjects (sum+max):   1%|          | 3/388 [00:02<05:24,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "[DEBUG][MAX] Subject: subject7326\n",
      "[DEBUG][MAX] Total posts: 118\n",
      "[DEBUG][MAX] Max similarity stats:\n",
      "  min=0.0131 max=0.4619 mean=0.1764 std=0.0727\n",
      "\n",
      "[DEBUG][MAX] Top-5 retrieved posts:\n",
      "\n",
      "  Rank 1\n",
      "  Score: 0.4619\n",
      "  Text: Thank you for sharing. I'll look into that link deeper tomorrow, but I always thought that maybe it's my biological clock that is not working correctly rather than the actual sleep. I can sleep during\n",
      "\n",
      "  Rank 2\n",
      "  Score: 0.3985\n",
      "  Text: I have similar experiences. I have often HUGE problems falling asleep and lying around waiting until my body decides it's ok now to fall asleep is just super annoying and exhausting for me. I'll mostl\n",
      "\n",
      "  Rank 3\n",
      "  Score: 0.3252\n",
      "  Text: \"actively sabotage\" lol. He offered her food. That's about it. He didn't fill her food with hidden chocolate and neither did he shove down pizza down her throat when she was asleep. There's NO point o\n",
      "\n",
      "  Rank 4\n",
      "  Score: 0.3210\n",
      "  Text: History. Actually I'm in 2nd semester already, but better late than never is guess...?\n",
      "\n",
      "  Rank 5\n",
      "  Score: 0.3041\n",
      "  Text: I actually DO think that playing ego-shooters increases your willingness to use violence and causes emotional blunting. edit: gettin' downvoted on an unpopular opinion thread, i did it reddit! ppl pla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train subjects (sum+max):  10%|█         | 40/388 [01:22<11:59,  2.07s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m train_subjects \u001b[38;5;241m=\u001b[39m train_posts_df_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, subject_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_subjects, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain subjects (sum+max)\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Method 1: Sum-based retrieval\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     sum_posts \u001b[38;5;241m=\u001b[39m \u001b[43mretrieve_top_k_posts_sum\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubject_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_posts_df_final\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconcept_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43msbert_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHYPERPARAMS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mk_posts\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMEMORY_CONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost_batch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDEBUG\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDEBUG_N_SUBJECTS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     train_sum_selected[subject_id] \u001b[38;5;241m=\u001b[39m sum_posts\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Method 2: Max-based retrieval\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 35\u001b[0m, in \u001b[0;36mretrieve_top_k_posts_sum\u001b[0;34m(subject_id, posts_df, concept_embs, sbert, k, batch_size, debug)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Compute similarities for this batch\u001b[39;00m\n\u001b[1;32m     34\u001b[0m cos_scores \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mcos_sim(batch_embeddings, concept_embs)  \u001b[38;5;66;03m# [batch, 21]\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m batch_sum_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcos_scores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# Move to CPU immediately\u001b[39;00m\n\u001b[1;32m     37\u001b[0m sum_sim_scores\u001b[38;5;241m.\u001b[39mextend(batch_sum_scores)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Clear references\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Retrieve top-k posts for all subjects using BOTH methods\n",
    "print(f\"Retrieving top-{HYPERPARAMS['k_posts']} posts using SUM and MAX methods...\")\n",
    "print(\"⏰ This will take ~2x longer due to dual retrieval\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Training subjects (80% of original training data)\n",
    "print(\"\\n  Processing training subjects (80% of train data)...\")\n",
    "train_sum_selected = {}\n",
    "train_max_selected = {}\n",
    "train_subjects = train_posts_df_final['subject_id'].unique()\n",
    "\n",
    "for idx, subject_id in enumerate(tqdm(train_subjects, desc=\"Train subjects (sum+max)\")):\n",
    "    # Method 1: Sum-based retrieval\n",
    "    sum_posts = retrieve_top_k_posts_sum(\n",
    "        subject_id,\n",
    "        train_posts_df_final,\n",
    "        concept_embeddings,\n",
    "        sbert_model,\n",
    "        k=HYPERPARAMS['k_posts'],\n",
    "        batch_size=MEMORY_CONFIG['post_batch_size'],\n",
    "        debug=(DEBUG and idx < DEBUG_N_SUBJECTS)\n",
    "    )\n",
    "    train_sum_selected[subject_id] = sum_posts\n",
    "    \n",
    "    # Method 2: Max-based retrieval\n",
    "    max_posts = retrieve_top_k_posts_max(\n",
    "        subject_id,\n",
    "        train_posts_df_final,\n",
    "        concept_embeddings,\n",
    "        sbert_model,\n",
    "        k=HYPERPARAMS['k_posts'],\n",
    "        batch_size=MEMORY_CONFIG['post_batch_size'],\n",
    "        debug=(DEBUG and idx < DEBUG_N_SUBJECTS)\n",
    "    )\n",
    "    train_max_selected[subject_id] = max_posts\n",
    "\n",
    "    # Clear GPU cache periodically\n",
    "    if (idx + 1) % MEMORY_CONFIG['subject_cache_interval'] == 0:\n",
    "        clear_gpu_cache()\n",
    "\n",
    "# Validation subjects (20% of original training data)\n",
    "print(\"\\n  Processing validation subjects (20% of train data)...\")\n",
    "val_sum_selected = {}\n",
    "val_max_selected = {}\n",
    "val_subjects = val_posts_df['subject_id'].unique()\n",
    "\n",
    "for idx, subject_id in enumerate(tqdm(val_subjects, desc=\"Val subjects (sum+max)\")):\n",
    "    # Method 1: Sum-based retrieval\n",
    "    sum_posts = retrieve_top_k_posts_sum(\n",
    "        subject_id,\n",
    "        val_posts_df,\n",
    "        concept_embeddings,\n",
    "        sbert_model,\n",
    "        k=HYPERPARAMS['k_posts'],\n",
    "        batch_size=MEMORY_CONFIG['post_batch_size'],\n",
    "        debug=(DEBUG and idx < DEBUG_N_SUBJECTS)\n",
    "    )\n",
    "    val_sum_selected[subject_id] = sum_posts\n",
    "    \n",
    "    # Method 2: Max-based retrieval\n",
    "    max_posts = retrieve_top_k_posts_max(\n",
    "        subject_id,\n",
    "        val_posts_df,\n",
    "        concept_embeddings,\n",
    "        sbert_model,\n",
    "        k=HYPERPARAMS['k_posts'],\n",
    "        batch_size=MEMORY_CONFIG['post_batch_size'],\n",
    "        debug=(DEBUG and idx < DEBUG_N_SUBJECTS)\n",
    "    )\n",
    "    val_max_selected[subject_id] = max_posts\n",
    "\n",
    "    if (idx + 1) % MEMORY_CONFIG['subject_cache_interval'] == 0:\n",
    "        clear_gpu_cache()\n",
    "\n",
    "# Test subjects (100% of test folder)\n",
    "print(\"\\n  Processing test subjects (100% of test folder)...\")\n",
    "test_sum_selected = {}\n",
    "test_max_selected = {}\n",
    "test_subjects = test_posts_df_final['subject_id'].unique()\n",
    "\n",
    "for idx, subject_id in enumerate(tqdm(test_subjects, desc=\"Test subjects (sum+max)\")):\n",
    "    # Method 1: Sum-based retrieval\n",
    "    sum_posts = retrieve_top_k_posts_sum(\n",
    "        subject_id,\n",
    "        test_posts_df_final,\n",
    "        concept_embeddings,\n",
    "        sbert_model,\n",
    "        k=HYPERPARAMS['k_posts'],\n",
    "        batch_size=MEMORY_CONFIG['post_batch_size'],\n",
    "        debug=(DEBUG and idx < DEBUG_N_SUBJECTS)\n",
    "    )\n",
    "    test_sum_selected[subject_id] = sum_posts\n",
    "    \n",
    "    # Method 2: Max-based retrieval\n",
    "    max_posts = retrieve_top_k_posts_max(\n",
    "        subject_id,\n",
    "        test_posts_df_final,\n",
    "        concept_embeddings,\n",
    "        sbert_model,\n",
    "        k=HYPERPARAMS['k_posts'],\n",
    "        batch_size=MEMORY_CONFIG['post_batch_size'],\n",
    "        debug=(DEBUG and idx < DEBUG_N_SUBJECTS)\n",
    "    )\n",
    "    test_max_selected[subject_id] = max_posts\n",
    "\n",
    "    if (idx + 1) % MEMORY_CONFIG['subject_cache_interval'] == 0:\n",
    "        clear_gpu_cache()\n",
    "\n",
    "# Final cache clear\n",
    "clear_gpu_cache()\n",
    "\n",
    "print(f\"\\n✓ Dual post retrieval complete in {time.time()-start_time:.1f}s ({(time.time()-start_time)/60:.1f} min)\")\n",
    "print(f\"  Processed {len(train_subjects) + len(val_subjects) + len(test_subjects)} subjects with BOTH methods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "## Section 5: Dual Embedding Generation & Concatenation\n",
    "\n",
    "Create sum-based and max-based embeddings, then concatenate to 768 dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode and pool for all splits using BOTH methods\n",
    "print(\"Encoding and pooling embeddings (SUM + MAX methods, memory-optimized)...\")\n",
    "print(\"Final embeddings will be 768-dim (384 sum + 384 max)\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# ==================== TRAINING SET ====================\n",
    "print(\"  Training set...\")\n",
    "# Sum-based embeddings (384 dims)\n",
    "X_train_sum, train_subject_ids = encode_and_attention_pool_sum(\n",
    "    train_sum_selected,\n",
    "    sbert_model,\n",
    "    concept_embeddings,\n",
    "    normalize=True,\n",
    "    debug=DEBUG\n",
    ")\n",
    "clear_gpu_cache()\n",
    "print(f\"    X_train_sum shape: {X_train_sum.shape}\")\n",
    "\n",
    "# Max-based embeddings (384 dims)\n",
    "X_train_max, _ = encode_and_attention_pool_max(\n",
    "    train_max_selected,\n",
    "    sbert_model,\n",
    "    concept_embeddings,\n",
    "    normalize=True,\n",
    "    debug=DEBUG\n",
    ")\n",
    "clear_gpu_cache()\n",
    "print(f\"    X_train_max shape: {X_train_max.shape}\")\n",
    "\n",
    "# Concatenate: 768 dims total\n",
    "X_train = np.hstack([X_train_sum, X_train_max])\n",
    "print(f\"    X_train (concatenated) shape: {X_train.shape}\\n\")\n",
    "\n",
    "# ==================== VALIDATION SET ====================\n",
    "print(\"  Validation set...\")\n",
    "# Sum-based embeddings (384 dims)\n",
    "X_val_sum, val_subject_ids = encode_and_attention_pool_sum(\n",
    "    val_sum_selected,\n",
    "    sbert_model,\n",
    "    concept_embeddings,\n",
    "    normalize=True\n",
    ")\n",
    "clear_gpu_cache()\n",
    "print(f\"    X_val_sum shape: {X_val_sum.shape}\")\n",
    "\n",
    "# Max-based embeddings (384 dims)\n",
    "X_val_max, _ = encode_and_attention_pool_max(\n",
    "    val_max_selected,\n",
    "    sbert_model,\n",
    "    concept_embeddings,\n",
    "    normalize=True\n",
    ")\n",
    "clear_gpu_cache()\n",
    "print(f\"    X_val_max shape: {X_val_max.shape}\")\n",
    "\n",
    "# Concatenate: 768 dims total\n",
    "X_val = np.hstack([X_val_sum, X_val_max])\n",
    "print(f\"    X_val (concatenated) shape: {X_val.shape}\\n\")\n",
    "\n",
    "# ==================== TEST SET ====================\n",
    "print(\"  Test set...\")\n",
    "# Sum-based embeddings (384 dims)\n",
    "X_test_sum, test_subject_ids = encode_and_attention_pool_sum(\n",
    "    test_sum_selected,\n",
    "    sbert_model,\n",
    "    concept_embeddings,\n",
    "    normalize=True\n",
    ")\n",
    "clear_gpu_cache()\n",
    "print(f\"    X_test_sum shape: {X_test_sum.shape}\")\n",
    "\n",
    "# Max-based embeddings (384 dims)\n",
    "X_test_max, _ = encode_and_attention_pool_max(\n",
    "    test_max_selected,\n",
    "    sbert_model,\n",
    "    concept_embeddings,\n",
    "    normalize=True\n",
    ")\n",
    "clear_gpu_cache()\n",
    "print(f\"    X_test_max shape: {X_test_max.shape}\")\n",
    "\n",
    "# Concatenate: 768 dims total\n",
    "X_test = np.hstack([X_test_sum, X_test_max])\n",
    "print(f\"    X_test (concatenated) shape: {X_test.shape}\\n\")\n",
    "\n",
    "print(f\"✓ Encoding complete in {time.time()-start_time:.1f}s ({(time.time()-start_time)/60:.1f} min)\")\n",
    "print(f\"\\n  Final embedding dimensions: {HYPERPARAMS['final_embedding_dim']} = {HYPERPARAMS['embedding_dim']} (sum) + {HYPERPARAMS['embedding_dim']} (max)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "## Section 6: Build Concept Matrices and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build concept matrices and label vectors\n",
    "print(\"Building concept matrices and labels...\")\n",
    "\n",
    "# Training: get concepts from questionnaires (80% of training data)\n",
    "C_train = []\n",
    "y_train = []\n",
    "for subject_id in train_subject_ids:\n",
    "    label = train_posts_df_final[train_posts_df_final['subject_id'] == subject_id]['label'].iloc[0]\n",
    "    y_train.append(label)\n",
    "    \n",
    "    concept_row = concepts_df[concepts_df['subject_id'] == subject_id]\n",
    "    if len(concept_row) > 0:\n",
    "        concepts = concept_row[concept_cols].values[0]\n",
    "    else:\n",
    "        concepts = np.zeros(N_CONCEPTS)\n",
    "    C_train.append(concepts)\n",
    "\n",
    "C_train = np.array(C_train, dtype=np.float32)\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "\n",
    "# Validation: get concepts from questionnaires (20% of training data)\n",
    "C_val = []\n",
    "y_val = []\n",
    "for subject_id in val_subject_ids:\n",
    "    label = val_posts_df[val_posts_df['subject_id'] == subject_id]['label'].iloc[0]\n",
    "    y_val.append(label)\n",
    "    \n",
    "    concept_row = concepts_df[concepts_df['subject_id'] == subject_id]\n",
    "    if len(concept_row) > 0:\n",
    "        concepts = concept_row[concept_cols].values[0]\n",
    "    else:\n",
    "        concepts = np.zeros(N_CONCEPTS)\n",
    "    C_val.append(concepts)\n",
    "\n",
    "C_val = np.array(C_val, dtype=np.float32)\n",
    "y_val = np.array(y_val, dtype=np.float32)\n",
    "\n",
    "# Test: zeros for concepts (no ground truth available)\n",
    "C_test = np.zeros((len(test_subject_ids), N_CONCEPTS), dtype=np.float32)\n",
    "y_test = []\n",
    "for subject_id in test_subject_ids:\n",
    "    label = test_posts_df_final[test_posts_df_final['subject_id'] == subject_id]['label'].iloc[0]\n",
    "    y_test.append(label)\n",
    "y_test = np.array(y_test, dtype=np.float32)\n",
    "\n",
    "print(\"✓ Matrices built\")\n",
    "print(f\"  Train: X={X_train.shape}, C={C_train.shape}, y={y_train.shape}\")\n",
    "print(f\"  Val:   X={X_val.shape}, C={C_val.shape}, y={y_val.shape}\")\n",
    "print(f\"  Test:  X={X_test.shape}, C={C_test.shape}, y={y_test.shape}\")\n",
    "print(f\"\\n  Training label distribution: {np.bincount(y_train.astype(int))}\")\n",
    "print(f\"  Validation label distribution: {np.bincount(y_val.astype(int))}\")\n",
    "print(f\"  Test label distribution: {np.bincount(y_test.astype(int))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "## Section 7: Compute Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights for imbalanced dataset\n",
    "n_negative = int(np.sum(y_train == 0))\n",
    "n_positive = int(np.sum(y_train == 1))\n",
    "pos_weight = n_negative / n_positive\n",
    "\n",
    "print(f\"Class imbalance:\")\n",
    "print(f\"  Negative samples: {n_negative}\")\n",
    "print(f\"  Positive samples: {n_positive}\")\n",
    "print(f\"  Ratio: 1:{pos_weight:.2f}\")\n",
    "print(f\"  Computed pos_weight: {pos_weight:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "## Section 8: Save All Datasets\n",
    "\n",
    "Save everything for fast loading by training pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed datasets to disk\n",
    "print(\"Saving datasets...\")\n",
    "\n",
    "# Save numpy arrays\n",
    "np.savez_compressed(\n",
    "    os.path.join(SAVE_DIR, \"train_data.npz\"),\n",
    "    X=X_train,\n",
    "    C=C_train,\n",
    "    y=y_train,\n",
    "    subject_ids=np.array(train_subject_ids)\n",
    ")\n",
    "\n",
    "np.savez_compressed(\n",
    "    os.path.join(SAVE_DIR, \"val_data.npz\"),\n",
    "    X=X_val,\n",
    "    C=C_val,\n",
    "    y=y_val,\n",
    "    subject_ids=np.array(val_subject_ids)\n",
    ")\n",
    "\n",
    "np.savez_compressed(\n",
    "    os.path.join(SAVE_DIR, \"test_data.npz\"),\n",
    "    X=X_test,\n",
    "    C=C_test,\n",
    "    y=y_test,\n",
    "    subject_ids=np.array(test_subject_ids)\n",
    ")\n",
    "\n",
    "# Save class weights info\n",
    "class_info = {\n",
    "    \"n_positive\": n_positive,\n",
    "    \"n_negative\": n_negative,\n",
    "    \"pos_weight\": float(pos_weight)\n",
    "}\n",
    "\n",
    "with open(os.path.join(SAVE_DIR, \"class_weights.json\"), 'w') as f:\n",
    "    json.dump(class_info, f, indent=4)\n",
    "\n",
    "print(f\"✓ Datasets saved to {SAVE_DIR}\")\n",
    "print(f\"  train_data.npz: {X_train.shape[0]} samples, {X_train.shape[1]} dims (768)\")\n",
    "print(f\"  val_data.npz:   {X_val.shape[0]} samples, {X_val.shape[1]} dims (768)\")\n",
    "print(f\"  test_data.npz:  {X_test.shape[0]} samples, {X_test.shape[1]} dims (768)\")\n",
    "print(f\"  class_weights.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-36",
   "metadata": {},
   "source": [
    "## Section 9: Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temporary directory\n",
    "try:\n",
    "    shutil.rmtree(temp_dir)\n",
    "    print(f\"✓ Cleaned up temporary directory: {temp_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Failed to clean up temporary directory: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"      LONG ALTERNATIVE DATASET PREPARATION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nSaved files:\")\n",
    "print(f\"  {SAVE_DIR}/train_data.npz\")\n",
    "print(f\"  {SAVE_DIR}/val_data.npz\")\n",
    "print(f\"  {SAVE_DIR}/test_data.npz\")\n",
    "print(f\"  {SAVE_DIR}/class_weights.json\")\n",
    "print(\"\\nData split strategy:\")\n",
    "print(\"  - Training: 80% of train folder (~389 subjects)\")\n",
    "print(\"  - Validation: 20% of train folder (~97 subjects)\")\n",
    "print(\"  - Test: 100% of test folder (401 subjects)\")\n",
    "print(\"\\nKey differences from original:\")\n",
    "print(\"  - Uses BOTH sum and max of concept similarities\")\n",
    "print(\"  - Retrieves posts separately for each method\")\n",
    "print(\"  - Concatenates embeddings: 384 (sum) + 384 (max) = 768 dims\")\n",
    "print(\"  - Captures both multi-concept posts (sum) and single-concept experts (max)\")\n",
    "print(\"\\nUse this data with CEM/CBM training notebooks!\")\n",
    "print(\"Note: Update model input_dim to 768 instead of 384\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "38concept_embedding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
