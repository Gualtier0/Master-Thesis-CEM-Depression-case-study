{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# CBM Hard Bottleneck - Two-Stage Training (Alternative Pipeline)\n",
    "\n",
    "**Runtime:** ~20-30 minutes\n",
    "\n",
    "This notebook implements a **true two-stage** Concept Bottleneck Model:\n",
    "1. **Stage 1**: Train concept predictor (X → Concepts)\n",
    "2. **Stage 2**: Freeze concept predictor, train task classifier (Concepts → Y)\n",
    "\n",
    "**Key Features:**\n",
    "- Uses alternative dataset with SUM-based concept scoring\n",
    "- Validation set has TRUE concept labels (better supervision)\n",
    "- Hard bottleneck with discrete concept predictions\n",
    "- LDAM loss for imbalanced task classification\n",
    "- Separate optimizers for each stage\n",
    "\n",
    "**Prerequisites:** Run `0_prepare_alternative_attention_dataset.ipynb` first!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Section 0: Configuration & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef,\n",
    "    roc_auc_score,\n",
    "    balanced_accuracy_score,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Random seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "pl.seed_everything(SEED)\n",
    "\n",
    "print(f\"✓ Random seed set to {SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Using MacBook GPU (MPS)\n"
     ]
    }
   ],
   "source": [
    "# Detect device (MPS/CUDA/CPU)\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "    print(\"✓ Using MacBook GPU (MPS)\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "    print(\"✓ Using CUDA GPU\")\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "    print(\"⚠ Using CPU (will be slow)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Paths configured\n",
      "  Project root: /Users/gualtieromarencoturi/Desktop/thesis/Master-Thesis-CEM-Depression-etc-case-study\n",
      "  Dataset dir: /Users/gualtieromarencoturi/Desktop/thesis/Master-Thesis-CEM-Depression-etc-case-study/data/processed/alternative_attention_pipeline\n",
      "  Output dir: outputs_cbm_hard_alt\n",
      "\n",
      "  NOTE: Using ALTERNATIVE dataset (SUM-based concept scoring)\n",
      "        Validation set has TRUE concept labels!\n"
     ]
    }
   ],
   "source": [
    "# Define paths - USING ALTERNATIVE PIPELINE\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "DATA_PROCESSED = os.path.join(PROJECT_ROOT, \"data/processed\")\n",
    "DATASET_DIR = os.path.join(DATA_PROCESSED, \"alternative_attention_pipeline\")  # CHANGED\n",
    "OUTPUT_DIR = \"outputs_cbm_hard_alt\"  # CHANGED\n",
    "\n",
    "print(\"✓ Paths configured\")\n",
    "print(f\"  Project root: {PROJECT_ROOT}\")\n",
    "print(f\"  Dataset dir: {DATASET_DIR}\")\n",
    "print(f\"  Output dir: {OUTPUT_DIR}\")\n",
    "print(\"\\n  NOTE: Using ALTERNATIVE dataset (SUM-based concept scoring)\")\n",
    "print(\"        Validation set has TRUE concept labels!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Defined 21 BDI-II concepts\n"
     ]
    }
   ],
   "source": [
    "# Define 21 BDI-II concept names\n",
    "CONCEPT_NAMES = [\n",
    "    \"Sadness\", \"Pessimism\", \"Past failure\", \"Loss of pleasure\",\n",
    "    \"Guilty feelings\", \"Punishment feelings\", \"Self-dislike\", \"Self-criticalness\",\n",
    "    \"Suicidal thoughts or wishes\", \"Crying\", \"Agitation\", \"Loss of interest\",\n",
    "    \"Indecisiveness\", \"Worthlessness\", \"Loss of energy\", \"Changes in sleeping pattern\",\n",
    "    \"Irritability\", \"Changes in appetite\", \"Concentration difficulty\",\n",
    "    \"Tiredness or fatigue\", \"Loss of interest in sex\"\n",
    "]\n",
    "N_CONCEPTS = len(CONCEPT_NAMES)\n",
    "\n",
    "print(f\"✓ Defined {N_CONCEPTS} BDI-II concepts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Hyperparameters configured (TWO-STAGE)\n",
      "  Stage 1: Concept predictor - 100 epochs\n",
      "  Stage 2: Task classifier - 100 epochs\n",
      "  Hard bottleneck threshold: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters - TWO-STAGE CONFIGURATION\n",
    "HYPERPARAMS = {\n",
    "    # Model architecture\n",
    "    \"embedding_dim\": 384,\n",
    "    \"n_concepts\": 21,\n",
    "    \"n_tasks\": 1,\n",
    "    \n",
    "    # STAGE 1: Concept predictor training\n",
    "    \"stage1_batch_size_train\": 32,\n",
    "    \"stage1_batch_size_eval\": 64,\n",
    "    \"stage1_max_epochs\": 100,\n",
    "    \"stage1_learning_rate\": 0.001,\n",
    "    \"stage1_weight_decay\": 0.0001,\n",
    "    \n",
    "    # STAGE 2: Task classifier training\n",
    "    \"stage2_batch_size_train\": 32,\n",
    "    \"stage2_batch_size_eval\": 64,\n",
    "    \"stage2_max_epochs\": 100,\n",
    "    \"stage2_learning_rate\": 0.01,\n",
    "    \"stage2_weight_decay\": 0.0001,\n",
    "    \n",
    "    # Hard bottleneck\n",
    "    \"concept_threshold\": 0.5,\n",
    "    \n",
    "    # LDAM Loss for Stage 2 (task)\n",
    "    \"use_ldam_loss\": True,\n",
    "    \"n_positive\": None,  # Will be set after loading data\n",
    "    \"n_negative\": None,  # Will be set after loading data\n",
    "    \"ldam_max_margin\": 0.5,\n",
    "    \"ldam_scale\": 40,\n",
    "}\n",
    "\n",
    "print(\"✓ Hyperparameters configured (TWO-STAGE)\")\n",
    "print(f\"  Stage 1: Concept predictor - {HYPERPARAMS['stage1_max_epochs']} epochs\")\n",
    "print(f\"  Stage 2: Task classifier - {HYPERPARAMS['stage2_max_epochs']} epochs\")\n",
    "print(f\"  Hard bottleneck threshold: {HYPERPARAMS['concept_threshold']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Section 1: Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed datasets...\n",
      "✓ Loaded training data:\n",
      "  X_train: (388, 384)\n",
      "  C_train: (388, 21)\n",
      "  y_train: (388,)\n",
      "  Subject IDs: 388\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "print(\"Loading preprocessed datasets...\")\n",
    "\n",
    "train_data = np.load(os.path.join(DATASET_DIR, \"train_data.npz\"))\n",
    "X_train = train_data['X']\n",
    "C_train = train_data['C']\n",
    "y_train = train_data['y']\n",
    "train_subject_ids = train_data['subject_ids']\n",
    "\n",
    "print(f\"✓ Loaded training data:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  C_train: {C_train.shape}\")\n",
    "print(f\"  y_train: {y_train.shape}\")\n",
    "print(f\"  Subject IDs: {len(train_subject_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded validation data:\n",
      "  X_val: (98, 384)\n",
      "  C_val: (98, 21) - has TRUE concept labels!\n",
      "  y_val: (98,)\n",
      "  Non-zero concept values: 126\n"
     ]
    }
   ],
   "source": [
    "# Load validation data\n",
    "val_data = np.load(os.path.join(DATASET_DIR, \"val_data.npz\"))\n",
    "X_val = val_data['X']\n",
    "C_val = val_data['C']\n",
    "y_val = val_data['y']\n",
    "val_subject_ids = val_data['subject_ids']\n",
    "\n",
    "print(f\"✓ Loaded validation data:\")\n",
    "print(f\"  X_val: {X_val.shape}\")\n",
    "print(f\"  C_val: {C_val.shape} - has TRUE concept labels!\")\n",
    "print(f\"  y_val: {y_val.shape}\")\n",
    "print(f\"  Non-zero concept values: {np.count_nonzero(C_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded test data:\n",
      "  X_test: (401, 384)\n",
      "  C_test: (401, 21)\n",
      "  y_test: (401,)\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "test_data = np.load(os.path.join(DATASET_DIR, \"test_data.npz\"))\n",
    "X_test = test_data['X']\n",
    "C_test = test_data['C']\n",
    "y_test = test_data['y']\n",
    "test_subject_ids = test_data['subject_ids']\n",
    "\n",
    "print(f\"✓ Loaded test data:\")\n",
    "print(f\"  X_test: {X_test.shape}\")\n",
    "print(f\"  C_test: {C_test.shape}\")\n",
    "print(f\"  y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded class weights:\n",
      "  Negative samples: 322\n",
      "  Positive samples: 66\n",
      "  Ratio: 1:4.88\n",
      "  pos_weight: 4.8788\n"
     ]
    }
   ],
   "source": [
    "# Load class weights\n",
    "with open(os.path.join(DATASET_DIR, \"class_weights.json\"), 'r') as f:\n",
    "    class_info = json.load(f)\n",
    "\n",
    "n_positive = class_info['n_positive']\n",
    "n_negative = class_info['n_negative']\n",
    "pos_weight = class_info['pos_weight']\n",
    "\n",
    "# Update HYPERPARAMS with actual class counts for LDAM\n",
    "HYPERPARAMS['n_positive'] = n_positive\n",
    "HYPERPARAMS['n_negative'] = n_negative\n",
    "\n",
    "print(f\"✓ Loaded class weights:\")\n",
    "print(f\"  Negative samples: {n_negative}\")\n",
    "print(f\"  Positive samples: {n_positive}\")\n",
    "print(f\"  Ratio: 1:{pos_weight:.2f}\")\n",
    "print(f\"  pos_weight: {pos_weight:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Section 2: PyTorch Dataset & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CBMDataset class defined\n"
     ]
    }
   ],
   "source": [
    "class CBMDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for CBM model.\"\"\"\n",
    "    \n",
    "    def __init__(self, X, C, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.C = torch.tensor(C, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.C[idx]\n",
    "\n",
    "print(\"✓ CBMDataset class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Datasets created\n",
      "  Train: 388 samples\n",
      "  Val: 98 samples\n",
      "  Test: 401 samples\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_dataset = CBMDataset(X_train, C_train, y_train)\n",
    "val_dataset = CBMDataset(X_val, C_val, y_val)\n",
    "test_dataset = CBMDataset(X_test, C_test, y_test)\n",
    "\n",
    "print(\"✓ Datasets created\")\n",
    "print(f\"  Train: {len(train_dataset)} samples\")\n",
    "print(f\"  Val: {len(val_dataset)} samples\")\n",
    "print(f\"  Test: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Section 3: Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ LDAM Loss defined\n"
     ]
    }
   ],
   "source": [
    "# LDAM Loss (for class imbalance in Stage 2)\n",
    "class LDAMLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Label-Distribution-Aware Margin (LDAM) Loss for long-tailed recognition.\n",
    "    Creates class-dependent margins to make decision boundaries harder for minority classes.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_positive, n_negative, max_margin=0.5, scale=30):\n",
    "        super(LDAMLoss, self).__init__()\n",
    "        self.max_margin = max_margin\n",
    "        self.scale = scale\n",
    "        \n",
    "        # Compute class frequencies\n",
    "        total = n_positive + n_negative\n",
    "        freq_pos = n_positive / total\n",
    "        freq_neg = n_negative / total\n",
    "        \n",
    "        # Compute margins: minority class gets larger margin\n",
    "        margin_pos = max_margin * (freq_pos ** (-0.25))\n",
    "        margin_neg = max_margin * (freq_neg ** (-0.25))\n",
    "        \n",
    "        self.register_buffer('margin_pos', torch.tensor(margin_pos))\n",
    "        self.register_buffer('margin_neg', torch.tensor(margin_neg))\n",
    "    \n",
    "    def forward(self, logits, targets):\n",
    "        logits = logits.view(-1)\n",
    "        targets = targets.view(-1).float()\n",
    "        \n",
    "        # Apply class-dependent margins\n",
    "        margin = targets * self.margin_pos + (1 - targets) * (-self.margin_neg)\n",
    "        adjusted_logits = (logits - margin) * self.scale\n",
    "        \n",
    "        return F.binary_cross_entropy_with_logits(adjusted_logits, targets, reduction='mean')\n",
    "\n",
    "print(\"✓ LDAM Loss defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Stage 1: ConceptPredictor defined\n"
     ]
    }
   ],
   "source": [
    "# STAGE 1: Concept Predictor\n",
    "class ConceptPredictor(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Stage 1: Concept predictor (X → C)\n",
    "    \n",
    "    This model learns to predict concept labels from input embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        n_concepts,\n",
    "        learning_rate=0.001,\n",
    "        weight_decay=1e-4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Concept extractor network\n",
    "        self.concept_extractor = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, n_concepts)\n",
    "        )\n",
    "        \n",
    "        # Loss function for concepts\n",
    "        self.concept_loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.concept_extractor(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, c = batch\n",
    "        c_logits = self(x)\n",
    "        loss = self.concept_loss_fn(c_logits, c)\n",
    "        \n",
    "        self.log('train_concept_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, c = batch\n",
    "        c_logits = self(x)\n",
    "        loss = self.concept_loss_fn(c_logits, c)\n",
    "        \n",
    "        self.log('val_concept_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.learning_rate,\n",
    "            weight_decay=self.hparams.weight_decay\n",
    "        )\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=10,\n",
    "            min_lr=1e-6,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_concept_loss\",\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "\n",
    "print(\"✓ Stage 1: ConceptPredictor defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Stage 2: TaskClassifier defined\n"
     ]
    }
   ],
   "source": [
    "# STAGE 2: Task Classifier\n",
    "class TaskClassifier(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Stage 2: Task classifier (C → Y)\n",
    "    \n",
    "    This model takes predicted concepts and classifies the task.\n",
    "    The concept predictor is frozen during this stage.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        concept_predictor,\n",
    "        n_concepts,\n",
    "        task_output_dim,\n",
    "        concept_threshold=0.5,\n",
    "        learning_rate=0.01,\n",
    "        weight_decay=1e-4,\n",
    "        use_ldam_loss=True,\n",
    "        n_positive=83,\n",
    "        n_negative=403,\n",
    "        ldam_max_margin=0.5,\n",
    "        ldam_scale=30,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['concept_predictor'])\n",
    "        \n",
    "        # Frozen concept predictor from Stage 1\n",
    "        self.concept_predictor = concept_predictor\n",
    "        # Freeze all concept predictor parameters\n",
    "        for param in self.concept_predictor.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Task classifier (operates on discrete concepts)\n",
    "        self.task_classifier = nn.Sequential(\n",
    "            nn.Linear(n_concepts, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, task_output_dim)\n",
    "        )\n",
    "        \n",
    "        # Loss function for task\n",
    "        if use_ldam_loss:\n",
    "            self.task_loss_fn = LDAMLoss(n_positive, n_negative, ldam_max_margin, ldam_scale)\n",
    "            print(f\"  Using LDAM Loss (margin={ldam_max_margin}, scale={ldam_scale})\")\n",
    "        else:\n",
    "            pos_weight_tensor = torch.tensor([n_negative / n_positive], dtype=torch.float32)\n",
    "            self.task_loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "            print(f\"  Using BCE Loss with pos_weight={pos_weight_tensor.item():.2f}\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Get concept predictions from frozen predictor\n",
    "        with torch.no_grad():\n",
    "            c_logits = self.concept_predictor(x)\n",
    "            c_probs = torch.sigmoid(c_logits)\n",
    "        \n",
    "        # Hard bottleneck: binarize concepts\n",
    "        c_discrete = (c_probs >= self.hparams.concept_threshold).float()\n",
    "        \n",
    "        # Task prediction from discrete concepts\n",
    "        y_logits = self.task_classifier(c_discrete)\n",
    "        \n",
    "        return y_logits, c_discrete\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, c = batch\n",
    "        y_logits, _ = self(x)\n",
    "        loss = self.task_loss_fn(y_logits.squeeze(), y.squeeze())\n",
    "        \n",
    "        self.log('train_task_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, c = batch\n",
    "        y_logits, _ = self(x)\n",
    "        loss = self.task_loss_fn(y_logits.squeeze(), y.squeeze())\n",
    "        \n",
    "        self.log('val_task_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # Only optimize task classifier parameters (concept predictor is frozen)\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.task_classifier.parameters(),\n",
    "            lr=self.hparams.learning_rate,\n",
    "            weight_decay=self.hparams.weight_decay\n",
    "        )\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=10,\n",
    "            min_lr=1e-6,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_task_loss\",\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "\n",
    "print(\"✓ Stage 2: TaskClassifier defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Section 4: STAGE 1 - Train Concept Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "          STAGE 1: TRAINING CONCEPT PREDICTOR (X → C)\n",
      "======================================================================\n",
      "\n",
      "Training concept predictor to predict all 21 BDI-II concepts\n",
      "Validation set has TRUE concept labels (better supervision!)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"          STAGE 1: TRAINING CONCEPT PREDICTOR (X → C)\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(\"Training concept predictor to predict all 21 BDI-II concepts\")\n",
    "print(\"Validation set has TRUE concept labels (better supervision!)\")\n",
    "print()\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Stage 1 DataLoaders created\n",
      "  Train batches: 13\n",
      "  Val batches: 2\n"
     ]
    }
   ],
   "source": [
    "# Create Stage 1 DataLoaders\n",
    "stage1_train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=HYPERPARAMS['stage1_batch_size_train'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "stage1_val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=HYPERPARAMS['stage1_batch_size_eval'],\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"✓ Stage 1 DataLoaders created\")\n",
    "print(f\"  Train batches: {len(stage1_train_loader)}\")\n",
    "print(f\"  Val batches: {len(stage1_val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Stage 1 model initialized\n",
      "  Learning rate: 0.001\n",
      "  Max epochs: 100\n"
     ]
    }
   ],
   "source": [
    "# Initialize Stage 1 model\n",
    "concept_predictor = ConceptPredictor(\n",
    "    input_dim=HYPERPARAMS['embedding_dim'],\n",
    "    n_concepts=HYPERPARAMS['n_concepts'],\n",
    "    learning_rate=HYPERPARAMS['stage1_learning_rate'],\n",
    "    weight_decay=HYPERPARAMS['stage1_weight_decay'],\n",
    ")\n",
    "\n",
    "print(\"✓ Stage 1 model initialized\")\n",
    "print(f\"  Learning rate: {HYPERPARAMS['stage1_learning_rate']}\")\n",
    "print(f\"  Max epochs: {HYPERPARAMS['stage1_max_epochs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cell-25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Stage 1 trainer configured\n"
     ]
    }
   ],
   "source": [
    "# Stage 1 callbacks\n",
    "stage1_early_stop = EarlyStopping(\n",
    "    monitor='val_concept_loss',\n",
    "    patience=20,\n",
    "    mode='min',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "stage1_checkpoint = ModelCheckpoint(\n",
    "    monitor=\"val_concept_loss\",\n",
    "    dirpath=os.path.join(OUTPUT_DIR, \"models/stage1\"),\n",
    "    filename=\"concept-predictor-{epoch:02d}-{val_concept_loss:.2f}\",\n",
    "    save_top_k=1,\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "# Stage 1 trainer\n",
    "stage1_trainer = pl.Trainer(\n",
    "    max_epochs=HYPERPARAMS['stage1_max_epochs'],\n",
    "    accelerator=DEVICE,\n",
    "    devices=1,\n",
    "    logger=CSVLogger(save_dir=os.path.join(OUTPUT_DIR, \"logs\"), name=\"stage1_concepts\"),\n",
    "    log_every_n_steps=10,\n",
    "    callbacks=[stage1_early_stop, stage1_checkpoint],\n",
    "    enable_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"✓ Stage 1 trainer configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cell-26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/38concept_embedding/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name              | Type              | Params\n",
      "--------------------------------------------------------\n",
      "0 | concept_extractor | Sequential        | 335 K \n",
      "1 | concept_loss_fn   | BCEWithLogitsLoss | 0     \n",
      "--------------------------------------------------------\n",
      "335 K     Trainable params\n",
      "0         Non-trainable params\n",
      "335 K     Total params\n",
      "1.342     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Stage 1 training...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63cc8a5fb43b4ba4b645a5f2a46c6740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/38concept_embedding/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/miniconda3/envs/38concept_embedding/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c09bfd0a9aac492996d0abd6906ca3a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b90d79eb7b64f4a8071f29a27ddd8aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_concept_loss improved. New best score: 0.509\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519957faf52b4c23b3921ac6f8ba612b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_concept_loss improved by 0.248 >= min_delta = 0.0. New best score: 0.261\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0395aecf404ec4b5633ab5611d8bc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_concept_loss improved by 0.052 >= min_delta = 0.0. New best score: 0.209\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598cd2ad4bb045099d2457a463e1f9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_concept_loss improved by 0.010 >= min_delta = 0.0. New best score: 0.199\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44050346883745598ac27dea01511172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a99659f5db4ecda673a1016b5da4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21b83d365704d29bb393701bbd10e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e0511fcc23426fa19cd0d91c44511e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687ac25c25354282ae95eb620accd9e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70dc38a932b4a13b298f1a4f3f29d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581501737563486e9becb8cb686a69bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe53bfcd51640358bce296528e6a322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc25552c1cf4657b445d7a1fa26e41d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa60424b29c4eed8bc59d22950c7df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e519f1fdeae4ff5bd7ff1c2fa88cf48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "795fcd7d408c4dd6aa55c795836cee83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0f26804e904024af895c2414189161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed0d83d826504cafb4ef27a7651b5c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29b7c65e0a34a41b7e42dfdbee0dfbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e15db0ee142481c83126b3d376dca85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8c4731f36b40af8ea0e4b52127ba15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8581db2b91443ab466cdd09609cca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651fb4651c7a4365b064dd218a01de84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ca93b4717a4acaac3009bb33070d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_concept_loss did not improve in the last 20 records. Best score: 0.199. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Stage 1 training complete!\n"
     ]
    }
   ],
   "source": [
    "# Train Stage 1\n",
    "print(\"\\nStarting Stage 1 training...\\n\")\n",
    "stage1_trainer.fit(concept_predictor, stage1_train_loader, stage1_val_loader)\n",
    "print(\"\\n✓ Stage 1 training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## Section 5: STAGE 2 - Train Task Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cell-28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "          STAGE 2: TRAINING TASK CLASSIFIER (C → Y)\n",
      "======================================================================\n",
      "\n",
      "Freezing concept predictor and training task classifier\n",
      "Using LDAM Loss for imbalanced classification\n",
      "Hard bottleneck threshold: 0.5\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"          STAGE 2: TRAINING TASK CLASSIFIER (C → Y)\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(\"Freezing concept predictor and training task classifier\")\n",
    "print(f\"Using LDAM Loss for imbalanced classification\")\n",
    "print(f\"Hard bottleneck threshold: {HYPERPARAMS['concept_threshold']}\")\n",
    "print()\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cell-29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Stage 2 DataLoaders created\n",
      "  Train batches: 13\n",
      "  Val batches: 2\n"
     ]
    }
   ],
   "source": [
    "# Create Stage 2 DataLoaders\n",
    "stage2_train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=HYPERPARAMS['stage2_batch_size_train'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "stage2_val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=HYPERPARAMS['stage2_batch_size_eval'],\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"✓ Stage 2 DataLoaders created\")\n",
    "print(f\"  Train batches: {len(stage2_train_loader)}\")\n",
    "print(f\"  Val batches: {len(stage2_val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cell-30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using LDAM Loss (margin=0.5, scale=40)\n",
      "✓ Task classifier bias initialized to log-odds: -1.5849\n",
      "\n",
      "✓ Stage 2 model initialized\n",
      "  Concept predictor: FROZEN (no gradient updates)\n",
      "  Learning rate: 0.01\n",
      "  Max epochs: 100\n"
     ]
    }
   ],
   "source": [
    "# Initialize Stage 2 model with frozen concept predictor\n",
    "task_classifier = TaskClassifier(\n",
    "    concept_predictor=concept_predictor,\n",
    "    n_concepts=HYPERPARAMS['n_concepts'],\n",
    "    task_output_dim=1,\n",
    "    concept_threshold=HYPERPARAMS['concept_threshold'],\n",
    "    learning_rate=HYPERPARAMS['stage2_learning_rate'],\n",
    "    weight_decay=HYPERPARAMS['stage2_weight_decay'],\n",
    "    use_ldam_loss=HYPERPARAMS['use_ldam_loss'],\n",
    "    n_positive=HYPERPARAMS['n_positive'],\n",
    "    n_negative=HYPERPARAMS['n_negative'],\n",
    "    ldam_max_margin=HYPERPARAMS['ldam_max_margin'],\n",
    "    ldam_scale=HYPERPARAMS['ldam_scale'],\n",
    ")\n",
    "\n",
    "# Initialize task classifier bias\n",
    "pos_frac = HYPERPARAMS['n_positive'] / (HYPERPARAMS['n_positive'] + HYPERPARAMS['n_negative'])\n",
    "bias_init = np.log(pos_frac / (1 - pos_frac))\n",
    "if hasattr(task_classifier.task_classifier[-1], 'bias') and task_classifier.task_classifier[-1].bias is not None:\n",
    "    task_classifier.task_classifier[-1].bias.data.fill_(bias_init)\n",
    "    print(f\"✓ Task classifier bias initialized to log-odds: {bias_init:.4f}\")\n",
    "\n",
    "print(\"\\n✓ Stage 2 model initialized\")\n",
    "print(f\"  Concept predictor: FROZEN (no gradient updates)\")\n",
    "print(f\"  Learning rate: {HYPERPARAMS['stage2_learning_rate']}\")\n",
    "print(f\"  Max epochs: {HYPERPARAMS['stage2_max_epochs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cell-31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Stage 2 trainer configured\n"
     ]
    }
   ],
   "source": [
    "# Stage 2 callbacks\n",
    "stage2_early_stop = EarlyStopping(\n",
    "    monitor='val_task_loss',\n",
    "    patience=20,\n",
    "    mode='min',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "stage2_checkpoint = ModelCheckpoint(\n",
    "    monitor=\"val_task_loss\",\n",
    "    dirpath=os.path.join(OUTPUT_DIR, \"models/stage2\"),\n",
    "    filename=\"task-classifier-{epoch:02d}-{val_task_loss:.2f}\",\n",
    "    save_top_k=1,\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "# Stage 2 trainer\n",
    "stage2_trainer = pl.Trainer(\n",
    "    max_epochs=HYPERPARAMS['stage2_max_epochs'],\n",
    "    accelerator=DEVICE,\n",
    "    devices=1,\n",
    "    logger=CSVLogger(save_dir=os.path.join(OUTPUT_DIR, \"logs\"), name=\"stage2_task\"),\n",
    "    log_every_n_steps=10,\n",
    "    callbacks=[stage2_early_stop, stage2_checkpoint],\n",
    "    enable_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"✓ Stage 2 trainer configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cell-32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name              | Type             | Params\n",
      "-------------------------------------------------------\n",
      "0 | concept_predictor | ConceptPredictor | 335 K \n",
      "1 | task_classifier   | Sequential       | 11.5 K\n",
      "2 | task_loss_fn      | LDAMLoss         | 0     \n",
      "-------------------------------------------------------\n",
      "11.5 K    Trainable params\n",
      "335 K     Non-trainable params\n",
      "346 K     Total params\n",
      "1.388     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Stage 2 training...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aac6305df884191bf021b4675aa478a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba0b7991af24f99a18d900d1becad9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b399a77edb744bf9bf9531af9c92aa42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_task_loss improved. New best score: 11.822\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee05808c6d0545d1ad11e462b80bd79e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_task_loss improved by 2.426 >= min_delta = 0.0. New best score: 9.396\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd57090ed0954cc08b11ee0ae574a84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3579c46ab4b4fadbf260a2dcd62b5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_task_loss improved by 0.137 >= min_delta = 0.0. New best score: 9.259\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b16318a0bb84bf79658080a3886df8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f26bad29ae042309d898a4805174552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9515ae9136e24156ba294ba9cbfebf15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ac45f898284369914e2322230cea85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e3516c76254d12a99b66a1ef727cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc62b0e285b4dcc8f6fe776f4d68064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a70a929031f4d1fb73c25e157c88e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed112185d824405b358400b8336ce0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7862397d07304a72adece26f4e32129d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a319023bf9dc4f90ae727fbf371b2787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c035ce3e13f453c80e33669612a11ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17015ddde15f4340bbf545fc9d3d1f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1aa9a24c7214da8a1f97fdfc241fc58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5754eb16a80c46928714dab659d93fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16cab07cb38d484b973b70f32379dc61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647afd05da9b4eb0b500781dcf41a43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e489fe37610b4430964275a12bd8bab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef89f2ee1204c2da689c424f590b038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b62c9884784dd7876824fa8819496a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_task_loss improved by 0.141 >= min_delta = 0.0. New best score: 9.118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ac747995674edfa1d4f18cd96ce37d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b63595ae41c47138ed1713755e77cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca65f08ff2c4646826f5b9aa3f8f1c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55048b8767c74eb7be387f8cc3baafdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b2c5f9f9fc4a7c9bfd096ca5839f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43090c7c4597448a814f0e1db814089c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1362bb219f4b76886eac48bb6ec7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236c8ecd2d5e4f0db188256405056da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374d6e15705b4d02ab18adef47802888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a526ac6d32bf4c659ab5b09e1de4e899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5163b816c617478e93c6c843cd3ba3d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d055459a6559449fa98e0d42386d721d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577fdd90c23b43d6a67c3417df716a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971128d60f394382bac481ed6847f4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335a089d7cd64c7e9026537dc6927182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa029e7701747c3b2ef422260307bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_task_loss improved by 0.029 >= min_delta = 0.0. New best score: 9.089\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703aa7ead5c04ebf8aa7a1da02c4a148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_task_loss improved by 0.222 >= min_delta = 0.0. New best score: 8.867\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f5586563144f32970a7431ed05c70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1c6c44b5d9459a8e308b94e344d410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eae02297b7d4364a970a25ea32ffa35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_task_loss improved by 0.925 >= min_delta = 0.0. New best score: 7.942\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a1bcd57ef94467a00172576901e776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d6eeddc8384099a8dd5f2238f7d522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0fc59a7bb94390b0939fc8a4074f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7841169f71d9427088ab132c15c5825b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a03a16ec98b4eae9538e6a1816e9530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23d55de28054228b5e971065a2853e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe3dfb88e3947318798c8af9e37c6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3490569dea7497f8a842ce3d3c462c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d430ee5bfb04433f91cafd632a27247e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e224d7e8a74adabcc0c4bb15acdb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9af8c62b6345a497a36129f1a2190d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47eb4f55bc04eaf9ebd75c8cb50b212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc35eff4b8646e597cb4719629e952d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8598c16cfc74b2786010f9dbf223157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8dad85bd3c4061839a3db86f254aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51406e31238c4c77a2e1c6b939560e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea96aa55cd9444a80317fe4c06e7b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06854b7e44a48139789059df8d3ed59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff89d14ac3474c2faa51bfe202e1d4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56552a0752f7486c8cafc7df402f58f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_task_loss did not improve in the last 20 records. Best score: 7.942. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Stage 2 training complete!\n"
     ]
    }
   ],
   "source": [
    "# Train Stage 2\n",
    "print(\"\\nStarting Stage 2 training...\\n\")\n",
    "stage2_trainer.fit(task_classifier, stage2_train_loader, stage2_val_loader)\n",
    "print(\"\\n✓ Stage 2 training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-33",
   "metadata": {},
   "source": [
    "## Section 6: Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cell-34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model set to evaluation mode\n"
     ]
    }
   ],
   "source": [
    "# Set model to evaluation mode\n",
    "task_classifier.eval()\n",
    "\n",
    "# Move model to device\n",
    "device_obj = torch.device(DEVICE)\n",
    "task_classifier = task_classifier.to(device_obj)\n",
    "\n",
    "print(\"✓ Model set to evaluation mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cell-35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Test DataLoader created (7 batches)\n"
     ]
    }
   ],
   "source": [
    "# Create test DataLoader\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=HYPERPARAMS['stage2_batch_size_eval'],\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"✓ Test DataLoader created ({len(test_loader)} batches)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cell-36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selecting decision threshold on validation set...\n",
      "✓ Selected validation threshold: 0.77\n",
      "  Validation MCC: 0.5075\n"
     ]
    }
   ],
   "source": [
    "# Run inference on validation set for threshold selection\n",
    "print(\"\\nSelecting decision threshold on validation set...\")\n",
    "\n",
    "y_val_true = []\n",
    "y_val_prob = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch, c_batch in stage2_val_loader:\n",
    "        x_batch = x_batch.to(device_obj)\n",
    "        \n",
    "        y_logits, _ = task_classifier(x_batch)\n",
    "        y_probs = torch.sigmoid(y_logits).cpu().squeeze().numpy()\n",
    "        \n",
    "        y_val_true.extend(y_batch.numpy().astype(int).tolist())\n",
    "        y_val_prob.extend(y_probs.tolist() if isinstance(y_probs, np.ndarray) else [y_probs])\n",
    "\n",
    "y_val_true = np.array(y_val_true)\n",
    "y_val_prob = np.array(y_val_prob)\n",
    "\n",
    "# Find best threshold\n",
    "best_threshold = 0.5\n",
    "best_mcc = -1.0\n",
    "\n",
    "for threshold in np.linspace(0.1, 0.9, 50):\n",
    "    y_pred_temp = (y_val_prob >= threshold).astype(int)\n",
    "    mcc = matthews_corrcoef(y_val_true, y_pred_temp)\n",
    "    if mcc > best_mcc:\n",
    "        best_mcc = mcc\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"✓ Selected validation threshold: {best_threshold:.2f}\")\n",
    "print(f\"  Validation MCC: {best_mcc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cell-37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running inference on test set...\n",
      "✓ Inference complete\n",
      "  Probabilities shape: (401,)\n",
      "  Concept probs shape: (401, 21)\n"
     ]
    }
   ],
   "source": [
    "# Run inference on test set\n",
    "print(\"\\nRunning inference on test set...\")\n",
    "\n",
    "y_true_list = []\n",
    "y_prob_list = []\n",
    "concept_probs_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch, c_batch in test_loader:\n",
    "        x_batch = x_batch.to(device_obj)\n",
    "        \n",
    "        # Get concept predictions\n",
    "        c_logits = concept_predictor(x_batch)\n",
    "        c_probs = torch.sigmoid(c_logits).cpu().numpy()\n",
    "        \n",
    "        # Get task predictions\n",
    "        y_logits, _ = task_classifier(x_batch)\n",
    "        y_probs = torch.sigmoid(y_logits).cpu().squeeze().numpy()\n",
    "        \n",
    "        y_true_list.extend(y_batch.numpy().astype(int).tolist())\n",
    "        y_prob_list.extend(y_probs.tolist() if isinstance(y_probs, np.ndarray) else [y_probs])\n",
    "        concept_probs_list.extend(c_probs.tolist())\n",
    "\n",
    "# Convert to arrays\n",
    "y_true = np.array(y_true_list)\n",
    "y_prob = np.array(y_prob_list)\n",
    "concept_probs = np.array(concept_probs_list)\n",
    "y_pred = (y_prob >= best_threshold).astype(int)\n",
    "\n",
    "print(\"✓ Inference complete\")\n",
    "print(f\"  Probabilities shape: {y_prob.shape}\")\n",
    "print(f\"  Concept probs shape: {concept_probs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-38",
   "metadata": {},
   "source": [
    "## Section 7: Results Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cell-39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "                    TEST SET EVALUATION\n",
      "======================================================================\n",
      "\n",
      "Decision Threshold: 0.77\n",
      "\n",
      "                 CONFUSION MATRIX                 \n",
      "==================================================\n",
      "                     │ Predicted Negative │ Predicted Positive\n",
      "──────────────────────────────────────────────────\n",
      "     Actual Negative │   TN = 337   │   FP = 12   \n",
      "     Actual Positive │   FN = 46    │    TP = 6   \n",
      "==================================================\n",
      "\n",
      "  True Positives:    6/52  ( 11.5% of depression cases caught)\n",
      "  False Negatives:  46/52  ( 88.5% of depression cases MISSED)\n",
      "  True Negatives:  337/349 ( 96.6% of healthy correctly identified)\n",
      "  False Positives:  12/349 (  3.4% false alarms)\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:                  0.8554\n",
      "  Balanced Accuracy:         0.5405\n",
      "  ROC-AUC:                   0.5965\n",
      "  Matthews Correlation:      0.1314\n",
      "\n",
      "  F1 Score (Binary):         0.1714\n",
      "  F1 Score (Macro):          0.5461\n",
      "  Precision (Binary):        0.3333\n",
      "  Recall (Binary):           0.1154\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.88      0.97      0.92       349\n",
      "    Positive       0.33      0.12      0.17        52\n",
      "\n",
      "    accuracy                           0.86       401\n",
      "   macro avg       0.61      0.54      0.55       401\n",
      "weighted avg       0.81      0.86      0.82       401\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Compute all metrics\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "roc_auc = roc_auc_score(y_true, y_prob)\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "f1_binary = f1_score(y_true, y_pred, pos_label=1)\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "precision_binary = precision_score(y_true, y_pred, pos_label=1)\n",
    "recall_binary = recall_score(y_true, y_pred, pos_label=1)\n",
    "\n",
    "# Print results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"                    TEST SET EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nDecision Threshold: {best_threshold:.2f}\")\n",
    "\n",
    "# Enhanced Confusion Matrix Display\n",
    "print(f\"\\n{'CONFUSION MATRIX':^50}\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'':>20} │ {'Predicted Negative':^12} │ {'Predicted Positive':^12}\")\n",
    "print(\"─\"*50)\n",
    "print(f\"{'Actual Negative':>20} │ {f'TN = {tn}':^12} │ {f'FP = {fp}':^12}\")\n",
    "print(f\"{'Actual Positive':>20} │ {f'FN = {fn}':^12} │ {f'TP = {tp}':^12}\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\n  True Positives:  {tp:>3}/{int(np.sum(y_true)):<3} ({100*tp/np.sum(y_true):>5.1f}% of depression cases caught)\")\n",
    "print(f\"  False Negatives: {fn:>3}/{int(np.sum(y_true)):<3} ({100*fn/np.sum(y_true):>5.1f}% of depression cases MISSED)\")\n",
    "print(f\"  True Negatives:  {tn:>3}/{int(len(y_true)-np.sum(y_true)):<3} ({100*tn/(len(y_true)-np.sum(y_true)):>5.1f}% of healthy correctly identified)\")\n",
    "print(f\"  False Positives: {fp:>3}/{int(len(y_true)-np.sum(y_true)):<3} ({100*fp/(len(y_true)-np.sum(y_true)):>5.1f}% false alarms)\")\n",
    "\n",
    "print(f\"\\nPerformance Metrics:\")\n",
    "print(f\"  Accuracy:                  {acc:.4f}\")\n",
    "print(f\"  Balanced Accuracy:         {balanced_acc:.4f}\")\n",
    "print(f\"  ROC-AUC:                   {roc_auc:.4f}\")\n",
    "print(f\"  Matthews Correlation:      {mcc:.4f}\")\n",
    "print(f\"\\n  F1 Score (Binary):         {f1_binary:.4f}\")\n",
    "print(f\"  F1 Score (Macro):          {f1_macro:.4f}\")\n",
    "print(f\"  Precision (Binary):        {precision_binary:.4f}\")\n",
    "print(f\"  Recall (Binary):           {recall_binary:.4f}\")\n",
    "\n",
    "print(\"\\n\" + classification_report(y_true, y_pred, target_names=['Negative', 'Positive']))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cell-40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Metrics saved to outputs_cbm_hard_alt/results/test_metrics.json\n"
     ]
    }
   ],
   "source": [
    "# Save metrics to JSON\n",
    "metrics_dict = {\n",
    "    \"model_type\": \"cbm_hard_two_stage\",\n",
    "    \"dataset\": \"alternative_attention_pipeline\",\n",
    "    \"threshold\": float(best_threshold),\n",
    "    \"n_samples\": int(len(y_true)),\n",
    "    \"n_positive\": int(np.sum(y_true)),\n",
    "    \"n_negative\": int(len(y_true) - np.sum(y_true)),\n",
    "    \"accuracy\": float(acc),\n",
    "    \"balanced_accuracy\": float(balanced_acc),\n",
    "    \"roc_auc\": float(roc_auc),\n",
    "    \"mcc\": float(mcc),\n",
    "    \"f1_binary\": float(f1_binary),\n",
    "    \"f1_macro\": float(f1_macro),\n",
    "    \"precision_binary\": float(precision_binary),\n",
    "    \"recall_binary\": float(recall_binary),\n",
    "    \"confusion_matrix\": {\"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)}\n",
    "}\n",
    "\n",
    "os.makedirs(os.path.join(OUTPUT_DIR, \"results\"), exist_ok=True)\n",
    "with open(os.path.join(OUTPUT_DIR, \"results/test_metrics.json\"), 'w') as f:\n",
    "    json.dump(metrics_dict, f, indent=4)\n",
    "\n",
    "print(f\"✓ Metrics saved to {OUTPUT_DIR}/results/test_metrics.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cell-41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Predictions saved to outputs_cbm_hard_alt/results/test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'subject_id': test_subject_ids,\n",
    "    'y_true': y_true,\n",
    "    'y_pred': y_pred,\n",
    "    'y_prob': y_prob\n",
    "})\n",
    "\n",
    "for i, concept_name in enumerate(CONCEPT_NAMES):\n",
    "    predictions_df[concept_name] = concept_probs[:, i]\n",
    "\n",
    "predictions_df.to_csv(os.path.join(OUTPUT_DIR, \"results/test_predictions.csv\"), index=False)\n",
    "\n",
    "print(f\"✓ Predictions saved to {OUTPUT_DIR}/results/test_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cell-42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "        CBM HARD TWO-STAGE TRAINING COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Generated files:\n",
      "  Stage 1 checkpoint: outputs_cbm_hard_alt/models/stage1/\n",
      "  Stage 2 checkpoint: outputs_cbm_hard_alt/models/stage2/\n",
      "  Metrics JSON:       outputs_cbm_hard_alt/results/test_metrics.json\n",
      "  Predictions CSV:    outputs_cbm_hard_alt/results/test_predictions.csv\n",
      "\n",
      "Key features:\n",
      "  - Two-stage training (concepts then task)\n",
      "  - Hard bottleneck with discrete concepts\n",
      "  - LDAM loss for imbalanced classification\n",
      "  - Alternative dataset (SUM-based scoring)\n",
      "  - Validation set with TRUE concept labels\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"        CBM HARD TWO-STAGE TRAINING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nGenerated files:\")\n",
    "print(f\"  Stage 1 checkpoint: {OUTPUT_DIR}/models/stage1/\")\n",
    "print(f\"  Stage 2 checkpoint: {OUTPUT_DIR}/models/stage2/\")\n",
    "print(f\"  Metrics JSON:       {OUTPUT_DIR}/results/test_metrics.json\")\n",
    "print(f\"  Predictions CSV:    {OUTPUT_DIR}/results/test_predictions.csv\")\n",
    "print(\"\\nKey features:\")\n",
    "print(\"  - Two-stage training (concepts then task)\")\n",
    "print(\"  - Hard bottleneck with discrete concepts\")\n",
    "print(\"  - LDAM loss for imbalanced classification\")\n",
    "print(\"  - Alternative dataset (SUM-based scoring)\")\n",
    "print(\"  - Validation set with TRUE concept labels\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "38concept_embedding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
