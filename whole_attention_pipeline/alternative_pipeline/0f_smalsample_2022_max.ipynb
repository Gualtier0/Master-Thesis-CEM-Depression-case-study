{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation: LargerV2 MAX + 2022 Data\n",
    "\n",
    "**MPNet-based (768-dim) concept similarity dataset with 2022 data added to training**\n",
    "\n",
    "This notebook:\n",
    "1. Loads original training data (486 subjects from train/)\n",
    "2. Loads 2022 data (1,400 subjects from 2022/)\n",
    "3. Combines into expanded training pool (1,886 subjects total)\n",
    "4. Splits into train (80%) and validation (20%)\n",
    "5. Loads test data unchanged (401 subjects from test/)\n",
    "6. Uses MAX-based attention pooling with MPNet embeddings\n",
    "\n",
    "**Data Sources:**\n",
    "- Original Train: data/raw/train/ (486 subjects)\n",
    "- 2022 Train: data/raw/2022/ (1,400 subjects)\n",
    "- Test: data/raw/test/ (401 subjects, unchanged)\n",
    "\n",
    "**Output:** data/processed/larger2022_max_alternative_attention_pipeline/\n",
    "\n",
    "**Runtime:** ~90-120 minutes (longer due to larger dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 0: Configuration & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import zipfile\n",
    "import tempfile\n",
    "import shutil\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Random seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "print(f\"✓ Random seed set to {SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Using CUDA GPU\n"
     ]
    }
   ],
   "source": [
    "# Detect device (MPS/CUDA/CPU)\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "    print(\"✓ Using MacBook GPU (MPS)\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "    print(\"✓ Using CUDA GPU\")\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "    print(\"⚠ Using CPU (will be slow)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Paths configured\n",
      "  Project root: /teamspace/studios/this_studio/Master-Thesis-CEM-Depression-etc-case-study\n",
      "  Original train: /teamspace/studios/this_studio/Master-Thesis-CEM-Depression-etc-case-study/data/raw/train/positive_examples_anonymous_chunks\n",
      "  2022 data: /teamspace/studios/this_studio/Master-Thesis-CEM-Depression-etc-case-study/data/raw/2022/datos\n",
      "  Data save dir: /teamspace/studios/this_studio/Master-Thesis-CEM-Depression-etc-case-study/data/processed/larger2022_max_alternative_attention_pipeline\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "DATA_RAW = os.path.join(PROJECT_ROOT, \"data/raw\")\n",
    "DATA_PROCESSED = os.path.join(PROJECT_ROOT, \"data/processed\")\n",
    "\n",
    "# Original training data paths\n",
    "POS_DIR = os.path.join(DATA_RAW, \"train/positive_examples_anonymous_chunks\")\n",
    "NEG_DIR = os.path.join(DATA_RAW, \"train/negative_examples_anonymous_chunks\")\n",
    "\n",
    "# 2022 training data paths\n",
    "DATA_2022_DIR = os.path.join(DATA_RAW, \"2022/datos\")\n",
    "LABELS_2022_FILE = os.path.join(DATA_RAW, \"2022/risk_golden_truth.txt\")\n",
    "CONCEPTS_2022_CONTROLS = os.path.join(DATA_RAW, \"2022/concepts_controls_2022_final.csv\")\n",
    "CONCEPTS_2022_DEPRESSED = os.path.join(DATA_RAW, \"2022/concepts_depressed_2022.csv\")\n",
    "\n",
    "# Test data paths\n",
    "TEST_DIR = os.path.join(DATA_RAW, \"test\")\n",
    "TEST_LABELS = os.path.join(TEST_DIR, \"test_golden_truth.txt\")\n",
    "\n",
    "# Concept labels\n",
    "CONCEPTS_FILE = os.path.join(DATA_PROCESSED, \"merged_questionnaires.csv\")\n",
    "\n",
    "# Output directory - NEW FOR 2022 COMBINED DATASET\n",
    "SAVE_DIR = os.path.join(DATA_PROCESSED, \"larger2022_max_alternative_attention_pipeline\")\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "print(\"✓ Paths configured\")\n",
    "print(f\"  Project root: {PROJECT_ROOT}\")\n",
    "print(f\"  Original train: {POS_DIR}\")\n",
    "print(f\"  2022 data: {DATA_2022_DIR}\")\n",
    "print(f\"  Data save dir: {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Defined 21 BDI-II concepts\n"
     ]
    }
   ],
   "source": [
    "# Define 21 BDI-II concept names\n",
    "CONCEPT_NAMES = [\n",
    "    \"Sadness\", \"Pessimism\", \"Past failure\", \"Loss of pleasure\",\n",
    "    \"Guilty feelings\", \"Punishment feelings\", \"Self-dislike\", \"Self-criticalness\",\n",
    "    \"Suicidal thoughts or wishes\", \"Crying\", \"Agitation\", \"Loss of interest\",\n",
    "    \"Indecisiveness\", \"Worthlessness\", \"Loss of energy\", \"Changes in sleeping pattern\",\n",
    "    \"Irritability\", \"Changes in appetite\", \"Concentration difficulty\",\n",
    "    \"Tiredness or fatigue\", \"Loss of interest in sex\"\n",
    "]\n",
    "N_CONCEPTS = len(CONCEPT_NAMES)\n",
    "\n",
    "print(f\"✓ Defined {N_CONCEPTS} BDI-II concepts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Hyperparameters configured:\n",
      "  k_posts: 10\n",
      "  sbert_model: all-mpnet-base-v2\n",
      "  embedding_dim: 768\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "HYPERPARAMS = {\n",
    "    \"k_posts\": 10,              # Top-k posts per subject\n",
    "    \"sbert_model\": \"all-mpnet-base-v2\",\n",
    "    \"embedding_dim\": 768,\n",
    "}\n",
    "# =========================\n",
    "# DEBUG / SANITY CHECK CONFIG\n",
    "# =========================\n",
    "DEBUG = True\n",
    "DEBUG_N_SUBJECTS = 3          # how many subjects to inspect\n",
    "DEBUG_TOP_N_POSTS = 5         # how many top posts to print\n",
    "DEBUG_PRINT_CONCEPTS = True   # print per-concept similarity stats\n",
    "\n",
    "print(\"✓ Hyperparameters configured:\")\n",
    "for k, v in HYPERPARAMS.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Memory configuration:\n",
      "  post_batch_size: 32\n",
      "  subject_cache_interval: 10\n",
      "  use_no_grad: True\n",
      "  move_to_cpu_immediately: True\n"
     ]
    }
   ],
   "source": [
    "# Memory Management Configuration\n",
    "MEMORY_CONFIG = {\n",
    "    \"post_batch_size\": 32,        # Encode N posts at a time\n",
    "    \"subject_cache_interval\": 10,  # Clear GPU cache every N subjects\n",
    "    \"use_no_grad\": True,           # Disable gradient tracking\n",
    "    \"move_to_cpu_immediately\": True # Move results to CPU after computation\n",
    "}\n",
    "\n",
    "print(\"✓ Memory configuration:\")\n",
    "for k, v in MEMORY_CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ GPU cache clearing utility defined\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def clear_gpu_cache():\n",
    "    \"\"\"Clear GPU cache and run garbage collection.\"\"\"\n",
    "    if DEVICE == \"mps\":\n",
    "        torch.mps.empty_cache()\n",
    "    elif DEVICE == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "print(\"✓ GPU cache clearing utility defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Load Training Data\n",
    "\n",
    "Extract 486 training subjects with posts and concept labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "# Helper functions for XML parsing\n",
    "WHITESPACE_RE = re.compile(r\"\\s+\")\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Normalize text by removing null chars and extra whitespace.\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = text.replace(\"\\u0000\", \"\")\n",
    "    text = WHITESPACE_RE.sub(\" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def extract_posts_from_xml(xml_path, min_chars=10):\n",
    "    \"\"\"Extract posts from a single XML file.\"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "    except Exception as e:\n",
    "        print(f\"WARNING: Failed to parse {xml_path}: {e}\")\n",
    "        return []\n",
    "    \n",
    "    posts = []\n",
    "    for writing in root.findall(\"WRITING\"):\n",
    "        title = writing.findtext(\"TITLE\") or \"\"\n",
    "        text = writing.findtext(\"TEXT\") or \"\"\n",
    "        \n",
    "        combined = normalize_text(f\"{title} {text}\".strip())\n",
    "        if len(combined) >= min_chars:\n",
    "            posts.append(combined)\n",
    "    \n",
    "    return posts\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "  Processing positive examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing positive examples: 100%|██████████| 830/830 [00:00<00:00, 972.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 29868 posts from positive subjects\n",
      "  Processing negative examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing negative examples: 100%|██████████| 4031/4031 [00:05<00:00, 696.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Loaded training data in 7.0s\n",
      "  Total posts: 286,740\n",
      "  Unique subjects: 486\n",
      "  Label distribution:\n",
      "label\n",
      "0    403\n",
      "1     83\n",
      "Name: subject_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Parse training XML files\n",
    "print(\"Loading training data...\")\n",
    "start_time = time.time()\n",
    "\n",
    "train_data = []\n",
    "\n",
    "# Process positive examples\n",
    "print(\"  Processing positive examples...\")\n",
    "pos_files = glob.glob(os.path.join(POS_DIR, \"**\", \"*.xml\"), recursive=True)\n",
    "for xml_file in tqdm(pos_files, desc=\"Processing positive examples\"):\n",
    "    filename = os.path.basename(xml_file)\n",
    "    match = re.match(r\"train_(subject\\d+)_\\d+\\.xml\", filename)\n",
    "    if match:\n",
    "        subject_id = match.group(1)\n",
    "        posts = extract_posts_from_xml(xml_file)\n",
    "        for post in posts:\n",
    "            train_data.append({\n",
    "                \"subject_id\": subject_id,\n",
    "                \"label\": 1,  # Positive (depression)\n",
    "                \"text\": post\n",
    "            })\n",
    "\n",
    "print(f\"  Loaded {sum(d['label'] == 1 for d in train_data)} posts from positive subjects\")\n",
    "\n",
    "# Process negative examples\n",
    "print(\"  Processing negative examples...\")\n",
    "neg_files = glob.glob(os.path.join(NEG_DIR, \"**\", \"*.xml\"), recursive=True)\n",
    "for xml_file in tqdm(neg_files, desc=\"Processing negative examples\"):\n",
    "    filename = os.path.basename(xml_file)\n",
    "    match = re.match(r\"train_(subject\\d+)_\\d+\\.xml\", filename)\n",
    "    if match:\n",
    "        subject_id = match.group(1)\n",
    "        posts = extract_posts_from_xml(xml_file)\n",
    "        for post in posts:\n",
    "            train_data.append({\n",
    "                \"subject_id\": subject_id,\n",
    "                \"label\": 0,  # Negative (control)\n",
    "                \"text\": post\n",
    "            })\n",
    "\n",
    "train_posts_df = pd.DataFrame(train_data)\n",
    "\n",
    "print(f\"\\n✓ Loaded training data in {time.time()-start_time:.1f}s\")\n",
    "print(f\"  Total posts: {len(train_posts_df):,}\")\n",
    "print(f\"  Unique subjects: {train_posts_df['subject_id'].nunique()}\")\n",
    "print(f\"  Label distribution:\")\n",
    "print(train_posts_df.groupby('label')['subject_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading concept labels...\n",
      "✓ Loaded concept labels for 486 subjects\n"
     ]
    }
   ],
   "source": [
    "# Load concept labels from questionnaires\n",
    "print(\"Loading concept labels...\")\n",
    "\n",
    "concepts_df = pd.read_csv(CONCEPTS_FILE)\n",
    "concepts_df[\"subject_id\"] = concepts_df[\"Subject\"].str.replace(\"train_\", \"\", regex=True)\n",
    "\n",
    "# Binarize concept values\n",
    "concept_cols = [col for col in concepts_df.columns if col in CONCEPT_NAMES]\n",
    "for col in concept_cols:\n",
    "    concepts_df[col] = (concepts_df[col] > 0).astype(int)\n",
    "\n",
    "print(f\"✓ Loaded concept labels for {len(concepts_df)} subjects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2022 training data...\n",
      "  Loaded 0 labels from risk_golden_truth.txt\n",
      "  Loaded 1302 control concepts\n",
      "  Loaded 98 depressed concepts\n",
      "  Mapped concepts for 0 subjects\n",
      "  Found 1400 XML files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2022 data: 100%|██████████| 1400/1400 [00:00<00:00, 2013726.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Loaded 2022 data in 0.0s\n",
      "  Total posts: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'subject_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 72\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✓ Loaded 2022 data in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Total posts: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data_2022_df)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Unique subjects: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdata_2022_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubject_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Label distribution:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_2022_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique())\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/pandas/core/indexes/range.py:418\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'subject_id'"
     ]
    }
   ],
   "source": [
    "# Load 2022 data\n",
    "print(\"Loading 2022 training data...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Load labels\n",
    "labels_2022 = {}\n",
    "with open(LABELS_2022_FILE, 'r') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) == 2:\n",
    "            subject_id = parts[0].strip()\n",
    "            label = int(parts[1].strip())\n",
    "            labels_2022[subject_id] = label\n",
    "\n",
    "print(f\"  Loaded {len(labels_2022)} labels from risk_golden_truth.txt\")\n",
    "\n",
    "# Load concept labels (two separate CSVs)\n",
    "concepts_controls = pd.read_csv(CONCEPTS_2022_CONTROLS)\n",
    "concepts_depressed = pd.read_csv(CONCEPTS_2022_DEPRESSED)\n",
    "\n",
    "print(f\"  Loaded {len(concepts_controls)} control concepts\")\n",
    "print(f\"  Loaded {len(concepts_depressed)} depressed concepts\")\n",
    "\n",
    "# Create mapping of subject_id → concept scores\n",
    "# According to stats: first 1302 are controls, next 98 are depressed\n",
    "concepts_2022 = {}\n",
    "\n",
    "# Get sorted subject IDs from labels file (should match CSV order)\n",
    "sorted_subjects = sorted(labels_2022.keys(), key=lambda x: int(x.replace('subject', '')))\n",
    "\n",
    "# Map controls (first 1302)\n",
    "control_subjects = [s for s in sorted_subjects if labels_2022[s] == 0]\n",
    "for idx, subject_id in enumerate(control_subjects):\n",
    "    if idx < len(concepts_controls):\n",
    "        concepts_2022[subject_id] = concepts_controls.iloc[idx].values\n",
    "\n",
    "# Map depressed (last 98)\n",
    "depressed_subjects = [s for s in sorted_subjects if labels_2022[s] == 1]\n",
    "for idx, subject_id in enumerate(depressed_subjects):\n",
    "    if idx < len(concepts_depressed):\n",
    "        concepts_2022[subject_id] = concepts_depressed.iloc[idx].values\n",
    "\n",
    "print(f\"  Mapped concepts for {len(concepts_2022)} subjects\")\n",
    "\n",
    "# Load posts from XML files\n",
    "subjects_2022_data = []\n",
    "\n",
    "xml_files = [f for f in os.listdir(DATA_2022_DIR) if f.endswith('.xml')]\n",
    "print(f\"  Found {len(xml_files)} XML files\")\n",
    "\n",
    "for xml_file in tqdm(xml_files, desc=\"Processing 2022 data\"):\n",
    "    # Extract subject ID (e.g., \"subject7249.xml\" → \"subject7249\")\n",
    "    subject_id = xml_file.replace('.xml', '')\n",
    "\n",
    "    if subject_id not in labels_2022:\n",
    "        continue\n",
    "\n",
    "    # Parse XML\n",
    "    posts = extract_posts_from_xml(os.path.join(DATA_2022_DIR, xml_file))\n",
    "\n",
    "    for post in posts:\n",
    "        subjects_2022_data.append({\n",
    "            \"subject_id\": subject_id,\n",
    "            \"label\": labels_2022[subject_id],\n",
    "            \"text\": post\n",
    "        })\n",
    "\n",
    "data_2022_df = pd.DataFrame(subjects_2022_data)\n",
    "\n",
    "print(f\"\\n✓ Loaded 2022 data in {time.time()-start_time:.1f}s\")\n",
    "print(f\"  Total posts: {len(data_2022_df):,}\")\n",
    "print(f\"  Unique subjects: {data_2022_df['subject_id'].nunique()}\")\n",
    "print(f\"  Label distribution:\")\n",
    "print(data_2022_df.groupby('label')['subject_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine original training data with 2022 data\n",
    "print(\"\\nCombining original training data with 2022 data...\")\n",
    "\n",
    "# Combine post dataframes\n",
    "all_train_posts = pd.concat([train_posts_df, data_2022_df], ignore_index=True)\n",
    "\n",
    "# Combine concept dataframes - add 2022 concepts to concepts_df\n",
    "concepts_2022_df = pd.DataFrame({\n",
    "    'subject_id': list(concepts_2022.keys())\n",
    "})\n",
    "\n",
    "# Add concept columns (binarized from 2022 CSVs)\n",
    "for idx, concept_name in enumerate(CONCEPT_NAMES):\n",
    "    concept_values = []\n",
    "    for subject_id in concepts_2022_df['subject_id']:\n",
    "        if subject_id in concepts_2022:\n",
    "            # Binarize: any value > 0 becomes 1\n",
    "            value = 1 if concepts_2022[subject_id][idx] > 0 else 0\n",
    "            concept_values.append(value)\n",
    "        else:\n",
    "            concept_values.append(0)\n",
    "    concepts_2022_df[concept_name] = concept_values\n",
    "\n",
    "# Combine concept dataframes\n",
    "all_concepts_df = pd.concat([concepts_df, concepts_2022_df], ignore_index=True)\n",
    "\n",
    "print(f\"✓ Combined training pool created\")\n",
    "print(f\"  Total posts: {len(all_train_posts):,}\")\n",
    "print(f\"  Unique subjects: {all_train_posts['subject_id'].nunique()}\")\n",
    "print(f\"  Label distribution:\")\n",
    "print(all_train_posts.groupby('label')['subject_id'].nunique())\n",
    "print(f\"\\n  Class imbalance ratio: {(all_train_posts.groupby('label')['subject_id'].nunique()[0] / all_train_posts.groupby('label')['subject_id'].nunique()[1]):.2f}:1\")\n",
    "print(f\"  Total concepts mapped: {len(all_concepts_df)} subjects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Load Test Data\n",
    "\n",
    "Load all 401 test subjects from test folder (will be used entirely as test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting test data...\n",
      "  Temp directory: /tmp/test_chunks_8j5wnmap\n",
      "  Extracted chunk 3/10\n",
      "  Extracted chunk 6/10\n",
      "  Extracted chunk 9/10\n",
      "✓ Test data extracted\n"
     ]
    }
   ],
   "source": [
    "# Extract test ZIP files to temporary directory\n",
    "print(\"Extracting test data...\")\n",
    "temp_dir = tempfile.mkdtemp(prefix=\"test_chunks_\")\n",
    "print(f\"  Temp directory: {temp_dir}\")\n",
    "\n",
    "for i in range(1, 11):\n",
    "    zip_path = os.path.join(TEST_DIR, f\"chunk {i}.zip\")\n",
    "    if os.path.exists(zip_path):\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(os.path.join(temp_dir, f\"chunk_{i}\"))\n",
    "        if i % 3 == 0:\n",
    "            print(f\"  Extracted chunk {i}/10\")\n",
    "\n",
    "print(\"✓ Test data extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded test labels for 401 subjects\n",
      "  Label distribution:\n",
      "label\n",
      "0    349\n",
      "1     52\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load test labels\n",
    "test_labels_df = pd.read_csv(TEST_LABELS, sep='\\t', header=None, names=['subject_id', 'label'])\n",
    "test_labels_df['subject_id'] = test_labels_df['subject_id'].str.strip()\n",
    "\n",
    "print(f\"✓ Loaded test labels for {len(test_labels_df)} subjects\")\n",
    "print(f\"  Label distribution:\")\n",
    "print(test_labels_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse test XML files\n",
    "print(\"Loading test posts...\")\n",
    "test_data = []\n",
    "\n",
    "test_xml_files = glob.glob(os.path.join(temp_dir, \"**\", \"*.xml\"), recursive=True)\n",
    "print(f\"  Found {len(test_xml_files)} XML files\")\n",
    "\n",
    "for xml_file in test_xml_files:\n",
    "    filename = os.path.basename(xml_file)\n",
    "    match = re.match(r\"(test_subject\\d+)_\\d+\\.xml\", filename)\n",
    "    if match:\n",
    "        subject_id = match.group(1)\n",
    "        label_row = test_labels_df[test_labels_df['subject_id'] == subject_id]\n",
    "        if len(label_row) > 0:\n",
    "            label = label_row.iloc[0]['label']\n",
    "            posts = extract_posts_from_xml(xml_file)\n",
    "            for post in posts:\n",
    "                test_data.append({\n",
    "                    \"subject_id\": subject_id,\n",
    "                    \"label\": label,\n",
    "                    \"text\": post\n",
    "                })\n",
    "\n",
    "test_posts_df = pd.DataFrame(test_data)\n",
    "\n",
    "print(f\"✓ Loaded test posts\")\n",
    "print(f\"  Total posts: {len(test_posts_df):,}\")\n",
    "print(f\"  Unique subjects: {test_posts_df['subject_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split COMBINED training pool into train (80%) and validation (20%)\n",
    "print(\"Splitting combined training pool into train (80%) and validation (20%)...\")\n",
    "\n",
    "# Get unique subjects from COMBINED dataset (original + 2022)\n",
    "all_train_subjects = all_train_posts.groupby('subject_id')['label'].first().reset_index()\n",
    "\n",
    "train_subjects_final, val_subjects = train_test_split(\n",
    "    all_train_subjects['subject_id'],\n",
    "    test_size=0.2,\n",
    "    stratify=all_train_subjects['label'],\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "# Create train dataframe from COMBINED pool\n",
    "train_posts_df_final = all_train_posts[all_train_posts['subject_id'].isin(train_subjects_final)].copy()\n",
    "\n",
    "# Create validation dataframe from COMBINED pool\n",
    "val_posts_df = all_train_posts[all_train_posts['subject_id'].isin(val_subjects)].copy()\n",
    "\n",
    "# Keep ALL test data as test set (no split)\n",
    "test_posts_df_final = test_posts_df.copy()\n",
    "\n",
    "print(f\"✓ Split complete\")\n",
    "print(f\"  Training: {train_posts_df_final['subject_id'].nunique()} subjects (80% of combined pool)\")\n",
    "print(f\"  Validation: {val_posts_df['subject_id'].nunique()} subjects (20% of combined pool)\")\n",
    "print(f\"  Test: {test_posts_df_final['subject_id'].nunique()} subjects (100% of test folder)\")\n",
    "\n",
    "# Show label distributions\n",
    "print(f\"\\n  Training label distribution:\")\n",
    "print(train_posts_df_final.groupby('label')['subject_id'].nunique())\n",
    "print(f\"\\n  Validation label distribution:\")\n",
    "print(val_posts_df.groupby('label')['subject_id'].nunique())\n",
    "print(f\"\\n  Test label distribution:\")\n",
    "print(test_posts_df_final.groupby('label')['subject_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: SBERT Setup & Concept Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SBERT model: all-mpnet-base-v2\n",
      "✓ SBERT model loaded on cuda\n",
      "  Embedding dimension: 768\n"
     ]
    }
   ],
   "source": [
    "# Load SBERT model\n",
    "print(f\"Loading SBERT model: {HYPERPARAMS['sbert_model']}\")\n",
    "sbert_model = SentenceTransformer(HYPERPARAMS['sbert_model'])\n",
    "sbert_model = sbert_model.to(DEVICE)\n",
    "\n",
    "print(f\"✓ SBERT model loaded on {DEVICE}\")\n",
    "print(f\"  Embedding dimension: {sbert_model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings for 21 concepts...\n",
      "✓ Concept embeddings created\n",
      "  Shape: torch.Size([21, 768])\n"
     ]
    }
   ],
   "source": [
    "# Create concept embeddings\n",
    "print(f\"Creating embeddings for {N_CONCEPTS} concepts...\")\n",
    "concept_embeddings = sbert_model.encode(\n",
    "    CONCEPT_NAMES,\n",
    "    convert_to_tensor=True,\n",
    "    show_progress_bar=False\n",
    ")\n",
    "\n",
    "print(f\"✓ Concept embeddings created\")\n",
    "print(f\"  Shape: {concept_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Batched post retrieval function defined (MAX-based)\n"
     ]
    }
   ],
   "source": [
    "def retrieve_top_k_posts_max(subject_id, posts_df, concept_embs, sbert, k=50, batch_size=32, debug=False):\n",
    "    \"\"\"\n",
    "    Retrieve top-k posts for a subject based on MAX of concept similarities.\n",
    "    OPTIMIZED: Uses batching to prevent memory exhaustion.\n",
    "    \n",
    "    For each post, takes MAX similarity across all 21 concepts.\n",
    "    Selects posts that are highly relevant to at least ONE concept.\n",
    "    \"\"\"\n",
    "    subj_posts = posts_df[posts_df['subject_id'] == subject_id]['text'].tolist()\n",
    "\n",
    "    if len(subj_posts) == 0:\n",
    "        return []\n",
    "\n",
    "    if len(subj_posts) <= k:\n",
    "        if len(subj_posts) < k:\n",
    "            extra_needed = k - len(subj_posts)\n",
    "            padding = list(np.random.choice(subj_posts, size=extra_needed, replace=True))\n",
    "            return subj_posts + padding\n",
    "        else:\n",
    "            return subj_posts\n",
    "\n",
    "    # Batch encoding to prevent memory issues\n",
    "    max_sim_scores = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient tracking\n",
    "        for i in range(0, len(subj_posts), batch_size):\n",
    "            batch_posts = subj_posts[i:i + batch_size]\n",
    "\n",
    "            # Encode batch\n",
    "            batch_embeddings = sbert.encode(\n",
    "                batch_posts,\n",
    "                convert_to_tensor=True,\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "\n",
    "            # Compute similarities for this batch\n",
    "            cos_scores = util.cos_sim(batch_embeddings, concept_embs)  # [batch, 21]\n",
    "            # KEY: Take MAX instead of SUM\n",
    "            batch_max_scores = cos_scores.max(dim=1)[0].cpu().numpy()  # [0] gets values, not indices\n",
    "\n",
    "            max_sim_scores.extend(batch_max_scores)\n",
    "\n",
    "            # Clear references\n",
    "            del batch_embeddings, cos_scores, batch_max_scores\n",
    "\n",
    "    max_sim_scores = np.array(max_sim_scores)\n",
    "\n",
    "    if debug:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"[DEBUG] Subject: {subject_id}\")\n",
    "        print(f\"[DEBUG] Total posts: {len(subj_posts)}\")\n",
    "        print(\"[DEBUG] Max similarity stats:\")\n",
    "        print(f\"  min={max_sim_scores.min():.4f} \"\n",
    "              f\"max={max_sim_scores.max():.4f} \"\n",
    "              f\"mean={max_sim_scores.mean():.4f} \"\n",
    "              f\"std={max_sim_scores.std():.4f}\")\n",
    "\n",
    "        top_idx_sorted = np.argsort(-max_sim_scores)\n",
    "        print(f\"\\n[DEBUG] Top-{DEBUG_TOP_N_POSTS} retrieved posts:\")\n",
    "        for rank, i in enumerate(top_idx_sorted[:DEBUG_TOP_N_POSTS]):\n",
    "            print(f\"\\n  Rank {rank+1}\")\n",
    "            print(f\"  Score: {max_sim_scores[i]:.4f}\")\n",
    "            print(f\"  Text: {subj_posts[i][:300]}\")\n",
    "\n",
    "    # Select top-k posts\n",
    "    top_k_indices = np.argpartition(-max_sim_scores, range(min(k, len(subj_posts))))[:k]\n",
    "\n",
    "    return [subj_posts[i] for i in top_k_indices]\n",
    "\n",
    "print(\"✓ Batched post retrieval function defined (MAX-based)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving top-50 posts (MAX-based scoring with batching)...\n",
      "⏰ This will be faster and more memory-efficient\n",
      "  Processing training subjects (80% of train data)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train subjects:   0%|          | 1/388 [00:02<18:18,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "[DEBUG] Subject: subject9683\n",
      "[DEBUG] Total posts: 332\n",
      "[DEBUG] Max similarity stats:\n",
      "  min=0.0171 max=0.4886 mean=0.1548 std=0.0658\n",
      "\n",
      "[DEBUG] Top-5 retrieved posts:\n",
      "\n",
      "  Rank 1\n",
      "  Score: 0.4886\n",
      "  Text: Just Pissed Off (Disclaimer: I Might Come Off As An Attention Seeker.)\n",
      "\n",
      "  Rank 2\n",
      "  Score: 0.3492\n",
      "  Text: ELI5: What does \"nostalgia\" mean?\n",
      "\n",
      "  Rank 3\n",
      "  Score: 0.3374\n",
      "  Text: Oh really? Please enlighten us on all the \"many mistakes\".\n",
      "\n",
      "  Rank 4\n",
      "  Score: 0.3252\n",
      "  Text: im assuming Triss-k-eye-deck-ah-phobia\n",
      "\n",
      "  Rank 5\n",
      "  Score: 0.3058\n",
      "  Text: Sorry, didn't know how to word it :(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train subjects:   1%|          | 2/388 [00:03<11:24,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "[DEBUG] Subject: subject3364\n",
      "[DEBUG] Total posts: 117\n",
      "[DEBUG] Max similarity stats:\n",
      "  min=0.0098 max=0.4374 mean=0.1726 std=0.0900\n",
      "\n",
      "[DEBUG] Top-5 retrieved posts:\n",
      "\n",
      "  Rank 1\n",
      "  Score: 0.4374\n",
      "  Text: I don't want anyone's help anymore I just wanted to say that I spent the last 8 years of my life trying to die and recently, I decided to try to re-gain my will to live again. I guess now is when life decides to try to push me down even more. If there was a time in my life where I should be dead, it\n",
      "\n",
      "  Rank 2\n",
      "  Score: 0.3644\n",
      "  Text: Why play with toys when you can bite an arm?\n",
      "\n",
      "  Rank 3\n",
      "  Score: 0.3603\n",
      "  Text: I'm not looking or wanting to get back with him. I'm just asking about the guilt I'm feeling.\n",
      "\n",
      "  Rank 4\n",
      "  Score: 0.3574\n",
      "  Text: She says it's normal but I would probably assume it's because she's obese.\n",
      "\n",
      "  Rank 5\n",
      "  Score: 0.3486\n",
      "  Text: Not being enough.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train subjects: 100%|██████████| 388/388 [21:09<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Processing validation subjects (20% of train data)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val subjects:   3%|▎         | 3/98 [00:06<03:14,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "[DEBUG] Subject: subject7364\n",
      "[DEBUG] Total posts: 506\n",
      "[DEBUG] Max similarity stats:\n",
      "  min=-0.0066 max=0.4058 mean=0.1591 std=0.0753\n",
      "\n",
      "[DEBUG] Top-5 retrieved posts:\n",
      "\n",
      "  Rank 1\n",
      "  Score: 0.4058\n",
      "  Text: Next up: Mandatory Catechism, and the beatings will improve until morale continues.\n",
      "\n",
      "  Rank 2\n",
      "  Score: 0.3807\n",
      "  Text: callouses snag silk lingerie grit from the days work smudges eyeliner rolls away with sweat moments evaporate into late hours these delusions of an abandoned heart that knows no bounds and feels no comfort\n",
      "\n",
      "  Rank 3\n",
      "  Score: 0.3617\n",
      "  Text: Like a hot knife through butter, Spreading my patience thin. Killing me softly in a game of hard ball, That neither of us can win. They'll take what they can get, two miles to the inch, It's not even really their fault. Their parents don't love them, or don't try hard enough, If they do it seems for\n",
      "\n",
      "  Rank 4\n",
      "  Score: 0.3594\n",
      "  Text: A winning lottery ticket so I can travel the world freeing slaves and shooting badguys.\n",
      "\n",
      "  Rank 5\n",
      "  Score: 0.3570\n",
      "  Text: that the school isn't justifying its end of the bargain We narrowly avoided having religion crammed down the throats of kids that are already going to have it a lot harder than we ever knew. I'm with it, go to fucking school. Period. It doesn't mean they have to like it. It doesn't mean what they ar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val subjects: 100%|██████████| 98/98 [05:55<00:00,  3.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Processing test subjects (100% of test folder)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test subjects:   0%|          | 1/401 [00:01<10:35,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "[DEBUG] Subject: test_subject1116\n",
      "[DEBUG] Total posts: 152\n",
      "[DEBUG] Max similarity stats:\n",
      "  min=0.0187 max=0.2887 mean=0.1210 std=0.0577\n",
      "\n",
      "[DEBUG] Top-5 retrieved posts:\n",
      "\n",
      "  Rank 1\n",
      "  Score: 0.2887\n",
      "  Text: First, what do you mean by power? And how can we compare the power of both?\n",
      "\n",
      "  Rank 2\n",
      "  Score: 0.2731\n",
      "  Text: I'm not saying that there isn't a connection between the two. I do think that there is a high probability that there is some connection. I just wanted to point out that other sports are experiencing a similar decline and that there are other possible factors in play that have led to a decline in the\n",
      "\n",
      "  Rank 3\n",
      "  Score: 0.2584\n",
      "  Text: Shocking the VP of Officiating defends the decision by the officials.\n",
      "\n",
      "  Rank 4\n",
      "  Score: 0.2522\n",
      "  Text: [Here is the link to the study.](http://archpsyc.jamanetwork.com/article.aspx?articleid=2319711)\n",
      "\n",
      "  Rank 5\n",
      "  Score: 0.2473\n",
      "  Text: He suffered it in the 2nd to last drive. He had a couple of good runs at the beginning of the last drive and then came in for that last atrocious play.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test subjects:   0%|          | 2/401 [00:02<08:20,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "[DEBUG] Subject: test_subject4850\n",
      "[DEBUG] Total posts: 102\n",
      "[DEBUG] Max similarity stats:\n",
      "  min=-0.0287 max=0.3284 mean=0.1227 std=0.0701\n",
      "\n",
      "[DEBUG] Top-5 retrieved posts:\n",
      "\n",
      "  Rank 1\n",
      "  Score: 0.3284\n",
      "  Text: Nothing more satisfying than seeing this\n",
      "\n",
      "  Rank 2\n",
      "  Score: 0.3089\n",
      "  Text: what happens when I get motivated at 1am..... (Spoilers for #StevenBomb warning)\n",
      "\n",
      "  Rank 3\n",
      "  Score: 0.2829\n",
      "  Text: Rose Tyler, happy...\n",
      "\n",
      "  Rank 4\n",
      "  Score: 0.2693\n",
      "  Text: I enjoy this subreddit far too much\n",
      "\n",
      "  Rank 5\n",
      "  Score: 0.2617\n",
      "  Text: What I imagine this giraffe is thinking: http://imgur.com/MhTGEbQ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test subjects:   1%|          | 3/401 [00:11<30:45,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "[DEBUG] Subject: test_subject2886\n",
      "[DEBUG] Total posts: 1093\n",
      "[DEBUG] Max similarity stats:\n",
      "  min=-0.0278 max=0.4646 mean=0.1442 std=0.0730\n",
      "\n",
      "[DEBUG] Top-5 retrieved posts:\n",
      "\n",
      "  Rank 1\n",
      "  Score: 0.4646\n",
      "  Text: A question/issue I've been lurking on this sub for a while now. Every post is full of \"your problems don't matter\" or \"just do it\" or \"be confident.\" It isn't that easy. Anxiety is part of my identity. It's like telling someone with clinical depression to \"just be happy.\" It's pointless, and a littl\n",
      "\n",
      "  Rank 2\n",
      "  Score: 0.4503\n",
      "  Text: Perhaps I just had a shitty therapist, but all I ever got from it was \"you have a chemical imbalance in your brain, sucks, don't it?\" Therapy just made me focus more on the stupid things, trying to figure out why they bother me. It ended up making me feel super self-absorbed, to the point that my ve\n",
      "\n",
      "  Rank 3\n",
      "  Score: 0.4146\n",
      "  Text: Oh my goodness, yes. This one guy, I still talk to him a lot, but can't really have sex with him anymore (he's got herpes, I don't and want to keep it that way). I've had to step back multiple times because I started to want more than he did and I didn't want to torture myself.... yet I still would \n",
      "\n",
      "  Rank 4\n",
      "  Score: 0.4117\n",
      "  Text: 20-year-old female. Lost my virginity about 18 months ago. Have had piv sex with 15 people, only oral with 2. One six-month relationship, four month-or-two-long flings, five less-than-one-month flings, seven one-night-stands.\n",
      "\n",
      "  Rank 5\n",
      "  Score: 0.4032\n",
      "  Text: I was about to ask the same thing. Might have something to do with the fact that it's all I got in my last relationship, so I had to figure out what worked. Only time I've ever orgasmed from just PIV sex was in Cowgirl.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test subjects: 100%|██████████| 401/401 [23:26<00:00,  3.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Post retrieval complete in 3030.6s (50.5 min)\n",
      "  Memory-optimized processing: 887 subjects\n"
     ]
    }
   ],
   "source": [
    "# Retrieve top-k posts for all subjects\n",
    "print(f\"Retrieving top-{HYPERPARAMS['k_posts']} posts (MAX-based scoring with batching)...\")\n",
    "print(\"⏰ This will be faster and more memory-efficient\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Training subjects (80% of original training data)\n",
    "print(\"  Processing training subjects (80% of train data)...\")\n",
    "train_selected = {}\n",
    "train_subjects = train_posts_df_final['subject_id'].unique()\n",
    "\n",
    "for idx, subject_id in enumerate(tqdm(train_subjects, desc=\"Train subjects\")):\n",
    "    selected = retrieve_top_k_posts_max(\n",
    "        subject_id,\n",
    "        train_posts_df_final,\n",
    "        concept_embeddings,\n",
    "        sbert_model,\n",
    "        k=HYPERPARAMS['k_posts'],\n",
    "        batch_size=MEMORY_CONFIG['post_batch_size'],\n",
    "        debug=(DEBUG and idx < DEBUG_N_SUBJECTS)\n",
    "    )\n",
    "    train_selected[subject_id] = selected\n",
    "\n",
    "    # Clear GPU cache periodically\n",
    "    if (idx + 1) % MEMORY_CONFIG['subject_cache_interval'] == 0:\n",
    "        clear_gpu_cache()\n",
    "\n",
    "# Validation subjects (20% of original training data)\n",
    "print(\"\\n  Processing validation subjects (20% of train data)...\")\n",
    "val_selected = {}\n",
    "val_subjects = val_posts_df['subject_id'].unique()\n",
    "\n",
    "for idx, subject_id in enumerate(tqdm(val_subjects, desc=\"Val subjects\")):\n",
    "    selected = retrieve_top_k_posts_max(\n",
    "        subject_id,\n",
    "        val_posts_df,\n",
    "        concept_embeddings,\n",
    "        sbert_model,\n",
    "        k=HYPERPARAMS['k_posts'],\n",
    "        batch_size=MEMORY_CONFIG['post_batch_size'],\n",
    "        debug=(DEBUG and idx < DEBUG_N_SUBJECTS)\n",
    "    )\n",
    "    val_selected[subject_id] = selected\n",
    "\n",
    "    if (idx + 1) % MEMORY_CONFIG['subject_cache_interval'] == 0:\n",
    "        clear_gpu_cache()\n",
    "\n",
    "# Test subjects (100% of test folder)\n",
    "print(\"\\n  Processing test subjects (100% of test folder)...\")\n",
    "test_selected = {}\n",
    "test_subjects = test_posts_df_final['subject_id'].unique()\n",
    "\n",
    "for idx, subject_id in enumerate(tqdm(test_subjects, desc=\"Test subjects\")):\n",
    "    selected = retrieve_top_k_posts_max(\n",
    "        subject_id,\n",
    "        test_posts_df_final,\n",
    "        concept_embeddings,\n",
    "        sbert_model,\n",
    "        k=HYPERPARAMS['k_posts'],\n",
    "        batch_size=MEMORY_CONFIG['post_batch_size'],\n",
    "        debug=(DEBUG and idx < DEBUG_N_SUBJECTS)\n",
    "    )\n",
    "    test_selected[subject_id] = selected\n",
    "\n",
    "    if (idx + 1) % MEMORY_CONFIG['subject_cache_interval'] == 0:\n",
    "        clear_gpu_cache()\n",
    "\n",
    "# Final cache clear\n",
    "clear_gpu_cache()\n",
    "\n",
    "print(f\"\\n✓ Post retrieval complete in {time.time()-start_time:.1f}s ({(time.time()-start_time)/60:.1f} min)\")\n",
    "print(f\"  Memory-optimized processing: {len(train_subjects) + len(val_subjects) + len(test_subjects)} subjects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Memory-optimized attention pooling function defined (MAX-based)\n"
     ]
    }
   ],
   "source": [
    "def encode_and_attention_pool_max(selected_posts_dict, sbert, concept_embs,\n",
    "                                   normalize=True, debug=False):\n",
    "    \"\"\"\n",
    "    Encode posts and pool using MAX of concept similarities for attention.\n",
    "    OPTIMIZED: Includes memory management for stability.\n",
    "    \n",
    "    For each post:\n",
    "    1. Compute similarities to all 21 concepts\n",
    "    2. Take MAX similarity as the post's relevance score\n",
    "    3. Use softmax(max_scores / temperature) for attention weights\n",
    "    4. Weighted sum pooling to create final embedding\n",
    "    \"\"\"\n",
    "    subject_ids = list(selected_posts_dict.keys())\n",
    "    pooled_embeddings = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient tracking\n",
    "        for idx, subject_id in enumerate(subject_ids):\n",
    "            posts = selected_posts_dict[subject_id]\n",
    "\n",
    "            # Handle empty posts\n",
    "            if len(posts) == 0:\n",
    "                print(f\"WARNING: No posts for subject {subject_id}, using zero embedding\")\n",
    "                pooled_embeddings.append(np.zeros(768))\n",
    "                continue\n",
    "\n",
    "            # Filter out empty posts\n",
    "            posts = [p for p in posts if p.strip()]\n",
    "            if len(posts) == 0:\n",
    "                print(f\"WARNING: All posts empty for subject {subject_id}, using zero embedding\")\n",
    "                pooled_embeddings.append(np.zeros(768))\n",
    "                continue\n",
    "\n",
    "            # Encode posts\n",
    "            post_embs = sbert.encode(\n",
    "                posts,\n",
    "                convert_to_tensor=True,\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "\n",
    "            if post_embs.shape[0] == 0 or post_embs.shape[1] == 0:\n",
    "                print(f\"WARNING: Empty embeddings for subject {subject_id}, using zero embedding\")\n",
    "                pooled_embeddings.append(np.zeros(768))\n",
    "                continue\n",
    "\n",
    "            # Compute similarity to concepts\n",
    "            cos_scores = util.cos_sim(post_embs, concept_embs)\n",
    "\n",
    "            # KEY: Take MAX instead of SUM\n",
    "            post_scores = cos_scores.max(dim=1)[0]  # [0] gets values, not indices\n",
    "\n",
    "            # Remove negative similarities\n",
    "            post_scores = torch.clamp(post_scores, min=0.0)\n",
    "\n",
    "            # Attention weights\n",
    "            TEMPERATURE = 0.2  \n",
    "            attn_weights = torch.softmax(post_scores / TEMPERATURE, dim=0)\n",
    "\n",
    "            if debug and idx < DEBUG_N_SUBJECTS:\n",
    "                print(\"\\n\" + \"=\"*60)\n",
    "                print(f\"[DEBUG][ATTENTION] Subject: {subject_id}\")\n",
    "                attn_np = attn_weights.cpu().numpy()\n",
    "                print(\"[DEBUG][ATTENTION] Weight stats:\")\n",
    "                print(f\"  min={attn_np.min():.6f} \"\n",
    "                      f\"max={attn_np.max():.6f} \"\n",
    "                      f\"mean={attn_np.mean():.6f} \"\n",
    "                      f\"entropy={-np.sum(attn_np * np.log(attn_np + 1e-12)):.4f}\")\n",
    "\n",
    "                top_attn_idx = np.argsort(-attn_np)[:DEBUG_TOP_N_POSTS]\n",
    "                print(f\"\\n[DEBUG][ATTENTION] Top-{DEBUG_TOP_N_POSTS} attended posts:\")\n",
    "                for rank, i in enumerate(top_attn_idx):\n",
    "                    print(f\"\\n  Rank {rank+1}\")\n",
    "                    print(f\"  Attention: {attn_np[i]:.6f}\")\n",
    "                    print(f\"  Text: {posts[i][:300]}\")\n",
    "\n",
    "            # Weighted sum pooling\n",
    "            pooled = torch.sum(attn_weights.unsqueeze(1) * post_embs, dim=0)\n",
    "            pooled_embeddings.append(pooled.cpu().numpy())\n",
    "\n",
    "            # Clean up GPU memory\n",
    "            del post_embs, cos_scores, attn_weights, pooled\n",
    "\n",
    "    return np.vstack(pooled_embeddings), subject_ids\n",
    "\n",
    "print(\"✓ Memory-optimized attention pooling function defined (MAX-based)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding and pooling embeddings (MAX-based attention, memory-optimized)...\n",
      "  Training set...\n",
      "\n",
      "============================================================\n",
      "[DEBUG][ATTENTION] Subject: subject9683\n",
      "[DEBUG][ATTENTION] Weight stats:\n",
      "  min=0.015762 max=0.059562 mean=0.020000 entropy=3.8741\n",
      "\n",
      "[DEBUG][ATTENTION] Top-5 attended posts:\n",
      "\n",
      "  Rank 1\n",
      "  Attention: 0.059562\n",
      "  Text: Just Pissed Off (Disclaimer: I Might Come Off As An Attention Seeker.)\n",
      "\n",
      "  Rank 2\n",
      "  Attention: 0.029667\n",
      "  Text: ELI5: What does \"nostalgia\" mean?\n",
      "\n",
      "  Rank 3\n",
      "  Attention: 0.027974\n",
      "  Text: Oh really? Please enlighten us on all the \"many mistakes\".\n",
      "\n",
      "  Rank 4\n",
      "  Attention: 0.026314\n",
      "  Text: im assuming Triss-k-eye-deck-ah-phobia\n",
      "\n",
      "  Rank 5\n",
      "  Attention: 0.023876\n",
      "  Text: Sorry, didn't know how to word it :(\n",
      "\n",
      "============================================================\n",
      "[DEBUG][ATTENTION] Subject: subject3364\n",
      "[DEBUG][ATTENTION] Weight stats:\n",
      "  min=0.012327 max=0.046286 mean=0.020000 entropy=3.8613\n",
      "\n",
      "[DEBUG][ATTENTION] Top-5 attended posts:\n",
      "\n",
      "  Rank 1\n",
      "  Attention: 0.046286\n",
      "  Text: I don't want anyone's help anymore I just wanted to say that I spent the last 8 years of my life trying to die and recently, I decided to try to re-gain my will to live again. I guess now is when life decides to try to push me down even more. If there was a time in my life where I should be dead, it\n",
      "\n",
      "  Rank 2\n",
      "  Attention: 0.032139\n",
      "  Text: Why play with toys when you can bite an arm?\n",
      "\n",
      "  Rank 3\n",
      "  Attention: 0.031482\n",
      "  Text: I'm not looking or wanting to get back with him. I'm just asking about the guilt I'm feeling.\n",
      "\n",
      "  Rank 4\n",
      "  Attention: 0.031024\n",
      "  Text: She says it's normal but I would probably assume it's because she's obese.\n",
      "\n",
      "  Rank 5\n",
      "  Attention: 0.029697\n",
      "  Text: Not being enough.\n",
      "\n",
      "============================================================\n",
      "[DEBUG][ATTENTION] Subject: subject7925\n",
      "[DEBUG][ATTENTION] Weight stats:\n",
      "  min=0.008614 max=0.038601 mean=0.020000 entropy=3.8512\n",
      "\n",
      "[DEBUG][ATTENTION] Top-5 attended posts:\n",
      "\n",
      "  Rank 1\n",
      "  Attention: 0.038601\n",
      "  Text: 'You don't deserve happiness' self talk, and how to stop it? When I'm truly happy, I feel like I can accomplish anything, and I feel like a totally different person from the depressed self-loathing human being that I usually am. When I'm depressed, I can't even IMAGINE being happy. I literally canno\n",
      "\n",
      "  Rank 2\n",
      "  Attention: 0.038601\n",
      "  Text: 'You don't deserve happiness' self talk, and how to stop it? When I'm truly happy, I feel like I can accomplish anything, and I feel like a totally different person from the depressed self-loathing human being that I usually am. When I'm depressed, I can't even IMAGINE being happy. I literally canno\n",
      "\n",
      "  Rank 3\n",
      "  Attention: 0.038601\n",
      "  Text: 'You don't deserve happiness' self talk, and how to stop it? When I'm truly happy, I feel like I can accomplish anything, and I feel like a totally different person from the depressed self-loathing human being that I usually am. When I'm depressed, I can't even IMAGINE being happy. I literally canno\n",
      "\n",
      "  Rank 4\n",
      "  Attention: 0.032413\n",
      "  Text: You sound a lot like my brother. He's 20 and he recently asked out a girl for the first time. He got rejected. He's very insecure and the rejection left him saying things like \"I'm not meant to be in a relationship\" and crap like that. Unless you think getting rejected won't take a shot at your self\n",
      "\n",
      "  Rank 5\n",
      "  Attention: 0.032413\n",
      "  Text: You sound a lot like my brother. He's 20 and he recently asked out a girl for the first time. He got rejected. He's very insecure and the rejection left him saying things like \"I'm not meant to be in a relationship\" and crap like that. Unless you think getting rejected won't take a shot at your self\n",
      "    X_train shape: (388, 768)\n",
      "  Validation set...\n",
      "    X_val shape: (98, 768)\n",
      "  Test set...\n",
      "    X_test shape: (401, 768)\n",
      "\n",
      "✓ Encoding complete in 222.0s (3.7 min)\n"
     ]
    }
   ],
   "source": [
    "# Encode and pool for all splits\n",
    "print(\"Encoding and pooling embeddings (MAX-based attention, memory-optimized)...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"  Training set...\")\n",
    "X_train, train_subject_ids = encode_and_attention_pool_max(\n",
    "    train_selected,\n",
    "    sbert_model,\n",
    "    concept_embeddings,\n",
    "    normalize=True,\n",
    "    debug=DEBUG\n",
    ")\n",
    "clear_gpu_cache()\n",
    "print(f\"    X_train shape: {X_train.shape}\")\n",
    "\n",
    "print(\"  Validation set...\")\n",
    "X_val, val_subject_ids = encode_and_attention_pool_max(\n",
    "    val_selected, sbert_model, concept_embeddings, normalize=True\n",
    ")\n",
    "clear_gpu_cache()\n",
    "print(f\"    X_val shape: {X_val.shape}\")\n",
    "\n",
    "print(\"  Test set...\")\n",
    "X_test, test_subject_ids = encode_and_attention_pool_max(\n",
    "    test_selected, sbert_model, concept_embeddings, normalize=True\n",
    ")\n",
    "clear_gpu_cache()\n",
    "print(f\"    X_test shape: {X_test.shape}\")\n",
    "\n",
    "print(f\"\\n✓ Encoding complete in {time.time()-start_time:.1f}s ({(time.time()-start_time)/60:.1f} min)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build concept matrices and label vectors\n",
    "print(\"Building concept matrices and labels...\")\n",
    "\n",
    "# Training: get concepts from COMBINED concept dataframe\n",
    "C_train = []\n",
    "y_train = []\n",
    "for subject_id in train_subject_ids:\n",
    "    label = train_posts_df_final[train_posts_df_final['subject_id'] == subject_id]['label'].iloc[0]\n",
    "    y_train.append(label)\n",
    "    \n",
    "    # Look up in COMBINED concepts dataframe (includes 2022 data)\n",
    "    concept_row = all_concepts_df[all_concepts_df['subject_id'] == subject_id]\n",
    "    if len(concept_row) > 0:\n",
    "        concepts = concept_row[CONCEPT_NAMES].values[0]\n",
    "    else:\n",
    "        print(f\"  WARNING: No concepts found for {subject_id}, using zeros\")\n",
    "        concepts = np.zeros(N_CONCEPTS)\n",
    "    C_train.append(concepts)\n",
    "\n",
    "C_train = np.array(C_train, dtype=np.float32)\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "\n",
    "# Validation: get concepts from COMBINED concept dataframe\n",
    "C_val = []\n",
    "y_val = []\n",
    "for subject_id in val_subject_ids:\n",
    "    label = val_posts_df[val_posts_df['subject_id'] == subject_id]['label'].iloc[0]\n",
    "    y_val.append(label)\n",
    "    \n",
    "    # Look up in COMBINED concepts dataframe (includes 2022 data)\n",
    "    concept_row = all_concepts_df[all_concepts_df['subject_id'] == subject_id]\n",
    "    if len(concept_row) > 0:\n",
    "        concepts = concept_row[CONCEPT_NAMES].values[0]\n",
    "    else:\n",
    "        print(f\"  WARNING: No concepts found for {subject_id}, using zeros\")\n",
    "        concepts = np.zeros(N_CONCEPTS)\n",
    "    C_val.append(concepts)\n",
    "\n",
    "C_val = np.array(C_val, dtype=np.float32)\n",
    "y_val = np.array(y_val, dtype=np.float32)\n",
    "\n",
    "# Test: zeros for concepts (no ground truth available)\n",
    "C_test = np.zeros((len(test_subject_ids), N_CONCEPTS), dtype=np.float32)\n",
    "y_test = []\n",
    "for subject_id in test_subject_ids:\n",
    "    label = test_posts_df_final[test_posts_df_final['subject_id'] == subject_id]['label'].iloc[0]\n",
    "    y_test.append(label)\n",
    "y_test = np.array(y_test, dtype=np.float32)\n",
    "\n",
    "print(\"✓ Matrices built\")\n",
    "print(f\"  Train: X={X_train.shape}, C={C_train.shape}, y={y_train.shape}\")\n",
    "print(f\"  Val:   X={X_val.shape}, C={C_val.shape}, y={y_val.shape}\")\n",
    "print(f\"  Test:  X={X_test.shape}, C={C_test.shape}, y={y_test.shape}\")\n",
    "print(f\"\\n  Training label distribution: {np.bincount(y_train.astype(int))}\")\n",
    "print(f\"  Validation label distribution: {np.bincount(y_val.astype(int))}\")\n",
    "print(f\"  Test label distribution: {np.bincount(y_test.astype(int))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Compute Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class imbalance:\n",
      "  Negative samples: 322\n",
      "  Positive samples: 66\n",
      "  Ratio: 1:4.88\n",
      "  Computed pos_weight: 4.8788\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights for imbalanced dataset\n",
    "n_negative = int(np.sum(y_train == 0))\n",
    "n_positive = int(np.sum(y_train == 1))\n",
    "pos_weight = n_negative / n_positive\n",
    "\n",
    "print(f\"Class imbalance:\")\n",
    "print(f\"  Negative samples: {n_negative}\")\n",
    "print(f\"  Positive samples: {n_positive}\")\n",
    "print(f\"  Ratio: 1:{pos_weight:.2f}\")\n",
    "print(f\"  Computed pos_weight: {pos_weight:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Save All Datasets\n",
    "\n",
    "Save everything for fast loading by training pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving datasets...\n",
      "✓ Datasets saved to /teamspace/studios/this_studio/Master-Thesis-CEM-Depression-etc-case-study/data/processed/largerV2_max_alternative_attention_pipeline\n",
      "  train_data.npz: 388 samples\n",
      "  val_data.npz:   98 samples\n",
      "  test_data.npz:  401 samples\n",
      "  class_weights.json\n"
     ]
    }
   ],
   "source": [
    "# Save processed datasets to disk\n",
    "print(\"Saving datasets...\")\n",
    "\n",
    "# Save numpy arrays\n",
    "np.savez_compressed(\n",
    "    os.path.join(SAVE_DIR, \"train_data.npz\"),\n",
    "    X=X_train,\n",
    "    C=C_train,\n",
    "    y=y_train,\n",
    "    subject_ids=np.array(train_subject_ids)\n",
    ")\n",
    "\n",
    "np.savez_compressed(\n",
    "    os.path.join(SAVE_DIR, \"val_data.npz\"),\n",
    "    X=X_val,\n",
    "    C=C_val,\n",
    "    y=y_val,\n",
    "    subject_ids=np.array(val_subject_ids)\n",
    ")\n",
    "\n",
    "np.savez_compressed(\n",
    "    os.path.join(SAVE_DIR, \"test_data.npz\"),\n",
    "    X=X_test,\n",
    "    C=C_test,\n",
    "    y=y_test,\n",
    "    subject_ids=np.array(test_subject_ids)\n",
    ")\n",
    "\n",
    "# Save class weights info\n",
    "class_info = {\n",
    "    \"n_positive\": n_positive,\n",
    "    \"n_negative\": n_negative,\n",
    "    \"pos_weight\": float(pos_weight)\n",
    "}\n",
    "\n",
    "with open(os.path.join(SAVE_DIR, \"class_weights.json\"), 'w') as f:\n",
    "    json.dump(class_info, f, indent=4)\n",
    "\n",
    "print(f\"✓ Datasets saved to {SAVE_DIR}\")\n",
    "print(f\"  train_data.npz: {X_train.shape[0]} samples\")\n",
    "print(f\"  val_data.npz:   {X_val.shape[0]} samples\")\n",
    "print(f\"  test_data.npz:  {X_test.shape[0]} samples\")\n",
    "print(f\"  class_weights.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 9: Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"    LARGER2022 MAX ALTERNATIVE DATASET PREPARATION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nSaved files:\")\n",
    "print(f\"  {SAVE_DIR}/train_data.npz\")\n",
    "print(f\"  {SAVE_DIR}/val_data.npz\")\n",
    "print(f\"  {SAVE_DIR}/test_data.npz\")\n",
    "print(f\"  {SAVE_DIR}/class_weights.json\")\n",
    "print(\"\\nData sources:\")\n",
    "print(\"  - Original train folder: 486 subjects (83 depressed, 403 controls)\")\n",
    "print(\"  - 2022 data folder: ~1,400 subjects (98 depressed, 1,302 controls)\")\n",
    "print(\"  - Combined training pool: ~1,886 subjects (181 depressed, 1,705 controls)\")\n",
    "print(\"\\nData split strategy:\")\n",
    "print(\"  - Training: 80% of combined pool (~1,509 subjects)\")\n",
    "print(\"  - Validation: 20% of combined pool (~377 subjects)\")\n",
    "print(\"  - Test: 100% of test folder (401 subjects, unchanged)\")\n",
    "print(\"\\nKey features:\")\n",
    "print(\"  - Uses MAX of concept similarities with MPNet model (768-dim)\")\n",
    "print(\"  - Larger, more powerful SBERT model: all-mpnet-base-v2\")\n",
    "print(\"  - Higher quality embeddings (768-dim vs 384-dim)\")\n",
    "print(\"  - Significantly expanded training set with 2022 data\")\n",
    "print(\"\\nUse this data with CEM/CBM training notebooks!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "      LARGER V2 MAX ALTERNATIVE DATASET PREPARATION COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Saved files:\n",
      "  /teamspace/studios/this_studio/Master-Thesis-CEM-Depression-etc-case-study/data/processed/largerV2_max_alternative_attention_pipeline/train_data.npz\n",
      "  /teamspace/studios/this_studio/Master-Thesis-CEM-Depression-etc-case-study/data/processed/largerV2_max_alternative_attention_pipeline/val_data.npz\n",
      "  /teamspace/studios/this_studio/Master-Thesis-CEM-Depression-etc-case-study/data/processed/largerV2_max_alternative_attention_pipeline/test_data.npz\n",
      "  /teamspace/studios/this_studio/Master-Thesis-CEM-Depression-etc-case-study/data/processed/largerV2_max_alternative_attention_pipeline/class_weights.json\n",
      "\n",
      "Data split strategy:\n",
      "  - Training: 80% of train folder (~389 subjects)\n",
      "  - Validation: 20% of train folder (~97 subjects)\n",
      "  - Test: 100% of test folder (401 subjects)\n",
      "\n",
      "Key difference from original:\n",
      "  - Uses MAX of concept similarities with MPNet model (768-dim)\n",
      "  - Larger, more powerful SBERT model: all-mpnet-base-v2\n",
      "  - Higher quality embeddings (768-dim vs 384-dim)\n",
      "\n",
      "Use this data with CEM/CBM training notebooks!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"      LARGER V2 MAX ALTERNATIVE DATASET PREPARATION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nSaved files:\")\n",
    "print(f\"  {SAVE_DIR}/train_data.npz\")\n",
    "print(f\"  {SAVE_DIR}/val_data.npz\")\n",
    "print(f\"  {SAVE_DIR}/test_data.npz\")\n",
    "print(f\"  {SAVE_DIR}/class_weights.json\")\n",
    "print(\"\\nData split strategy:\")\n",
    "print(\"  - Training: 80% of train folder (~389 subjects)\")\n",
    "print(\"  - Validation: 20% of train folder (~97 subjects)\")\n",
    "print(\"  - Test: 100% of test folder (401 subjects)\")\n",
    "print(\"\\nKey difference from original:\")\n",
    "print(\"  - Uses MAX of concept similarities with MPNet model (768-dim)\")\n",
    "print(\"  - Larger, more powerful SBERT model: all-mpnet-base-v2\")\n",
    "print(\"  - Higher quality embeddings (768-dim vs 384-dim)\")\n",
    "print(\"\\nUse this data with CEM/CBM training notebooks!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
