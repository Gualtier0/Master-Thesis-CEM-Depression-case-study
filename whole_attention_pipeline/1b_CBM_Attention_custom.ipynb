{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete CBM Pipeline - Concept Bottleneck Model\n",
    "\n",
    "This notebook implements a complete pipeline for:\n",
    "1. Loading preprocessed data from disk\n",
    "2. Training a simple Concept Bottleneck Model (CBM)\n",
    "3. Evaluating with detailed metrics and concept probabilities\n",
    "\n",
    "**Architecture:** X → Concept Logits → Concepts → Task Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 0: Configuration & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef,\n",
    "    roc_auc_score,\n",
    "    balanced_accuracy_score,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Random seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "pl.seed_everything(SEED)\n",
    "\n",
    "print(f\"✓ Random seed set to {SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Using MacBook GPU (MPS)\n"
     ]
    }
   ],
   "source": [
    "# Detect device (MPS/CUDA/CPU)\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "    print(\"✓ Using MacBook GPU (MPS)\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "    print(\"✓ Using CUDA GPU\")\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "    print(\"⚠ Using CPU (will be slow)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Paths configured\n",
      "  Project root: /Users/gualtieromarencoturi/Desktop/thesis/Master-Thesis-CEM-Depression-etc-case-study\n",
      "  Dataset dir: /Users/gualtieromarencoturi/Desktop/thesis/Master-Thesis-CEM-Depression-etc-case-study/data/processed/whole_attention_pipeline\n",
      "  Output dir: outputs_cbm\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "DATA_PROCESSED = os.path.join(PROJECT_ROOT, \"data/processed\")\n",
    "DATASET_DIR = os.path.join(DATA_PROCESSED, \"whole_attention_pipeline\")\n",
    "OUTPUT_DIR = \"outputs_cbm\"\n",
    "\n",
    "print(\"✓ Paths configured\")\n",
    "print(f\"  Project root: {PROJECT_ROOT}\")\n",
    "print(f\"  Dataset dir: {DATASET_DIR}\")\n",
    "print(f\"  Output dir: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Defined 21 BDI-II concepts\n"
     ]
    }
   ],
   "source": [
    "# Define 21 BDI-II concept names\n",
    "CONCEPT_NAMES = [\n",
    "    \"Sadness\", \"Pessimism\", \"Past failure\", \"Loss of pleasure\",\n",
    "    \"Guilty feelings\", \"Punishment feelings\", \"Self-dislike\", \"Self-criticalness\",\n",
    "    \"Suicidal thoughts or wishes\", \"Crying\", \"Agitation\", \"Loss of interest\",\n",
    "    \"Indecisiveness\", \"Worthlessness\", \"Loss of energy\", \"Changes in sleeping pattern\",\n",
    "    \"Irritability\", \"Changes in appetite\", \"Concentration difficulty\",\n",
    "    \"Tiredness or fatigue\", \"Loss of interest in sex\"\n",
    "]\n",
    "N_CONCEPTS = len(CONCEPT_NAMES)\n",
    "\n",
    "print(f\"✓ Defined {N_CONCEPTS} BDI-II concepts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters - UPDATED for better learning\n",
    "HYPERPARAMS = {\n",
    "    # Model architecture\n",
    "    \"embedding_dim\": 384,       # SBERT embedding dimension\n",
    "    \"n_concepts\": 21,\n",
    "    \"n_tasks\": 1,\n",
    "    \n",
    "    # Training - REDUCED LR, INCREASED BATCH SIZE\n",
    "    \"batch_size_train\": 64,     # Increased for stability\n",
    "    \"batch_size_eval\": 128,     # Increased for faster eval\n",
    "    \"max_epochs\": 200,          # More epochs for convergence\n",
    "    \"learning_rate\": 0.001,     # REDUCED LR for stability\n",
    "    \"weight_decay\": 0.001,      # Reduced regularization\n",
    "    \n",
    "    # Loss weights - BALANCED LOSSES\n",
    "    \"concept_loss_weight\": 1.0, # EQUAL weight for concepts and task\n",
    "    \"task_pos_weight\": 4.86,    # TRUE imbalance ratio\n",
    "    \n",
    "    # Hard bottleneck configuration - RELAXED\n",
    "    \"hard_bottleneck\": False,   # TRY SOFT BOTTLENECK FIRST\n",
    "    \"concept_threshold\": 0.3,   # Higher threshold for more activation\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Load Preprocessed Data\n",
    "\n",
    "Load the datasets that were saved by the CEM pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed datasets...\n",
      "✓ Loaded training data:\n",
      "  X_train: (486, 384)\n",
      "  C_train: (486, 21)\n",
      "  y_train: (486,)\n",
      "  Subject IDs: 486\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "print(\"Loading preprocessed datasets...\")\n",
    "\n",
    "train_data = np.load(os.path.join(DATASET_DIR, \"train_data.npz\"))\n",
    "X_train = train_data['X']\n",
    "C_train = train_data['C']\n",
    "y_train = train_data['y']\n",
    "train_subject_ids = train_data['subject_ids']\n",
    "\n",
    "print(f\"✓ Loaded training data:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  C_train: {C_train.shape}\")\n",
    "print(f\"  y_train: {y_train.shape}\")\n",
    "print(f\"  Subject IDs: {len(train_subject_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded validation data:\n",
      "  X_val: (200, 384)\n",
      "  C_val: (200, 21)\n",
      "  y_val: (200,)\n"
     ]
    }
   ],
   "source": [
    "# Load validation data\n",
    "val_data = np.load(os.path.join(DATASET_DIR, \"val_data.npz\"))\n",
    "X_val = val_data['X']\n",
    "C_val = val_data['C']\n",
    "y_val = val_data['y']\n",
    "val_subject_ids = val_data['subject_ids']\n",
    "\n",
    "print(f\"✓ Loaded validation data:\")\n",
    "print(f\"  X_val: {X_val.shape}\")\n",
    "print(f\"  C_val: {C_val.shape}\")\n",
    "print(f\"  y_val: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded test data:\n",
      "  X_test: (201, 384)\n",
      "  C_test: (201, 21)\n",
      "  y_test: (201,)\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "test_data = np.load(os.path.join(DATASET_DIR, \"test_data.npz\"))\n",
    "X_test = test_data['X']\n",
    "C_test = test_data['C']\n",
    "y_test = test_data['y']\n",
    "test_subject_ids = test_data['subject_ids']\n",
    "\n",
    "print(f\"✓ Loaded test data:\")\n",
    "print(f\"  X_test: {X_test.shape}\")\n",
    "print(f\"  C_test: {C_test.shape}\")\n",
    "print(f\"  y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded class weights:\n",
      "  Negative samples: 403\n",
      "  Positive samples: 83\n",
      "  Ratio: 1:4.86\n",
      "  pos_weight: 4.8554\n"
     ]
    }
   ],
   "source": [
    "# Load class weights\n",
    "with open(os.path.join(DATASET_DIR, \"class_weights.json\"), 'r') as f:\n",
    "    class_info = json.load(f)\n",
    "\n",
    "n_positive = class_info['n_positive']\n",
    "n_negative = class_info['n_negative']\n",
    "pos_weight = class_info['pos_weight']\n",
    "\n",
    "# Convert to tensor\n",
    "pos_weight_tensor = torch.tensor([pos_weight], dtype=torch.float32)\n",
    "\n",
    "print(f\"✓ Loaded class weights:\")\n",
    "print(f\"  Negative samples: {n_negative}\")\n",
    "print(f\"  Positive samples: {n_positive}\")\n",
    "print(f\"  Ratio: 1:{pos_weight:.2f}\")\n",
    "print(f\"  pos_weight: {pos_weight:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: PyTorch Dataset & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CBMDataset class defined\n"
     ]
    }
   ],
   "source": [
    "class CBMDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for CBM model.\"\"\"\n",
    "    \n",
    "    def __init__(self, X, C, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.C = torch.tensor(C, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.C[idx]\n",
    "\n",
    "print(\"✓ CBMDataset class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Datasets created\n",
      "  Train: 486 samples\n",
      "  Val: 200 samples\n",
      "  Test: 201 samples\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_dataset = CBMDataset(X_train, C_train, y_train)\n",
    "val_dataset = CBMDataset(X_val, C_val, y_val)\n",
    "test_dataset = CBMDataset(X_test, C_test, y_test)\n",
    "\n",
    "print(\"✓ Datasets created\")\n",
    "print(f\"  Train: {len(train_dataset)} samples\")\n",
    "print(f\"  Val: {len(val_dataset)} samples\")\n",
    "print(f\"  Test: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ DataLoaders created\n",
      "  Train batches: 8\n",
      "  Val batches: 2\n",
      "  Test batches: 2\n",
      "\n",
      "  Sample batch shapes:\n",
      "    X: torch.Size([64, 384])\n",
      "    y: torch.Size([64])\n",
      "    C: torch.Size([64, 21])\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=HYPERPARAMS['batch_size_train'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=HYPERPARAMS['batch_size_eval'],\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=HYPERPARAMS['batch_size_eval'],\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"✓ DataLoaders created\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Test batch\n",
    "x_batch, y_batch, c_batch = next(iter(train_loader))\n",
    "print(f\"\\n  Sample batch shapes:\")\n",
    "print(f\"    X: {x_batch.shape}\")\n",
    "print(f\"    y: {y_batch.shape}\")\n",
    "print(f\"    C: {c_batch.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Concept Bottleneck Model\n",
    "\n",
    "Simple CBM architecture:\n",
    "- X → Concept Extractor → Concept Logits\n",
    "- Concept Probabilities (sigmoid) → Task Classifier → Task Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CBM model defined with HARD bottleneck support\n"
     ]
    }
   ],
   "source": [
    "class ConceptBottleneckModel(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Concept Bottleneck Model with HARD bottleneck support.\n",
    "    \n",
    "    Architecture:\n",
    "      X -> concept extractor -> concept logits -> discrete concepts (hard bottleneck) -> task classifier -> y\n",
    "    \n",
    "    Hard bottleneck ensures:\n",
    "      - Concepts are discrete (0 or 1), not continuous probabilities\n",
    "      - Task classifier only sees binary concept values\n",
    "      - True interpretability and intervention capability\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        n_concepts,\n",
    "        task_output_dim,\n",
    "        c_extractor_arch,\n",
    "        learning_rate=0.01,\n",
    "        weight_decay=1e-4,\n",
    "        concept_loss_weight=1.0,\n",
    "        task_pos_weight=2.0,\n",
    "        hard_bottleneck=True,\n",
    "        concept_threshold=0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['c_extractor_arch'])\n",
    "        \n",
    "        # Concept extractor\n",
    "        self.concept_extractor = c_extractor_arch(output_dim=n_concepts)\n",
    "        \n",
    "        # IMPROVED Task classifier - small MLP instead of linear\n",
    "        self.task_classifier = nn.Sequential(\n",
    "            nn.Linear(n_concepts, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, task_output_dim)\n",
    "        )\n",
    "        \n",
    "        # Loss functions\n",
    "        self.concept_loss_fn = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        # Task loss: plain BCEWithLogitsLoss with modest pos_weight\n",
    "        # Use the passed task_pos_weight parameter\n",
    "        task_pos_weight_tensor = torch.tensor([task_pos_weight], dtype=torch.float32)\n",
    "        self.task_loss_fn = nn.BCEWithLogitsLoss(pos_weight=task_pos_weight_tensor)\n",
    "        print(f\"✓ Task BCEWithLogitsLoss pos_weight set to {task_pos_weight_tensor.item():.2f}\")\n",
    "\n",
    "        # For threshold optimization during validation\n",
    "        self.validation_outputs = []\n",
    "    \n",
    "    def forward(self, x, use_ground_truth_concepts=False, c_true=None):\n",
    "        \"\"\"\n",
    "        Forward pass with hard bottleneck support.\n",
    "        \n",
    "        Args:\n",
    "            x: Input features\n",
    "            use_ground_truth_concepts: If True, use c_true instead of predictions (for intervention)\n",
    "            c_true: Ground truth concepts (optional)\n",
    "        \n",
    "        Returns:\n",
    "            concept_logits: Raw concept predictions (None if using ground truth)\n",
    "            task_logits: Task predictions\n",
    "        \"\"\"\n",
    "        if use_ground_truth_concepts and c_true is not None:\n",
    "            # Use ground truth concepts (for intervention experiments)\n",
    "            concept_input = c_true\n",
    "            concept_logits = None\n",
    "        else:\n",
    "            # Get concept predictions\n",
    "            concept_logits = self.concept_extractor(x)\n",
    "            concept_probs = torch.sigmoid(concept_logits)\n",
    "            \n",
    "            if self.hparams.hard_bottleneck:\n",
    "                # HARD BOTTLENECK: Use discrete predictions, detach gradients\n",
    "                # This creates a true bottleneck - task classifier only sees binary concept values\n",
    "                # and cannot backpropagate gradients to the concept extractor\n",
    "                concept_input = (concept_probs >= self.hparams.concept_threshold).float().detach()\n",
    "            else:\n",
    "                # SOFT BOTTLENECK: Use continuous probabilities (end-to-end training)\n",
    "                concept_input = concept_probs\n",
    "        \n",
    "        # Task prediction from concepts\n",
    "        task_logits = self.task_classifier(concept_input)\n",
    "        \n",
    "        return concept_logits, task_logits\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, c = batch\n",
    "        concept_logits, task_logits = self(x)\n",
    "        \n",
    "        # Concept loss\n",
    "        concept_loss = self.concept_loss_fn(concept_logits, c)\n",
    "        \n",
    "        # Task loss\n",
    "        task_loss = self.task_loss_fn(task_logits.squeeze(), y.squeeze())\n",
    "        \n",
    "        # Combined loss (single-stage)\n",
    "        loss = task_loss + self.hparams.concept_loss_weight * concept_loss\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log('train_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_concept_loss', concept_loss, on_epoch=True)\n",
    "        self.log('train_task_loss', task_loss, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, c = batch\n",
    "        concept_logits, task_logits = self(x)\n",
    "        \n",
    "        # Concept loss\n",
    "        concept_loss = self.concept_loss_fn(concept_logits, c)\n",
    "        \n",
    "        # Task loss\n",
    "        task_loss = self.task_loss_fn(task_logits.squeeze(), y.squeeze())\n",
    "        \n",
    "        # Combined loss\n",
    "        loss = task_loss + self.hparams.concept_loss_weight * concept_loss\n",
    "        \n",
    "        # Store outputs for threshold optimization\n",
    "        self.validation_outputs.append({\n",
    "            'task_logits': task_logits.detach().cpu().float(),  # Convert to float32\n",
    "            'y_true': y.detach().cpu().float()  # Convert to float32\n",
    "        })\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log('val_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_concept_loss', concept_loss, on_epoch=True)\n",
    "        self.log('val_task_loss', task_loss, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"Find best threshold on validation set at end of each epoch.\"\"\"\n",
    "        if len(self.validation_outputs) == 0:\n",
    "            return\n",
    "        \n",
    "        # Collect all validation predictions\n",
    "        all_logits = torch.cat([x['task_logits'] for x in self.validation_outputs])\n",
    "        all_y_true = torch.cat([x['y_true'] for x in self.validation_outputs])\n",
    "        \n",
    "        # Convert to numpy as float32 (not float64)\n",
    "        logits = all_logits.squeeze().numpy().astype(np.float32)\n",
    "        y_true = all_y_true.numpy().astype(np.int32)\n",
    "        probs = 1.0 / (1.0 + np.exp(-logits))  # sigmoid\n",
    "        \n",
    "        # Log logit statistics - ensure float32 before converting to Python float\n",
    "        self.log('val_logit_min', float(np.min(logits).astype(np.float32)))\n",
    "        self.log('val_logit_mean', float(np.mean(logits).astype(np.float32)))\n",
    "        self.log('val_logit_max', float(np.max(logits).astype(np.float32)))\n",
    "        \n",
    "        # Sweep thresholds to find best MCC\n",
    "        from sklearn.metrics import matthews_corrcoef\n",
    "        \n",
    "        best_mcc = -1.0\n",
    "        best_threshold = 0.5\n",
    "        \n",
    "        for threshold in np.arange(0.1, 0.9, 0.05):\n",
    "            y_pred = (probs >= threshold).astype(np.int32)\n",
    "            mcc = matthews_corrcoef(y_true, y_pred)\n",
    "            if mcc > best_mcc:\n",
    "                best_mcc = mcc\n",
    "                best_threshold = float(threshold)\n",
    "        \n",
    "        # Log as float32 to avoid MPS issues\n",
    "        self.log('val_best_threshold', float(np.float32(best_threshold)))\n",
    "        self.log('val_best_mcc', float(np.float32(best_mcc)))\n",
    "        \n",
    "        # Clear for next epoch\n",
    "        self.validation_outputs.clear()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.learning_rate,\n",
    "            weight_decay=self.hparams.weight_decay\n",
    "        )\n",
    "        \n",
    "        # Add learning rate scheduler for better convergence\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, \n",
    "            mode='min', \n",
    "            factor=0.5, \n",
    "            patience=10, \n",
    "            min_lr=1e-6,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\",\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "\n",
    "print(\"✓ CBM model defined with HARD bottleneck support\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Concept extractor architecture defined\n"
     ]
    }
   ],
   "source": [
    "def c_extractor_arch(output_dim):\n",
    "    \"\"\"IMPROVED Concept extractor architecture - deeper network.\"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(HYPERPARAMS['embedding_dim'], 512),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.BatchNorm1d(256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(256, output_dim)\n",
    "    )\n",
    "\n",
    "print(\"✓ Concept extractor architecture defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Task BCEWithLogitsLoss pos_weight set to 4.86\n",
      "✓ Task classifier bias initialized to log-odds: -1.5801\n",
      "✓ CBM model initialized\n",
      "  Task pos_weight: 4.86\n",
      "  Hard bottleneck: False (HARD with threshold=0.3)\n",
      "  Concept threshold: 0.3 (lowered from 0.5 to match learned distributions)\n",
      "  Concept loss weight: 1.0 (reduced to prioritize task)\n",
      "  Learning rate: 0.001 (increased to escape local minima)\n"
     ]
    }
   ],
   "source": [
    "# Get class counts\n",
    "n_positive = class_info['n_positive']\n",
    "n_negative = class_info['n_negative']\n",
    "\n",
    "# Initialize CBM model\n",
    "cbm_model = ConceptBottleneckModel(\n",
    "    input_dim=HYPERPARAMS['embedding_dim'],\n",
    "    n_concepts=HYPERPARAMS['n_concepts'],\n",
    "    task_output_dim=1,\n",
    "    c_extractor_arch=c_extractor_arch,\n",
    "    learning_rate=HYPERPARAMS['learning_rate'],\n",
    "    weight_decay=HYPERPARAMS['weight_decay'],\n",
    "    concept_loss_weight=HYPERPARAMS['concept_loss_weight'],\n",
    "    task_pos_weight=HYPERPARAMS['task_pos_weight'],\n",
    "    hard_bottleneck=HYPERPARAMS['hard_bottleneck'],\n",
    "    concept_threshold=HYPERPARAMS['concept_threshold'],\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize task classifier bias to match positive prevalence\n",
    "pos_frac = n_positive / (n_positive + n_negative)  # e.g., 26/201\n",
    "bias_init = np.log(pos_frac / (1 - pos_frac))      # log-odds\n",
    "\n",
    "# Safely access bias from the last layer in the Sequential model\n",
    "if hasattr(cbm_model.task_classifier[-1], 'bias') and cbm_model.task_classifier[-1].bias is not None:\n",
    "    cbm_model.task_classifier[-1].bias.data.fill_(bias_init)\n",
    "    print(f\"✓ Task classifier bias initialized to log-odds: {bias_init:.4f}\")\n",
    "else:\n",
    "    print(f\"⚠ Could not initialize bias (last layer has no bias), bias_init would be: {bias_init:.4f}\")\n",
    "print(\"✓ CBM model initialized\")\n",
    "print(f\"  Task pos_weight: {HYPERPARAMS['task_pos_weight']}\")\n",
    "print(f\"  Hard bottleneck: {HYPERPARAMS['hard_bottleneck']} (HARD with threshold={HYPERPARAMS['concept_threshold']})\")\n",
    "print(f\"  Concept threshold: {HYPERPARAMS['concept_threshold']} (lowered from 0.5 to match learned distributions)\")\n",
    "print(f\"  Concept loss weight: {HYPERPARAMS['concept_loss_weight']} (reduced to prioritize task)\")\n",
    "print(f\"  Learning rate: {HYPERPARAMS['learning_rate']} (increased to escape local minima)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "          SINGLE-STAGE HARD BOTTLENECK TRAINING\n",
      "======================================================================\n",
      "\n",
      "Training concepts and task jointly with hard bottleneck (threshold=0.15)\n",
      "Lower threshold allows ~30-50% of concepts to activate (not all zeros)\n",
      "\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "MODEL ANALYSIS BEFORE TRAINING\n",
      "======================================================================\n",
      "Input shape: torch.Size([64, 384])\n",
      "Concept logits shape: torch.Size([64, 21])\n",
      "Task logits shape: torch.Size([64, 1])\n",
      "Concept probs range: [0.053, 0.942]\n",
      "Task probs range: [0.033, 0.338]\n",
      "\n",
      "Concept activation means: tensor([0.5356, 0.5261, 0.4431, 0.4537, 0.4602, 0.4069, 0.5374, 0.5406, 0.5243,\n",
      "        0.5960, 0.4888, 0.5445, 0.5317, 0.5341, 0.4959, 0.5237, 0.4854, 0.3957,\n",
      "        0.4813, 0.4105, 0.5528])\n",
      "Concepts with >50% activation: 11/21\n",
      "\n",
      "Batch class distribution: 8.0/64 positive samples\n",
      "\n",
      "======================================================================\n",
      "STARTING TRAINING...\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/38concept_embedding/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name              | Type              | Params\n",
      "--------------------------------------------------------\n",
      "0 | concept_extractor | Sequential        | 335 K \n",
      "1 | task_classifier   | Sequential        | 1.6 K \n",
      "2 | concept_loss_fn   | BCEWithLogitsLoss | 0     \n",
      "3 | task_loss_fn      | BCEWithLogitsLoss | 0     \n",
      "--------------------------------------------------------\n",
      "336 K     Trainable params\n",
      "0         Non-trainable params\n",
      "336 K     Total params\n",
      "1.348     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15166df584014e758079710c9e1e995b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/38concept_embedding/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/miniconda3/envs/38concept_embedding/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/miniconda3/envs/38concept_embedding/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d387a6c1994493da69e8d409902cb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7b3e62dd5147ce9e49bacd5bffad71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 1.971\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ee5fde09f64eb597b1c46daaa1d75c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.145 >= min_delta = 0.0. New best score: 1.826\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641876d38e284867b2cac0547165c631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.185 >= min_delta = 0.0. New best score: 1.641\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620dcf3f0b464484948f68c74c88fab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.217 >= min_delta = 0.0. New best score: 1.424\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b340c72b416949f59fd4a65ebe4a1ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.175 >= min_delta = 0.0. New best score: 1.249\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a780a5a3da4c21b802b98db8120058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.118 >= min_delta = 0.0. New best score: 1.131\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c3e113db07400f829ffbb4dd5806de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.145 >= min_delta = 0.0. New best score: 0.986\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14031ed63aff42c584045e781ff91266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.120 >= min_delta = 0.0. New best score: 0.866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad969eccc8e24ba59d75701c12bbd071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c2e249903f4e86988f850ac65772f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73bdbc0a18c74d38ab1f4d8a8c244041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.042 >= min_delta = 0.0. New best score: 0.824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b411b2ac1d14bbfa4e80cae37599f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.078 >= min_delta = 0.0. New best score: 0.746\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c97c1e8e7e41d1846288fe7ed396be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.738\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812c3ec5c3cb4165a143254308e69991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094da7634fca43d4a1ed9ac4d1509ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc557122971741309e8c065042626c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502fa6bdcff541f486031aed2521097f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94cca0658fdf4a60bb2101fde65fc71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a3bab81f7b4ad4a1627355adeb1895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343a220bfcd340468d1706e1c11b97d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c292b6cdcb7846d8b7cf209c715342aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.028 >= min_delta = 0.0. New best score: 0.709\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5c234ffcad4f71a216b878f66dafc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d95ee8f2ec478e859cf9c10747bcb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f022d85a78141c8842dc2e00b4f1c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760e282d8020489385a34ca843e6301b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3708cebddd0c4cd7b6996b14126cf2ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de12bdeb22ba480cad66526f2b2f0513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f6c35aa5c0415d803a1af437850ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11fb50f5a3b04a0f91885898314a61ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115a7a49f5c946fa9d707dc2a48305c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65596a2779ce43869bebef6ccdc26aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb052f54a82478bb6e1d1d0675c3e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddfb3e4051374656b0b6dae6c2eb1cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fdb1a046a34460caa1a8672777cf2ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362a0dfb37ee45409f037a882e960d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b00c70351c2d493db754237e167eb748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c21ab02d705b4ac29f909be0a06804f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc51e63e6824331a89d2d7315ec4b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442a5130db2c433184df9a653ea43120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466e8fc1922a41b99686f1a1fcf479d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105824350a1d4656bf01edf0fd096d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 20 records. Best score: 0.709. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "✓ TRAINING COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"          SINGLE-STAGE HARD BOTTLENECK TRAINING\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(\"Training concepts and task jointly with hard bottleneck (threshold=0.15)\")\n",
    "print(\"Lower threshold allows ~30-50% of concepts to activate (not all zeros)\")\n",
    "print()\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Early stopping callback\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20,\n",
    "    mode='min',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Checkpoint callback\n",
    "checkpoint = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    dirpath=os.path.join(OUTPUT_DIR, \"models\"),\n",
    "    filename=\"cbm-{epoch:02d}-{val_loss:.2f}\",\n",
    "    save_top_k=1,\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "# ADDITIONAL CALLBACK: Monitor concept activation\n",
    "class ConceptActivationCallback(pl.Callback):\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        # Log concept activation statistics\n",
    "        if hasattr(pl_module, 'validation_outputs') and len(pl_module.validation_outputs) > 0:\n",
    "            # Get concept predictions from a few validation batches\n",
    "            concept_activations = []\n",
    "            for batch in trainer.val_dataloaders[0]:\n",
    "                x_batch, y_batch, c_batch = batch\n",
    "                x_batch = x_batch.to(pl_module.device)\n",
    "                c_logits, _ = pl_module(x_batch)\n",
    "                c_probs = torch.sigmoid(c_logits).detach().cpu().numpy()\n",
    "                concept_activations.append(c_probs)\n",
    "                if len(concept_activations) >= 5:  # Sample from 5 batches\n",
    "                    break\n",
    "            \n",
    "            if concept_activations:\n",
    "                avg_activations = np.mean(np.concatenate(concept_activations), axis=0)\n",
    "                for i, activation in enumerate(avg_activations):\n",
    "                    pl_module.log(f'concept_{i}_activation', float(activation))\n",
    "                \n",
    "                # Log overall concept sparsity\n",
    "                sparsity = np.mean(avg_activations < 0.1)  # Concepts with <10% activation\n",
    "                pl_module.log('concept_sparsity', float(sparsity))\n",
    "\n",
    "# Trainer with additional monitoring\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=HYPERPARAMS['max_epochs'],\n",
    "    accelerator=DEVICE,\n",
    "    devices=1,\n",
    "    logger=CSVLogger(save_dir=os.path.join(OUTPUT_DIR, \"logs\"), name=\"cbm\"),\n",
    "    log_every_n_steps=10,\n",
    "    callbacks=[early_stop, checkpoint, ConceptActivationCallback()],\n",
    "    enable_progress_bar=True\n",
    ")\n",
    "\n",
    "# DEBUGGING CELL: Analyze model behavior before training\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL ANALYSIS BEFORE TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test forward pass on a single batch\n",
    "x_batch, y_batch, c_batch = next(iter(train_loader))\n",
    "x_batch = x_batch.to(device_obj) if 'device_obj' in locals() else x_batch\n",
    "\n",
    "with torch.no_grad():\n",
    "    c_logits, y_logits = cbm_model(x_batch)\n",
    "    c_probs = torch.sigmoid(c_logits)\n",
    "    y_probs = torch.sigmoid(y_logits)\n",
    "\n",
    "print(f\"Input shape: {x_batch.shape}\")\n",
    "print(f\"Concept logits shape: {c_logits.shape}\")\n",
    "print(f\"Task logits shape: {y_logits.shape}\")\n",
    "print(f\"Concept probs range: [{c_probs.min().item():.3f}, {c_probs.max().item():.3f}]\")\n",
    "print(f\"Task probs range: [{y_probs.min().item():.3f}, {y_probs.max().item():.3f}]\")\n",
    "\n",
    "# Check concept activation distribution\n",
    "concept_means = c_probs.mean(dim=0)\n",
    "print(f\"\\nConcept activation means: {concept_means}\")\n",
    "print(f\"Concepts with >50% activation: {(concept_means > 0.5).sum().item()}/{len(concept_means)}\")\n",
    "\n",
    "# Check class distribution in batch\n",
    "print(f\"\\nBatch class distribution: {y_batch.sum().item()}/{len(y_batch)} positive samples\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STARTING TRAINING...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Train\n",
    "trainer.fit(cbm_model, train_loader, val_loader)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ TRAINING COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model set to evaluation mode\n"
     ]
    }
   ],
   "source": [
    "# Set model to evaluation mode\n",
    "cbm_model.eval()\n",
    "\n",
    "# Move model to device\n",
    "device_obj = torch.device(DEVICE)\n",
    "cbm_model = cbm_model.to(device_obj)\n",
    "\n",
    "print(\"✓ Model set to evaluation mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on test set...\n",
      "✓ Inference complete\n",
      "  Probabilities shape: (201,)\n",
      "  Concept probs shape: (201, 21)\n",
      "\n",
      "Test set logit statistics:\n",
      "  Min:  -4.8226\n",
      "  Mean: -2.6702\n",
      "  Max:  7.6939\n",
      "  Std:  2.4685\n",
      "  ✓ Logits show good diversity\n",
      "\n",
      "✓ Using threshold from validation: 0.45\n",
      "  Predictions shape: (201,)\n"
     ]
    }
   ],
   "source": [
    "# Run inference on test set\n",
    "print(\"Running inference on test set...\")\n",
    "\n",
    "y_true_list = []\n",
    "y_prob_list = []\n",
    "y_logits_list = []\n",
    "concept_probs_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch, c_batch in test_loader:\n",
    "        x_batch = x_batch.to(device_obj)\n",
    "        \n",
    "        # Forward pass\n",
    "        c_logits, y_logits = cbm_model(x_batch)\n",
    "        \n",
    "        # Apply sigmoid to get probabilities\n",
    "        c_probs = torch.sigmoid(c_logits).cpu().numpy()\n",
    "        y_probs = torch.sigmoid(y_logits).cpu().squeeze().numpy()\n",
    "        \n",
    "        # Collect results\n",
    "        y_true_list.extend(y_batch.numpy().astype(int).tolist())\n",
    "        y_prob_list.extend(y_probs.tolist() if isinstance(y_probs, np.ndarray) else [y_probs])\n",
    "        y_logits_list.extend(y_logits.cpu().squeeze().numpy().tolist() if y_logits.dim() > 1 else [y_logits.cpu().squeeze().item()])\n",
    "        concept_probs_list.extend(c_probs.tolist())\n",
    "\n",
    "# Convert to arrays\n",
    "y_true = np.array(y_true_list)\n",
    "y_prob = np.array(y_prob_list)\n",
    "y_logits = np.array(y_logits_list)\n",
    "concept_probs = np.array(concept_probs_list)\n",
    "\n",
    "print(\"✓ Inference complete\")\n",
    "print(f\"  Probabilities shape: {y_prob.shape}\")\n",
    "print(f\"  Concept probs shape: {concept_probs.shape}\")\n",
    "\n",
    "# Log test logit statistics\n",
    "print(f\"\\nTest set logit statistics:\")\n",
    "print(f\"  Min:  {np.min(y_logits):.4f}\")\n",
    "print(f\"  Mean: {np.mean(y_logits):.4f}\")\n",
    "print(f\"  Max:  {np.max(y_logits):.4f}\")\n",
    "print(f\"  Std:  {np.std(y_logits):.4f}\")\n",
    "\n",
    "# Check for diversity (should NOT be all identical)\n",
    "if np.std(y_logits) < 0.01:\n",
    "    print(\"  ⚠ WARNING: Logits have very low variance - model may have collapsed!\")\n",
    "else:\n",
    "    print(\"  ✓ Logits show good diversity\")\n",
    "\n",
    "# Get best threshold from final validation epoch\n",
    "# Read from trainer logs\n",
    "import pandas as pd\n",
    "log_dir = os.path.join(OUTPUT_DIR, \"logs/cbm/version_0/metrics.csv\")\n",
    "if os.path.exists(log_dir):\n",
    "    metrics_df = pd.read_csv(log_dir)\n",
    "    # Get last non-null val_best_threshold\n",
    "    best_threshold = metrics_df['val_best_threshold'].dropna().iloc[-1]\n",
    "    print(f\"\\n✓ Using threshold from validation: {best_threshold:.2f}\")\n",
    "else:\n",
    "    # Fallback: find best threshold on validation set manually\n",
    "    print(\"\\n⚠ No validation logs found, using threshold=0.5\")\n",
    "    best_threshold = 0.5\n",
    "\n",
    "# Use best threshold for final predictions\n",
    "y_pred = (y_prob >= best_threshold).astype(int)\n",
    "print(f\"  Predictions shape: {y_pred.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics...\n",
      "✓ Metrics computed\n"
     ]
    }
   ],
   "source": [
    "# Compute all metrics\n",
    "print(\"Computing metrics...\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Metrics\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "roc_auc = roc_auc_score(y_true, y_prob)\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "f1_binary = f1_score(y_true, y_pred, pos_label=1)\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "f1_micro = f1_score(y_true, y_pred, average='micro')\n",
    "\n",
    "precision_binary = precision_score(y_true, y_pred, pos_label=1)\n",
    "recall_binary = recall_score(y_true, y_pred, pos_label=1)\n",
    "\n",
    "print(\"✓ Metrics computed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "                    TEST SET EVALUATION\n",
      "======================================================================\n",
      "\n",
      "Dataset Statistics:\n",
      "  Test subjects:        201\n",
      "  Positive cases:       26 (12.9%)\n",
      "  Negative cases:       175 (87.1%)\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:                  0.8557\n",
      "  Balanced Accuracy:         0.6715\n",
      "  ROC-AUC:                   0.8101\n",
      "  Matthews Correlation:      0.3489\n",
      "\n",
      "  F1 Score (Binary):         0.4314\n",
      "  F1 Score (Macro):          0.6744\n",
      "  F1 Score (Micro):          0.8557\n",
      "\n",
      "  Precision (Binary):        0.4400\n",
      "  Recall (Binary):           0.4231\n",
      "\n",
      "                 CONFUSION MATRIX                 \n",
      "==================================================\n",
      "                     │ Predicted Negative │ Predicted Positive\n",
      "──────────────────────────────────────────────────\n",
      "     Actual Negative │   TN = 161   │   FP = 14   \n",
      "     Actual Positive │   FN = 15    │   TP = 11   \n",
      "==================================================\n",
      "\n",
      "  True Positives:   11/26  ( 42.3% of depression cases caught)\n",
      "  False Negatives:  15/26  ( 57.7% of depression cases MISSED)\n",
      "  True Negatives:  161/175 ( 92.0% of healthy correctly identified)\n",
      "  False Positives:  14/175 (  8.0% false alarms)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.92      0.92       175\n",
      "    Positive       0.44      0.42      0.43        26\n",
      "\n",
      "    accuracy                           0.86       201\n",
      "   macro avg       0.68      0.67      0.67       201\n",
      "weighted avg       0.85      0.86      0.85       201\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Print formatted results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"                    TEST SET EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(f\"Dataset Statistics:\")\n",
    "print(f\"  Test subjects:        {len(y_true)}\")\n",
    "print(f\"  Positive cases:       {np.sum(y_true)} ({100*np.sum(y_true)/len(y_true):.1f}%)\")\n",
    "print(f\"  Negative cases:       {len(y_true)-np.sum(y_true)} ({100*(len(y_true)-np.sum(y_true))/len(y_true):.1f}%)\")\n",
    "print()\n",
    "print(f\"Performance Metrics:\")\n",
    "print(f\"  Accuracy:                  {acc:.4f}\")\n",
    "print(f\"  Balanced Accuracy:         {balanced_acc:.4f}\")\n",
    "print(f\"  ROC-AUC:                   {roc_auc:.4f}\")\n",
    "print(f\"  Matthews Correlation:      {mcc:.4f}\")\n",
    "print()\n",
    "print(f\"  F1 Score (Binary):         {f1_binary:.4f}\")\n",
    "print(f\"  F1 Score (Macro):          {f1_macro:.4f}\")\n",
    "print(f\"  F1 Score (Micro):          {f1_micro:.4f}\")\n",
    "print()\n",
    "print(f\"  Precision (Binary):        {precision_binary:.4f}\")\n",
    "print(f\"  Recall (Binary):           {recall_binary:.4f}\")\n",
    "\n",
    "# Enhanced confusion matrix display\n",
    "print(f\"\\n{'CONFUSION MATRIX':^50}\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'':>20} │ {'Predicted Negative':^12} │ {'Predicted Positive':^12}\")\n",
    "print(\"─\"*50)\n",
    "print(f\"{'Actual Negative':>20} │ {f'TN = {tn}':^12} │ {f'FP = {fp}':^12}\")\n",
    "print(f\"{'Actual Positive':>20} │ {f'FN = {fn}':^12} │ {f'TP = {tp}':^12}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\n  True Positives:  {tp:>3}/{int(np.sum(y_true)):<3} ({100*tp/np.sum(y_true):>5.1f}% of depression cases caught)\")\n",
    "print(f\"  False Negatives: {fn:>3}/{int(np.sum(y_true)):<3} ({100*fn/np.sum(y_true):>5.1f}% of depression cases MISSED)\")\n",
    "print(f\"  True Negatives:  {tn:>3}/{int(len(y_true)-np.sum(y_true)):<3} ({100*tn/(len(y_true)-np.sum(y_true)):>5.1f}% of healthy correctly identified)\")\n",
    "print(f\"  False Positives: {fp:>3}/{int(len(y_true)-np.sum(y_true)):<3} ({100*fp/(len(y_true)-np.sum(y_true)):>5.1f}% false alarms)\")\n",
    "\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Negative', 'Positive']))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Metrics saved to outputs_cbm/results/test_metrics.json\n"
     ]
    }
   ],
   "source": [
    "# Save metrics to JSON\n",
    "metrics_dict = {\n",
    "    \"n_samples\": int(len(y_true)),\n",
    "    \"n_positive\": int(np.sum(y_true)),\n",
    "    \"n_negative\": int(len(y_true) - np.sum(y_true)),\n",
    "    \"best_threshold\": float(best_threshold),\n",
    "    \"accuracy\": float(acc),\n",
    "    \"balanced_accuracy\": float(balanced_acc),\n",
    "    \"roc_auc\": float(roc_auc),\n",
    "    \"mcc\": float(mcc),\n",
    "    \"f1_binary\": float(f1_binary),\n",
    "    \"f1_macro\": float(f1_macro),\n",
    "    \"f1_micro\": float(f1_micro),\n",
    "    \"precision_binary\": float(precision_binary),\n",
    "    \"recall_binary\": float(recall_binary),\n",
    "    \"confusion_matrix\": {\n",
    "        \"tn\": int(tn),\n",
    "        \"fp\": int(fp),\n",
    "        \"fn\": int(fn),\n",
    "        \"tp\": int(tp)\n",
    "    }\n",
    "}\n",
    "\n",
    "os.makedirs(os.path.join(OUTPUT_DIR, \"results\"), exist_ok=True)\n",
    "metrics_path = os.path.join(OUTPUT_DIR, \"results/test_metrics.json\")\n",
    "\n",
    "with open(metrics_path, 'w') as f:\n",
    "    json.dump(metrics_dict, f, indent=4)\n",
    "\n",
    "print(f\"✓ Metrics saved to {metrics_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Predictions saved to outputs_cbm/results/test_predictions.csv\n",
      "\n",
      "First 10 subjects with concept probabilities:\n",
      "         subject_id  y_true  y_pred    y_prob   Sadness  Pessimism  \\\n",
      "0  test_subject4471       1       1  0.869716  0.089046   0.227653   \n",
      "1  test_subject8981       0       0  0.046299  0.025544   0.096699   \n",
      "2  test_subject8777       0       0  0.016334  0.014689   0.036407   \n",
      "3  test_subject1372       0       0  0.008605  0.186242   0.254578   \n",
      "4  test_subject1830       0       0  0.020472  0.023861   0.056897   \n",
      "5  test_subject3791       0       0  0.014678  0.019136   0.018401   \n",
      "6  test_subject2284       0       0  0.018185  0.046446   0.068418   \n",
      "7  test_subject5689       0       0  0.021459  0.038876   0.072512   \n",
      "8  test_subject7467       1       0  0.256077  0.049246   0.118178   \n",
      "9  test_subject7578       0       0  0.014783  0.020362   0.028903   \n",
      "\n",
      "   Past failure  Loss of pleasure  Guilty feelings  Punishment feelings  ...  \\\n",
      "0      0.225428          0.040993         0.063577             0.144133  ...   \n",
      "1      0.080988          0.030835         0.018106             0.043574  ...   \n",
      "2      0.054320          0.013909         0.009987             0.013234  ...   \n",
      "3      0.324026          0.114259         0.094723             0.139793  ...   \n",
      "4      0.103617          0.033840         0.023002             0.047666  ...   \n",
      "5      0.019409          0.007272         0.003387             0.003806  ...   \n",
      "6      0.037053          0.023560         0.013089             0.038389  ...   \n",
      "7      0.158269          0.026617         0.022269             0.027433  ...   \n",
      "8      0.108763          0.022092         0.032622             0.079130  ...   \n",
      "9      0.043695          0.013366         0.004523             0.008339  ...   \n",
      "\n",
      "   Loss of interest  Indecisiveness  Worthlessness  Loss of energy  \\\n",
      "0          0.109640        0.084598       0.325761        0.315047   \n",
      "1          0.035845        0.029884       0.090823        0.099520   \n",
      "2          0.018769        0.014141       0.010994        0.023044   \n",
      "3          0.143271        0.123976       0.085559        0.147802   \n",
      "4          0.055484        0.025429       0.047077        0.059692   \n",
      "5          0.011246        0.007541       0.008199        0.006136   \n",
      "6          0.038983        0.017569       0.031948        0.029077   \n",
      "7          0.035818        0.069164       0.041786        0.068326   \n",
      "8          0.063934        0.037730       0.158819        0.148934   \n",
      "9          0.016917        0.009212       0.006067        0.008677   \n",
      "\n",
      "   Changes in sleeping pattern  Irritability  Changes in appetite  \\\n",
      "0                     0.068969      0.048630             0.144522   \n",
      "1                     0.030206      0.022492             0.047521   \n",
      "2                     0.010586      0.007200             0.011728   \n",
      "3                     0.096858      0.085828             0.082665   \n",
      "4                     0.019763      0.017775             0.035665   \n",
      "5                     0.008358      0.005403             0.006125   \n",
      "6                     0.025167      0.015210             0.026421   \n",
      "7                     0.028450      0.030095             0.047163   \n",
      "8                     0.047313      0.023226             0.085480   \n",
      "9                     0.006012      0.008417             0.008475   \n",
      "\n",
      "   Concentration difficulty  Tiredness or fatigue  Loss of interest in sex  \n",
      "0                  0.082527              0.080493                 0.058900  \n",
      "1                  0.062023              0.054889                 0.025368  \n",
      "2                  0.023784              0.037146                 0.010141  \n",
      "3                  0.143746              0.200510                 0.159106  \n",
      "4                  0.039582              0.067340                 0.021155  \n",
      "5                  0.013797              0.038981                 0.008534  \n",
      "6                  0.033017              0.027690                 0.021808  \n",
      "7                  0.070391              0.069426                 0.041338  \n",
      "8                  0.044021              0.044145                 0.025348  \n",
      "9                  0.027655              0.026066                 0.011021  \n",
      "\n",
      "[10 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create predictions DataFrame with concept probabilities\n",
    "predictions_df = pd.DataFrame({\n",
    "    'subject_id': test_subject_ids,\n",
    "    'y_true': y_true,\n",
    "    'y_pred': y_pred,\n",
    "    'y_prob': y_prob\n",
    "})\n",
    "\n",
    "# Add concept probabilities\n",
    "for i, concept_name in enumerate(CONCEPT_NAMES):\n",
    "    predictions_df[concept_name] = concept_probs[:, i]\n",
    "\n",
    "# Save to CSV\n",
    "predictions_path = os.path.join(OUTPUT_DIR, \"results/test_predictions.csv\")\n",
    "predictions_df.to_csv(predictions_path, index=False)\n",
    "\n",
    "print(f\"✓ Predictions saved to {predictions_path}\")\n",
    "print(f\"\\nFirst 10 subjects with concept probabilities:\")\n",
    "print(predictions_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concept Activation Statistics:\n",
      "======================================================================\n",
      "Concept                                   Mean        Std        Max\n",
      "----------------------------------------------------------------------\n",
      "Sadness                                 0.0685     0.0663     0.3273\n",
      "Pessimism                               0.1220     0.1210     0.6445\n",
      "Past failure                            0.1359     0.1281     0.5971\n",
      "Loss of pleasure                        0.0444     0.0495     0.2993\n",
      "Guilty feelings                         0.0449     0.0579     0.3415\n",
      "Punishment feelings                     0.0739     0.0904     0.5012\n",
      "Self-dislike                            0.1780     0.1821     0.8220\n",
      "Self-criticalness                       0.0744     0.0538     0.2930\n",
      "Suicidal thoughts or wishes             0.0444     0.0340     0.1735\n",
      "Crying                                  0.0459     0.0507     0.2610\n",
      "Agitation                               0.0313     0.0290     0.1750\n",
      "Loss of interest                        0.0705     0.0795     0.5363\n",
      "Indecisiveness                          0.0648     0.0761     0.3917\n",
      "Worthlessness                           0.1086     0.1438     0.7595\n",
      "Loss of energy                          0.1186     0.1509     0.7611\n",
      "Changes in sleeping pattern             0.0524     0.0589     0.3782\n",
      "Irritability                            0.0329     0.0308     0.1324\n",
      "Changes in appetite                     0.0696     0.0784     0.4341\n",
      "Concentration difficulty                0.0703     0.0631     0.3271\n",
      "Tiredness or fatigue                    0.0736     0.0543     0.2401\n",
      "Loss of interest in sex                 0.0492     0.0548     0.2614\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display concept activation statistics\n",
    "print(\"\\nConcept Activation Statistics:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Concept':<35} {'Mean':>10} {'Std':>10} {'Max':>10}\")\n",
    "print(\"-\"*70)\n",
    "for i, concept_name in enumerate(CONCEPT_NAMES):\n",
    "    mean_act = np.mean(concept_probs[:, i])\n",
    "    std_act = np.std(concept_probs[:, i])\n",
    "    max_act = np.max(concept_probs[:, i])\n",
    "    print(f\"{concept_name:<35} {mean_act:>10.4f} {std_act:>10.4f} {max_act:>10.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "              CBM PIPELINE EXECUTION COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Generated files:\n",
      "  Model checkpoint: outputs_cbm/models/\n",
      "  Metrics JSON:     outputs_cbm/results/test_metrics.json\n",
      "  Predictions CSV:  outputs_cbm/results/test_predictions.csv\n",
      "  Training logs:    outputs_cbm/logs/\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"              CBM PIPELINE EXECUTION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nGenerated files:\")\n",
    "print(f\"  Model checkpoint: {OUTPUT_DIR}/models/\")\n",
    "print(f\"  Metrics JSON:     {OUTPUT_DIR}/results/test_metrics.json\")\n",
    "print(f\"  Predictions CSV:  {OUTPUT_DIR}/results/test_predictions.csv\")\n",
    "print(f\"  Training logs:    {OUTPUT_DIR}/logs/\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "38concept_embedding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
